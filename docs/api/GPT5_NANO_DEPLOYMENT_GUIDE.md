# ğŸš€ GPT-5 Nano éƒ¨ç½²æº–å‚™æŒ‡å—

## ğŸ“‹ éƒ¨ç½²å‰æº–å‚™æ¸…å–®

### 1. ğŸ”‘ API é‡‘é‘°è¨­ç½®
```bash
# 1. å‰å¾€ OpenAI å¹³å°ç²å– API é‡‘é‘°
# https://platform.openai.com/api-keys

# 2. è¨­ç½®ç’°å¢ƒè®Šæ•¸
export OPENAI_API_KEY="your_api_key_here"
```

### 2. ğŸ“¦ ä¾è³´å®‰è£
```bash
# å®‰è£ OpenAI Python å®¢æˆ¶ç«¯
pip install openai

# æˆ–æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬
pip install --upgrade openai
```

### 3. ğŸ”§ ç’°å¢ƒé…ç½®
```bash
# åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ 
OPENAI_API_KEY=your_api_key_here
OPENAI_MODEL=gpt-5-nano
OPENAI_MAX_TOKENS=500
OPENAI_TEMPERATURE=0.7
OPENAI_TIMEOUT=30
```

## ğŸ—ï¸ æŠ€è¡“ç‰¹æ€§

### GPT-5 Nano å„ªå‹¢
- âœ… **æœ€å¿«é€Ÿåº¦** - æœ€å„ªç”¨æˆ¶é«”é©—
- âœ… **æœ€å…·æˆæœ¬æ•ˆç›Š** - é©åˆé ç®—æ§åˆ¶
- âœ… **400,000 tokens ä¸Šä¸‹æ–‡çª—å£** - æ”¯æŒå¤§å‹å°è©±
- âœ… **é‡å°æ˜ç¢ºå®šç¾©ä»»å‹™å„ªåŒ–** - å®Œç¾é©åˆæ¨™ç±¤æ¨è–¦

### é©ç”¨å ´æ™¯
- ğŸ¯ æ¨™ç±¤æ¨è–¦å’Œåˆ†é¡
- ğŸ¯ å¿«é€Ÿå›æ‡‰ä»»å‹™
- ğŸ¯ æˆæœ¬æ•æ„Ÿçš„æ‡‰ç”¨
- ğŸ¯ ç§»å‹•ç«¯å’Œé‚Šç·£è¨ˆç®—

## ğŸ’» ä»£ç¢¼é›†æˆç¯„ä¾‹

### 1. åŸºç¤ API èª¿ç”¨
```python
import openai
import os
from typing import Dict, List

class GPT5NanoClient:
    def __init__(self):
        self.client = openai.OpenAI(
            api_key=os.getenv("OPENAI_API_KEY")
        )
        self.model = "gpt-5-nano"
        self.max_tokens = 500
        self.temperature = 0.7
    
    async def generate_tags(self, description: str) -> Dict:
        """ç”Ÿæˆæ¨™ç±¤æ¨è–¦"""
        try:
            response = await self.client.chat.completions.acreate(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ¨™ç±¤æ¨è–¦åŠ©æ‰‹ã€‚æ ¹æ“šç”¨æˆ¶çš„æè¿°ï¼Œæ¨è–¦æœ€ç›¸é—œçš„æ¨™ç±¤çµ„åˆã€‚
                        
                        è«‹ä»¥ JSON æ ¼å¼è¿”å›ï¼š
                        {
                            "tags": ["æ¨™ç±¤1", "æ¨™ç±¤2", "æ¨™ç±¤3"],
                            "categories": ["åˆ†é¡1", "åˆ†é¡2"],
                            "confidence": 0.95,
                            "reasoning": "æ¨è–¦ç†ç”±"
                        }"""
                    },
                    {
                        "role": "user",
                        "content": f"è«‹ç‚ºä»¥ä¸‹æè¿°æ¨è–¦æ¨™ç±¤ï¼š{description}"
                    }
                ],
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                timeout=30
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"GPT-5 Nano API èª¿ç”¨å¤±æ•—: {e}")
            return None
```

### 2. èˆ‡ç¾æœ‰ç³»çµ±é›†æˆ
```python
# åœ¨ src/api/routers/llm/recommendations.py ä¸­é›†æˆ
from .gpt5_nano_client import GPT5NanoClient

@router.post("/recommend-tags")
async def recommend_tags(
    request: LLMRecommendRequest,
    db: SupabaseService = Depends(get_supabase_service)
):
    # åˆå§‹åŒ– GPT-5 Nano å®¢æˆ¶ç«¯
    gpt5_client = GPT5NanoClient()
    
    # èª¿ç”¨ GPT-5 Nano API
    gpt5_response = await gpt5_client.generate_tags(request.description)
    
    if gpt5_response:
        # è§£æ GPT-5 å›æ‡‰
        import json
        try:
            tags_data = json.loads(gpt5_response)
            return TagRecommendationResponse(
                recommended_tags=tags_data.get("tags", []),
                categories=tags_data.get("categories", []),
                confidence=tags_data.get("confidence", 0.8),
                reasoning=tags_data.get("reasoning", "")
            )
        except json.JSONDecodeError:
            # å›é€€åˆ°ç¾æœ‰é‚è¼¯
            pass
    
    # å›é€€åˆ°ç¾æœ‰çš„é—œéµå­—åŒ¹é…é‚è¼¯
    return await fallback_keyword_matching(request, db)
```

## ğŸ’° æˆæœ¬å„ªåŒ–ç­–ç•¥

### 1. Token ä½¿ç”¨å„ªåŒ–
```python
def optimize_prompt(description: str) -> str:
    """å„ªåŒ–æç¤ºè©ä»¥æ¸›å°‘ token ä½¿ç”¨"""
    # ç§»é™¤å†—é¤˜æ–‡å­—
    cleaned = description.strip()
    
    # é™åˆ¶é•·åº¦
    if len(cleaned) > 1000:
        cleaned = cleaned[:1000] + "..."
    
    return cleaned
```

### 2. å¿«å–æ©Ÿåˆ¶
```python
import redis
from functools import lru_cache

# è¨­ç½® Redis å¿«å–
redis_client = redis.Redis(host='localhost', port=6379, db=0)

@lru_cache(maxsize=1000)
async def cached_tag_recommendation(description_hash: str):
    """å¿«å–æ¨™ç±¤æ¨è–¦çµæœ"""
    cached_result = redis_client.get(f"tags:{description_hash}")
    if cached_result:
        return json.loads(cached_result)
    return None
```

### 3. æ‰¹é‡è™•ç†
```python
async def batch_process_descriptions(descriptions: List[str]):
    """æ‰¹é‡è™•ç†å¤šå€‹æè¿°ä»¥é™ä½æˆæœ¬"""
    # åˆä½µå¤šå€‹æè¿°åˆ°ä¸€å€‹è«‹æ±‚ä¸­
    combined_prompt = "è«‹ç‚ºä»¥ä¸‹æè¿°åˆ†åˆ¥æ¨è–¦æ¨™ç±¤ï¼š\n" + "\n".join(descriptions)
    
    response = await gpt5_client.generate_tags(combined_prompt)
    return response
```

## ğŸ§ª æ¸¬è©¦ç­–ç•¥

### 1. å–®å…ƒæ¸¬è©¦
```python
import pytest
from unittest.mock import AsyncMock, patch

@pytest.mark.asyncio
async def test_gpt5_nano_tag_generation():
    """æ¸¬è©¦ GPT-5 Nano æ¨™ç±¤ç”Ÿæˆ"""
    client = GPT5NanoClient()
    
    with patch.object(client.client.chat.completions, 'acreate') as mock_create:
        mock_create.return_value = AsyncMock(
            choices=[AsyncMock(message=AsyncMock(content='{"tags": ["ç¾é£Ÿ", "é¤å»³"], "confidence": 0.9}'))]
        )
        
        result = await client.generate_tags("æˆ‘æƒ³æ‰¾å¥½åƒçš„é¤å»³")
        assert result is not None
```

### 2. é›†æˆæ¸¬è©¦
```python
@pytest.mark.asyncio
async def test_api_integration():
    """æ¸¬è©¦ API é›†æˆ"""
    test_request = {
        "description": "ç¾é£Ÿæ¨è–¦"
    }
    
    response = await client.post("/api/llm/recommend-tags", json=test_request)
    assert response.status_code == 200
    assert "recommended_tags" in response.json()
```

## ğŸ“Š ç›£æ§å’Œæ—¥èªŒ

### 1. æ€§èƒ½ç›£æ§
```python
import time
import logging

async def monitored_api_call(description: str):
    """ç›£æ§ API èª¿ç”¨æ€§èƒ½"""
    start_time = time.time()
    
    try:
        result = await gpt5_client.generate_tags(description)
        duration = time.time() - start_time
        
        logging.info(f"GPT-5 Nano èª¿ç”¨æˆåŠŸ - è€—æ™‚: {duration:.2f}s")
        return result
        
    except Exception as e:
        duration = time.time() - start_time
        logging.error(f"GPT-5 Nano èª¿ç”¨å¤±æ•— - è€—æ™‚: {duration:.2f}s, éŒ¯èª¤: {e}")
        raise
```

### 2. æˆæœ¬è¿½è¹¤
```python
def track_token_usage(response):
    """è¿½è¹¤ token ä½¿ç”¨é‡"""
    if hasattr(response, 'usage'):
        logging.info(f"Token ä½¿ç”¨ - è¼¸å…¥: {response.usage.prompt_tokens}, "
                    f"è¼¸å‡º: {response.usage.completion_tokens}, "
                    f"ç¸½è¨ˆ: {response.usage.total_tokens}")
```

## ğŸš€ éƒ¨ç½²æ­¥é©Ÿ

### 1. æº–å‚™éšæ®µ
- [ ] ç²å– OpenAI API é‡‘é‘°
- [ ] å®‰è£ OpenAI å®¢æˆ¶ç«¯åº«
- [ ] è¨­ç½®ç’°å¢ƒè®Šæ•¸
- [ ] å‰µå»º GPT5NanoClient é¡åˆ¥

### 2. é–‹ç™¼éšæ®µ
- [ ] å¯¦ç¾åŸºç¤ API èª¿ç”¨
- [ ] é›†æˆåˆ°ç¾æœ‰æ¨è–¦ç³»çµ±
- [ ] æ·»åŠ éŒ¯èª¤è™•ç†å’Œå›é€€æ©Ÿåˆ¶
- [ ] å¯¦ç¾å¿«å–å’Œå„ªåŒ–

### 3. æ¸¬è©¦éšæ®µ
- [ ] å–®å…ƒæ¸¬è©¦
- [ ] é›†æˆæ¸¬è©¦
- [ ] æ€§èƒ½æ¸¬è©¦
- [ ] æˆæœ¬æ¸¬è©¦

### 4. éƒ¨ç½²éšæ®µ
- [ ] ç”Ÿç”¢ç’°å¢ƒé…ç½®
- [ ] ç›£æ§è¨­ç½®
- [ ] æ—¥èªŒé…ç½®
- [ ] æ€§èƒ½å„ªåŒ–

## ğŸ“š ç›¸é—œè³‡æº

- [OpenAI API æ–‡æª”](https://platform.openai.com/docs)
- [GPT-5 ç³»åˆ—ä»‹ç´¹](https://openai.com/gpt-5)
- [Python å®¢æˆ¶ç«¯åº«](https://github.com/openai/openai-python)
- [æœ€ä½³å¯¦è¸æŒ‡å—](https://platform.openai.com/docs/guides/production-best-practices)

## ğŸ¯ ä¸‹ä¸€æ­¥è¡Œå‹•

1. **ç«‹å³é–‹å§‹**: è¨­ç½® API é‡‘é‘°å’ŒåŸºç¤ç’°å¢ƒ
2. **é–‹ç™¼é›†æˆ**: å¯¦ç¾ GPT5NanoClient é¡åˆ¥
3. **æ¸¬è©¦é©—è­‰**: é€²è¡Œå…¨é¢æ¸¬è©¦
4. **éƒ¨ç½²ä¸Šç·š**: é€æ­¥éƒ¨ç½²åˆ°ç”Ÿç”¢ç’°å¢ƒ

æº–å‚™å¥½äº†å—ï¼Ÿè®“æˆ‘å€‘é–‹å§‹ GPT-5 Nano çš„é›†æˆï¼ğŸš€
