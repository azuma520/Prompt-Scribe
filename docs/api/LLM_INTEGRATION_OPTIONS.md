# ğŸ¤– LLM æ•´åˆæ–¹æ¡ˆ

**æ–‡æª”æ—¥æœŸ**: 2025-10-17  
**ç‹€æ…‹**: è¦åŠƒä¸­

---

## ğŸ“Š ç•¶å‰ç‹€æ³

### âŒ ç„¡çœŸæ­£ LLM æ•´åˆ

**ç•¶å‰å¯¦ä½œ**:
- ä½¿ç”¨é—œéµå­—åŒ¹é…ï¼ˆKeywordExpanderï¼‰
- è³‡æ–™åº«æŸ¥è©¢ï¼ˆSupabaseï¼‰
- åŒç¾©è©æ“´å±•
- **ä¸æ˜¯çœŸæ­£çš„ AI ç”Ÿæˆ**

**å„ªé»**: å¿«é€Ÿã€å…è²»ã€å¯é æ¸¬  
**ç¼ºé»**: å‰µæ„æœ‰é™ã€ç„¡æ³•ç†è§£è¤‡é›œèªæ„

---

## ğŸ¯ æ•´åˆç›®æ¨™

### Inspire åŠŸèƒ½éœ€æ±‚
1. ç†è§£æƒ…ç·’æè¿°ï¼ˆå¦‚ã€Œå­¤ç¨åˆå¤¢å¹»ã€ï¼‰
2. ç”Ÿæˆå‰µæ„çµ„åˆ
3. æä¾›å¤šæ¨£åŒ–å»ºè­°
4. æ”¯æ´åé¥‹å„ªåŒ–

### å…¶ä»–åŠŸèƒ½æ“´å±•
1. æ™ºèƒ½æ¨™ç±¤çµ„åˆ
2. Prompt å“è³ªè©•ä¼°
3. è‡ªç„¶èªè¨€è½‰æ¨™ç±¤

---

## ğŸš€ æ–¹æ¡ˆé¸é …

### æ–¹æ¡ˆ 1ï¼šOpenAI GPT-4/3.5ï¼ˆæ¨è–¦ï¼‰â­

**æŠ€è¡“æ£§**:
```python
import openai
from openai import AsyncOpenAI

client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
```

**å„ªé»**:
- âœ… å¼·å¤§çš„èªè¨€ç†è§£
- âœ… è±å¯Œçš„ API åŠŸèƒ½
- âœ… è‰¯å¥½çš„æ–‡æª”æ”¯æ´
- âœ… ç©©å®šæ€§é«˜

**ç¼ºé»**:
- âŒ éœ€è¦ä»˜è²»ï¼ˆç´„ $0.002/1K tokensï¼‰
- âŒ éœ€è¦ API Key
- âŒ æœ‰é€Ÿç‡é™åˆ¶

**æˆæœ¬ä¼°ç®—**:
- Inspire å–®æ¬¡ç”Ÿæˆï¼š~500 tokens = $0.001
- 1000 æ¬¡/æœˆ = $1
- **éå¸¸ä¾¿å®œï¼**

**å¯¦ä½œç¯„ä¾‹**:
```python
# src/api/services/llm_service.py

from openai import AsyncOpenAI
from config import settings
import json

class LLMService:
    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
    
    async def generate_inspiration_cards(
        self, 
        description: str,
        available_tags: list[str]
    ) -> list[dict]:
        """ä½¿ç”¨ GPT ç”Ÿæˆéˆæ„Ÿå¡"""
        
        system_prompt = f"""ä½ æ˜¯ä¸€å€‹ AI åœ–åƒç”ŸæˆåŠ©æ‰‹ã€‚
ç”¨æˆ¶æœƒæè¿°ä»–å€‘æƒ³è¦çš„æ„Ÿè¦ºæˆ–ä¸»é¡Œï¼Œä½ éœ€è¦ï¼š
1. ç†è§£æƒ…ç·’å’Œæ„åœ–
2. å¾å¯ç”¨æ¨™ç±¤ä¸­é¸æ“‡åˆé©çš„çµ„åˆ
3. ç”Ÿæˆ 3 å¼µå‰µæ„éˆæ„Ÿå¡

å¯ç”¨æ¨™ç±¤åº«ï¼š{', '.join(available_tags[:100])}...
ï¼ˆå…± {len(available_tags)} å€‹æ¨™ç±¤ï¼‰

è¿”å› JSON æ ¼å¼ï¼š
{{
  "cards": [
    {{
      "subject": "ä¸»é«”æè¿°",
      "scene": "å ´æ™¯æè¿°",
      "style": "é¢¨æ ¼æè¿°",
      "source_tags": ["tag1", "tag2", "tag3"],
      "confidence_score": 0.85
    }}
  ]
}}
"""
        
        response = await self.client.chat.completions.create(
            model="gpt-3.5-turbo",  # æˆ– gpt-4
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": description}
            ],
            response_format={"type": "json_object"},
            temperature=0.7,
            max_tokens=1000
        )
        
        result = json.loads(response.choices[0].message.content)
        return result["cards"]
```

**é…ç½®**:
```python
# config.py
OPENAI_API_KEY: str = Field(..., env="OPENAI_API_KEY")
```

```bash
# .env
OPENAI_API_KEY=sk-...your-key...
```

---

### æ–¹æ¡ˆ 2ï¼šAnthropic Claudeï¼ˆå‚™é¸ï¼‰

**å„ªé»**:
- âœ… æ›´å¥½çš„å‰µæ„èƒ½åŠ›
- âœ… æ›´é•·çš„ä¸Šä¸‹æ–‡ï¼ˆ200K tokensï¼‰
- âœ… æ›´å¥½çš„æŒ‡ä»¤éµå¾ª

**ç¼ºé»**:
- âŒ ç¨è²´ï¼ˆç´„ $0.003/1K tokensï¼‰
- âŒ API è¼ƒæ–°ï¼Œæ–‡æª”è¼ƒå°‘

**å¯¦ä½œ**:
```python
import anthropic

client = anthropic.AsyncAnthropic(api_key=settings.ANTHROPIC_API_KEY)

async def generate_with_claude(description: str):
    message = await client.messages.create(
        model="claude-3-sonnet-20240229",
        max_tokens=1024,
        messages=[
            {"role": "user", "content": description}
        ]
    )
    return message.content
```

---

### æ–¹æ¡ˆ 3ï¼šæœ¬åœ° LLMï¼ˆOllamaï¼‰

**æŠ€è¡“**:
- Ollama + Llama 3.1 / Mistral
- å®Œå…¨æœ¬åœ°é‹è¡Œ

**å„ªé»**:
- âœ… å®Œå…¨å…è²»
- âœ… ç„¡ API é™åˆ¶
- âœ… è³‡æ–™éš±ç§

**ç¼ºé»**:
- âŒ éœ€è¦ GPU ä¼ºæœå™¨
- âŒ éƒ¨ç½²è¤‡é›œ
- âŒ æ•ˆèƒ½è¼ƒå·®

**ä¸æ¨è–¦ç†ç”±**:
- Zeabur/Vercel ç„¡æ³•é‹è¡Œ
- æˆæœ¬åè€Œæ›´é«˜ï¼ˆéœ€è¦ GPU ä¼ºæœå™¨ï¼‰

---

### æ–¹æ¡ˆ 4ï¼šæ··åˆæ¨¡å¼ï¼ˆæ¨è–¦ç”¨æ–¼ç”Ÿç”¢ï¼‰â­â­

**ç­–ç•¥**:
1. **å…è²»ç”¨æˆ¶**: é—œéµå­—åŒ¹é…ï¼ˆç•¶å‰æ–¹æ¡ˆï¼‰
2. **ä»˜è²»ç”¨æˆ¶**: GPT-3.5 ç”Ÿæˆ
3. **é«˜ç´šç”¨æˆ¶**: GPT-4 ç”Ÿæˆ

**å„ªé»**:
- âœ… æˆæœ¬å¯æ§
- âœ… æ¼¸é€²å¼å‡ç´š
- âœ… ä¿ç•™å‚™ç”¨æ–¹æ¡ˆ

**å¯¦ä½œ**:
```python
async def generate_cards(description: str, user_tier: str):
    if user_tier == "free":
        # ç•¶å‰æ–¹æ¡ˆï¼šé—œéµå­—åŒ¹é…
        return await keyword_based_generation(description)
    elif user_tier == "pro":
        # GPT-3.5
        return await llm_generation(description, model="gpt-3.5-turbo")
    else:  # premium
        # GPT-4
        return await llm_generation(description, model="gpt-4")
```

---

## ğŸ”§ å¯¦ä½œæ­¥é©Ÿ

### Step 1: å®‰è£ä¾è³´

```bash
cd src/api
pip install openai==1.3.0
```

æ›´æ–° `requirements.txt`:
```
openai==1.3.0
```

---

### Step 2: é…ç½®ç’°å¢ƒè®Šæ•¸

```bash
# .envï¼ˆå¾Œç«¯ï¼‰
OPENAI_API_KEY=sk-...your-api-key...

# å¯é¸ï¼šé¸æ“‡æ¨¡å‹
OPENAI_MODEL=gpt-3.5-turbo  # æˆ– gpt-4
```

---

### Step 3: å‰µå»º LLM æœå‹™

å‰µå»º `src/api/services/llm_service.py`:

```python
"""
LLM æœå‹™ - OpenAI GPT æ•´åˆ
"""
from openai import AsyncOpenAI
from config import settings
import json
import logging

logger = logging.getLogger(__name__)

class LLMService:
    """LLM æœå‹™é¡"""
    
    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = getattr(settings, "OPENAI_MODEL", "gpt-3.5-turbo")
    
    async def generate_inspiration_cards(
        self,
        description: str,
        available_tags: list[dict],
        num_cards: int = 3
    ) -> list[dict]:
        """
        ä½¿ç”¨ GPT ç”Ÿæˆéˆæ„Ÿå¡
        
        Args:
            description: ç”¨æˆ¶è¼¸å…¥æè¿°
            available_tags: å¯ç”¨æ¨™ç±¤åˆ—è¡¨ï¼ˆå¾è³‡æ–™åº«æŸ¥è©¢ï¼‰
            num_cards: ç”Ÿæˆå¡ç‰‡æ•¸é‡
        
        Returns:
            éˆæ„Ÿå¡åˆ—è¡¨
        """
        try:
            # æº–å‚™æ¨™ç±¤è³‡è¨Š
            tag_summary = self._prepare_tag_summary(available_tags)
            
            # æ§‹å»º prompt
            system_prompt = self._build_system_prompt(tag_summary)
            
            # èª¿ç”¨ GPT
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"æè¿°ï¼š{description}\n\nè«‹ç”Ÿæˆ {num_cards} å¼µéˆæ„Ÿå¡ã€‚"}
                ],
                response_format={"type": "json_object"},
                temperature=0.7,
                max_tokens=1500
            )
            
            # è§£æçµæœ
            result = json.loads(response.choices[0].message.content)
            cards = result.get("cards", [])
            
            logger.info(f"æˆåŠŸç”Ÿæˆ {len(cards)} å¼µéˆæ„Ÿå¡")
            return cards
            
        except Exception as e:
            logger.error(f"LLM ç”Ÿæˆå¤±æ•—: {e}")
            # é™ç´šåˆ°é—œéµå­—åŒ¹é…
            return await self._fallback_generation(description, available_tags)
    
    def _prepare_tag_summary(self, tags: list[dict]) -> str:
        """æº–å‚™æ¨™ç±¤æ‘˜è¦"""
        # æŒ‰åˆ†é¡æ•´ç†æ¨™ç±¤
        by_category = {}
        for tag in tags[:50]:  # åªç”¨å‰ 50 å€‹
            cat = tag.get("category", "OTHER")
            if cat not in by_category:
                by_category[cat] = []
            by_category[cat].append(tag["name"])
        
        # æ ¼å¼åŒ–
        summary = []
        for cat, tag_names in by_category.items():
            summary.append(f"{cat}: {', '.join(tag_names[:10])}")
        
        return "\n".join(summary)
    
    def _build_system_prompt(self, tag_summary: str) -> str:
        """æ§‹å»ºç³»çµ±æç¤º"""
        return f"""ä½ æ˜¯å°ˆæ¥­çš„ AI åœ–åƒç”ŸæˆåŠ©æ‰‹ã€‚

ä½ çš„ä»»å‹™ï¼š
1. ç†è§£ç”¨æˆ¶çš„æƒ…ç·’å’Œä¸»é¡Œæè¿°
2. å¾å¯ç”¨æ¨™ç±¤ä¸­é¸æ“‡åˆé©çš„çµ„åˆ
3. ç”Ÿæˆ 3 å¼µæœ‰å‰µæ„ä¸”å¤šæ¨£åŒ–çš„éˆæ„Ÿå¡

å¯ç”¨æ¨™ç±¤ï¼ˆæŒ‰åˆ†é¡ï¼‰ï¼š
{tag_summary}

è¼¸å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
  "cards": [
    {{
      "subject": "ä¸»é«”æè¿°ï¼ˆå¦‚ 'lone girl, contemplative'ï¼‰",
      "scene": "å ´æ™¯æè¿°ï¼ˆå¦‚ 'misty forest, dawn'ï¼‰",
      "lighting": "å…‰ç·šæè¿°ï¼ˆå¯é¸ï¼‰",
      "style": "é¢¨æ ¼æè¿°ï¼ˆå¦‚ 'cinematic, dreamy'ï¼‰",
      "source_tags": ["å¯¦éš›æ¨™ç±¤1", "å¯¦éš›æ¨™ç±¤2", "æ¨™ç±¤3"],
      "confidence_score": 0.85
    }}
  ]
}}

è¦æ±‚ï¼š
- 3 å¼µå¡ç‰‡è¦æœ‰å¤šæ¨£æ€§ï¼ˆä¸åŒé¢¨æ ¼/å ´æ™¯/æƒ…ç·’ï¼‰
- source_tags å¿…é ˆä¾†è‡ªæä¾›çš„æ¨™ç±¤åº«
- confidence_score åœ¨ 0.6-0.95 ä¹‹é–“
- æè¿°è¦å…·é«”ä¸”å¯Œæœ‰ç•«é¢æ„Ÿ
"""
    
    async def _fallback_generation(
        self, 
        description: str, 
        tags: list[dict]
    ) -> list[dict]:
        """é™ç´šæ–¹æ¡ˆï¼šé—œéµå­—åŒ¹é…"""
        # ä½¿ç”¨ç¾æœ‰çš„é—œéµå­—åŒ¹é…é‚è¼¯
        from services.keyword_analyzer import KeywordAnalyzer
        
        analyzer = KeywordAnalyzer()
        keywords = analyzer.extract_keywords(description)
        
        # ç°¡å–®çµ„åˆæˆå¡ç‰‡
        return [
            {
                "subject": f"{keywords[0] if keywords else 'character'}",
                "scene": f"{keywords[1] if len(keywords) > 1 else 'scene'}",
                "style": "artistic",
                "source_tags": [t["name"] for t in tags[:5]],
                "confidence_score": 0.6
            }
        ]


# å–®ä¾‹
_llm_service = None

def get_llm_service() -> LLMService:
    """ç²å– LLM æœå‹™å–®ä¾‹"""
    global _llm_service
    if _llm_service is None:
        _llm_service = LLMService()
    return _llm_service
```

---

### Step 4: æ›´æ–° Inspire ç«¯é»

ä¿®æ”¹ `src/api/routers/llm/recommendations.py`:

```python
from services.llm_service import get_llm_service, LLMService

@router.post("/inspire/generate")
async def generate_inspiration(
    request: InspireRequest,
    db: SupabaseService = Depends(get_supabase_service),
    llm: LLMService = Depends(get_llm_service)
):
    """ç”Ÿæˆéˆæ„Ÿå¡ï¼ˆä½¿ç”¨çœŸæ­£çš„ LLMï¼‰"""
    
    try:
        # 1. å¾è³‡æ–™åº«ç²å–å€™é¸æ¨™ç±¤
        tags = await db.search_tags_by_keywords(
            keywords=extract_keywords(request.description),
            limit=100
        )
        
        # 2. ä½¿ç”¨ LLM ç”Ÿæˆ
        cards = await llm.generate_inspiration_cards(
            description=request.description,
            available_tags=tags,
            num_cards=3
        )
        
        return {
            "mode": detect_mode(request.description),
            "round": 1,
            "cards": cards,
            "suggestions": ["é¸æ“‡ä½ æœ€å–œæ­¡çš„", "æˆ–é‡æ–°æè¿°"]
        }
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

---

### Step 5: æ›´æ–°å‰ç«¯ API å®¢æˆ¶ç«¯

ä¿®æ”¹ `prompt-scribe-web/src/lib/api/inspire.ts`:

```typescript
export async function generateInspirationCards(
  input: string,
  sessionId: string
): Promise<InspireGenerateResponse> {
  try {
    // èª¿ç”¨æ–°çš„ LLM ç«¯é»
    const response = await fetch(
      `${API_BASE_URL}/api/llm/inspire/generate`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ 
          description: input,
          session_id: sessionId 
        }),
      }
    );

    if (!response.ok) {
      throw new Error(`API è«‹æ±‚å¤±æ•— (${response.status})`);
    }

    return await response.json();
  } catch (error) {
    console.error('ç”Ÿæˆéˆæ„Ÿå¡æ™‚ç™¼ç”ŸéŒ¯èª¤:', error);
    throw error;
  }
}
```

---

## ğŸ’° æˆæœ¬åˆ†æ

### OpenAI GPT-3.5 Turbo

| é …ç›® | æˆæœ¬ |
|------|------|
| è¼¸å…¥ | $0.0005 / 1K tokens |
| è¼¸å‡º | $0.0015 / 1K tokens |
| **å–®æ¬¡ Inspire ç”Ÿæˆ** | **~$0.001** |
| 1000 æ¬¡/æœˆ | $1 |
| 10000 æ¬¡/æœˆ | $10 |

### OpenAI GPT-4

| é …ç›® | æˆæœ¬ |
|------|------|
| è¼¸å…¥ | $0.01 / 1K tokens |
| è¼¸å‡º | $0.03 / 1K tokens |
| **å–®æ¬¡ç”Ÿæˆ** | **~$0.02** |
| 1000 æ¬¡/æœˆ | $20 |

**çµè«–**: GPT-3.5 éå¸¸ä¾¿å®œï¼Œå®Œå…¨å¯ä»¥æ¥å—ï¼

---

## ğŸ¯ æ¨è–¦æ–¹æ¡ˆ

### ğŸ¥‡ æœ€ä½³æ–¹æ¡ˆï¼šæ··åˆæ¨¡å¼

```python
# é…ç½®
LLM_ENABLED = True  # æ˜¯å¦å•Ÿç”¨ LLM
LLM_FREE_TIER_LIMIT = 5  # å…è²»ç”¨æˆ¶æ¯æ—¥é™åˆ¶
LLM_PAID_TIER_UNLIMITED = True  # ä»˜è²»ç„¡é™åˆ¶

# é‚è¼¯
if user.is_paid or (user.daily_llm_count < FREE_TIER_LIMIT):
    # ä½¿ç”¨ LLM
    cards = await llm.generate()
    user.daily_llm_count += 1
else:
    # é™ç´šåˆ°é—œéµå­—åŒ¹é…
    cards = await keyword_match()
```

**å„ªé»**:
- âœ… å…è²»ç”¨æˆ¶æœ‰åŸºæœ¬é«”é©—
- âœ… æˆæœ¬å®Œå…¨å¯æ§
- âœ… ä»˜è²»è½‰æ›å‹•æ©Ÿ
- âœ… ä¿ç•™é™ç´šæ–¹æ¡ˆ

---

## ğŸ“ å¯¦ä½œæª¢æŸ¥æ¸…å–®

### å¾Œç«¯
- [ ] å®‰è£ `openai` å¥—ä»¶
- [ ] å‰µå»º `LLMService` é¡
- [ ] æ·»åŠ ç’°å¢ƒè®Šæ•¸ `OPENAI_API_KEY`
- [ ] å‰µå»ºæ–°ç«¯é» `/api/llm/inspire/generate`
- [ ] å¯¦ä½œé™ç´šæ©Ÿåˆ¶
- [ ] æ·»åŠ é€Ÿç‡é™åˆ¶
- [ ] æ¸¬è©¦ API

### å‰ç«¯
- [ ] æ›´æ–° API å®¢æˆ¶ç«¯
- [ ] æ·»åŠ  loading ç‹€æ…‹
- [ ] è™•ç†éŒ¯èª¤æƒ…æ³
- [ ] æ¸¬è©¦å®Œæ•´æµç¨‹

### éƒ¨ç½²
- [ ] é…ç½® Zeabur ç’°å¢ƒè®Šæ•¸
- [ ] æ¸¬è©¦ç”Ÿç”¢ç’°å¢ƒ
- [ ] ç›£æ§æˆæœ¬

---

## ğŸ“š åƒè€ƒè³‡æº

- [OpenAI API æ–‡æª”](https://platform.openai.com/docs)
- [OpenAI Pricing](https://openai.com/pricing)
- [Best Practices](https://platform.openai.com/docs/guides/gpt-best-practices)

---

**æœ€å¾Œæ›´æ–°**: 2025-10-17  
**ç‹€æ…‹**: âœ… æ–¹æ¡ˆè¦åŠƒå®Œæˆï¼Œå¾…å¯¦ä½œ














