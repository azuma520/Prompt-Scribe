# ğŸš€ API å„ªåŒ–å¿«é€Ÿé–‹å§‹æŒ‡å—

åŸºæ–¼æˆ‘å€‘çš„è¨è«–å’Œéœ€æ±‚åˆ†æï¼Œæœ¬æŒ‡å—å°‡å¹«åŠ©æ‚¨å¿«é€Ÿé–‹å§‹ LLM å‹å¥½çš„ API é–‹ç™¼ã€‚

---

## ğŸ“‹ è¨ˆç•«ç¸½è¦½

### æ ¸å¿ƒæ”¹é€²é»

| é¢å‘ | æ”¹é€²å‰ | æ”¹é€²å¾Œ | æ•ˆæœ |
|------|--------|--------|------|
| LLM API èª¿ç”¨ | 2-3 æ¬¡ | 1 æ¬¡ | ç°¡åŒ– 60% |
| é–‹ç™¼æ™‚é–“ | 2-3 é€± | 1 é€± | åŠ é€Ÿ 50% |
| åˆæœŸæˆæœ¬ | $5 | $0 | ç¯€çœ 100% |
| è¤‡é›œåº¦ | é«˜ | ä½ | é™ä½ 70% |

### é–‹ç™¼ç­–ç•¥

```
Week 1: é—œéµå­—æœå°‹ API    â†’ 80% éœ€æ±‚è¦†è“‹
Week 2: LLM å°ˆç”¨ç«¯é»      â†’ 90% éœ€æ±‚è¦†è“‹  
Week 3-4: æ¸¬è©¦å’Œéƒ¨ç½²      â†’ ç”Ÿç”¢å°±ç·’
æœªä¾†: å‘é‡æœå°‹ï¼ˆå¯é¸ï¼‰    â†’ 95%+ éœ€æ±‚è¦†è“‹
```

---

## ğŸ¯ Phase 1: åŸºç¤ API é–‹ç™¼ï¼ˆæœ¬é€±ï¼‰

### Step 1: å°ˆæ¡ˆè¨­ç½®

```bash
# å»ºç«‹ API å°ˆæ¡ˆçµæ§‹
mkdir -p prompt-scribe-api
cd prompt-scribe-api

# å»ºç«‹ç›®éŒ„çµæ§‹
mkdir -p api/{routers/{v1,llm,admin},services,models,tests,data}

# å»ºç«‹æ ¸å¿ƒæª”æ¡ˆ
touch api/main.py
touch api/config.py
touch api/requirements.txt
touch api/routers/__init__.py
touch api/routers/v1/__init__.py
touch api/routers/llm/__init__.py
touch api/services/__init__.py
touch api/models/__init__.py
```

### Step 2: å®‰è£ä¾è³´

```bash
# requirements.txt
cat > api/requirements.txt << 'EOF'
fastapi==0.109.0
uvicorn[standard]==0.27.0
supabase==2.3.0
python-dotenv==1.0.0
pydantic==2.5.0
pyyaml==6.0.1
httpx==0.26.0
python-multipart==0.0.6
EOF

# å®‰è£
pip install -r api/requirements.txt
```

### Step 3: é…ç½®ç’°å¢ƒ

```bash
# .env
cat > api/.env << 'EOF'
# Supabase é…ç½®
SUPABASE_URL=https://fumuvmbhmmzkenizksyq.supabase.co
SUPABASE_ANON_KEY=your-anon-key
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# API é…ç½®
API_TITLE=Prompt-Scribe API
API_VERSION=2.0.0
API_HOST=0.0.0.0
API_PORT=8000

# å¿«å–é…ç½®
ENABLE_CACHE=true
CACHE_TTL=3600

# æ—¥èªŒé…ç½®
LOG_LEVEL=INFO
EOF
```

### Step 4: å¯¦ä½œç¬¬ä¸€å€‹ç«¯é»

```python
# api/main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from routers.v1 import tags
from routers.llm import recommendations
import os
from dotenv import load_dotenv

load_dotenv()

app = FastAPI(
    title=os.getenv("API_TITLE", "Prompt-Scribe API"),
    version=os.getenv("API_VERSION", "2.0.0"),
    description="LLM å‹å¥½çš„ Danbooru æ¨™ç±¤ API"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è·¯ç”±
app.include_router(tags.router, prefix="/api/v1", tags=["Tags"])
app.include_router(recommendations.router, prefix="/api/llm", tags=["LLM"])

@app.get("/")
async def root():
    return {
        "message": "Prompt-Scribe API",
        "version": "2.0.0",
        "docs": "/docs"
    }

@app.get("/health")
async def health():
    return {"status": "healthy"}
```

```python
# api/config.py
from pydantic_settings import BaseSettings
from functools import lru_cache

class Settings(BaseSettings):
    # Supabase
    supabase_url: str
    supabase_anon_key: str
    supabase_service_role_key: str
    
    # API
    api_title: str = "Prompt-Scribe API"
    api_version: str = "2.0.0"
    api_host: str = "0.0.0.0"
    api_port: int = 8000
    
    # Cache
    enable_cache: bool = True
    cache_ttl: int = 3600
    
    class Config:
        env_file = ".env"

@lru_cache()
def get_settings():
    return Settings()
```

```python
# api/services/supabase_client.py
from supabase import create_client, Client
from functools import lru_cache
from config import get_settings

@lru_cache()
def get_supabase_client() -> Client:
    settings = get_settings()
    return create_client(
        settings.supabase_url,
        settings.supabase_anon_key
    )

@lru_cache()
def get_supabase_admin_client() -> Client:
    settings = get_settings()
    return create_client(
        settings.supabase_url,
        settings.supabase_service_role_key
    )
```

### Step 5: å¯¦ä½œåŸºç¤æ¨™ç±¤æŸ¥è©¢

```python
# api/routers/v1/tags.py
from fastapi import APIRouter, Query, HTTPException
from typing import Optional, List
from services.supabase_client import get_supabase_client

router = APIRouter()

@router.get("/tags")
async def get_tags(
    name: Optional[str] = None,
    category: Optional[str] = None,
    min_popularity: int = Query(0, ge=0),
    limit: int = Query(20, ge=1, le=100),
    offset: int = Query(0, ge=0)
):
    """
    æŸ¥è©¢æ¨™ç±¤åˆ—è¡¨
    
    - **name**: æ¨™ç±¤åç¨±ç¯©é¸ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰
    - **category**: åˆ†é¡ç¯©é¸
    - **min_popularity**: æœ€ä½æµè¡Œåº¦
    - **limit**: è¿”å›æ•¸é‡ï¼ˆæœ€å¤š 100ï¼‰
    - **offset**: åˆ†é åç§»
    """
    try:
        client = get_supabase_client()
        query = client.table('tags_final').select('*', count='exact')
        
        # ç¯©é¸æ¢ä»¶
        if name:
            query = query.ilike('name', f'%{name}%')
        if category:
            query = query.eq('main_category', category)
        if min_popularity > 0:
            query = query.gte('post_count', min_popularity)
        
        # åˆ†é å’Œæ’åº
        response = query.order('post_count', desc=True).range(offset, offset + limit - 1).execute()
        
        return {
            "data": response.data,
            "total": response.count,
            "limit": limit,
            "offset": offset
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/tags/{tag_name}")
async def get_tag_detail(tag_name: str):
    """å–å¾—ç‰¹å®šæ¨™ç±¤çš„è©³ç´°è³‡è¨Š"""
    try:
        client = get_supabase_client()
        response = client.table('tags_final').select('*').eq('name', tag_name).execute()
        
        if not response.data:
            raise HTTPException(status_code=404, detail=f"Tag '{tag_name}' not found")
        
        return response.data[0]
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

### Step 6: æ¸¬è©¦åŸºç¤åŠŸèƒ½

```bash
# å•Ÿå‹• API
cd api
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# æ¸¬è©¦ç«¯é»
curl http://localhost:8000/health
curl "http://localhost:8000/api/v1/tags?limit=5"
curl "http://localhost:8000/api/v1/tags/1girl"
```

---

## ğŸ¤– Phase 2: LLM å°ˆç”¨ç«¯é»ï¼ˆä¸‹é€±ï¼‰

### Step 1: å»ºç«‹åŒç¾©è©å­—å…¸

```yaml
# api/data/keyword_synonyms.yaml
character:
  girl: [1girl, female, woman, girl_character]
  boy: [1boy, male, man, boy_character]
  alone: [solo, single, one_person, solitary]
  people: [2people, 3people, multiple, group]

emotion:
  happy: [smile, smiling, cheerful, joyful, happy_expression]
  sad: [crying, tears, melancholy, sad_expression]
  lonely: [solo, alone, isolated, loneliness, solitary]

style:
  cyberpunk: [neon, futuristic, sci-fi, technology, cyber, digital, tech]
  anime: [manga, japanese_style, illustration, drawn, animated]
  realistic: [photorealistic, photo, real, photograph, photographic]

environment:
  city: [urban, cityscape, street, buildings, downtown, metropolitan]
  nature: [forest, mountain, outdoor, landscape, wilderness, natural]
  room: [bedroom, living_room, indoor, interior, indoors]
  school: [classroom, school_building, campus, academy]

time:
  night: [nighttime, evening, dark, moonlight, night_time]
  day: [daytime, sunlight, bright, sunny, day_time]
  sunset: [dusk, twilight, evening_glow, golden_hour]

clothing:
  uniform: [school_uniform, military_uniform, outfit, costume]
  dress: [gown, skirt, clothing, formal_dress]
  casual: [casual_clothes, everyday_wear, comfortable]

action:
  sitting: [seated, sit, sitting_down, sitting_on]
  standing: [stand, standing_up, upright, standing_on]
  running: [run, sprint, jogging, running_motion]
  looking: [looking_at_viewer, eye_contact, gaze, stare]
```

### Step 2: å¯¦ä½œé—œéµå­—æ“´å±•æœå‹™

```python
# api/services/keyword_expander.py
import yaml
from pathlib import Path
from typing import List, Set, Dict
from functools import lru_cache

class KeywordExpander:
    def __init__(self, synonyms_file: str = "data/keyword_synonyms.yaml"):
        self.synonyms = self._load_synonyms(synonyms_file)
    
    def _load_synonyms(self, file_path: str) -> Dict[str, List[str]]:
        """è¼‰å…¥åŒç¾©è©å­—å…¸"""
        file_path = Path(__file__).parent.parent / file_path
        if not file_path.exists():
            return {}
        
        with open(file_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
        
        # æ‰å¹³åŒ–å­—å…¸
        flat_synonyms = {}
        for category, words in data.items():
            for word, synonyms in words.items():
                flat_synonyms[word.lower()] = [s.lower() for s in synonyms]
        
        return flat_synonyms
    
    def expand(self, query: str) -> Set[str]:
        """æ“´å±•æŸ¥è©¢é—œéµå­—"""
        keywords = query.lower().replace(',', ' ').split()
        expanded = set()
        
        for keyword in keywords:
            # åŠ å…¥åŸå§‹é—œéµå­—
            expanded.add(keyword)
            
            # åŠ å…¥åŒç¾©è©
            if keyword in self.synonyms:
                expanded.update(self.synonyms[keyword])
        
        return expanded
    
    def extract_and_expand(self, text: str) -> Dict[str, any]:
        """æå–ä¸¦æ“´å±•é—œéµå­—ï¼Œè¿”å›è©³ç´°è³‡è¨Š"""
        original_keywords = text.lower().replace(',', ' ').split()
        expanded_keywords = self.expand(text)
        
        return {
            "original": original_keywords,
            "expanded": list(expanded_keywords),
            "expansion_count": len(expanded_keywords) - len(original_keywords)
        }

@lru_cache()
def get_keyword_expander():
    return KeywordExpander()
```

### Step 3: å¯¦ä½œ LLM æ¨è–¦ç«¯é»

```python
# api/routers/llm/recommendations.py
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from typing import List, Optional, Dict
from services.supabase_client import get_supabase_client
from services.keyword_expander import get_keyword_expander
import time

router = APIRouter()

class RecommendTagsRequest(BaseModel):
    description: str = Field(..., description="ç”¨æˆ¶çš„åœ–åƒæè¿°")
    max_tags: int = Field(10, ge=1, le=50, description="æœ€å¤šè¿”å›æ¨™ç±¤æ•¸")
    exclude_adult: bool = Field(True, description="æ’é™¤æˆäººå…§å®¹")
    min_popularity: int = Field(100, ge=0, description="æœ€ä½æµè¡Œåº¦")
    balance_categories: bool = Field(True, description="å¹³è¡¡åˆ†é¡")

class TagRecommendation(BaseModel):
    tag: str
    confidence: float
    popularity_tier: str
    post_count: int
    category: str
    subcategory: Optional[str]
    match_reason: str
    usage_context: str
    weight: int
    related_tags: List[str] = []

@router.post("/recommend-tags", response_model=Dict)
async def recommend_tags(request: RecommendTagsRequest):
    """
    ğŸ¤– LLM å°ˆç”¨çš„æ™ºèƒ½æ¨™ç±¤æ¨è–¦
    
    æ ¹æ“šè‡ªç„¶èªè¨€æè¿°ï¼Œæ¨è–¦æœ€é©åˆçš„æ¨™ç±¤çµ„åˆã€‚
    åŒ…å«è©³ç´°çš„è§£é‡‹å’Œä½¿ç”¨å»ºè­°ï¼Œé©åˆ LLM ç›´æ¥ä½¿ç”¨ã€‚
    """
    start_time = time.time()
    
    try:
        # 1. é—œéµå­—æå–å’Œæ“´å±•
        expander = get_keyword_expander()
        keyword_info = expander.extract_and_expand(request.description)
        expanded_keywords = keyword_info["expanded"]
        
        # 2. æ§‹å»ºè³‡æ–™åº«æŸ¥è©¢
        client = get_supabase_client()
        
        # ä½¿ç”¨ OR æŸ¥è©¢åŒ¹é…å¤šå€‹é—œéµå­—
        or_conditions = []
        for keyword in expanded_keywords:
            or_conditions.append(f"name.ilike.%{keyword}%")
        
        query = client.table('tags_final').select('*')
        
        # åŸºæœ¬ç¯©é¸
        if request.exclude_adult:
            query = query.neq('main_category', 'ADULT_CONTENT')
        if request.min_popularity > 0:
            query = query.gte('post_count', request.min_popularity)
        
        # é—œéµå­—åŒ¹é…ï¼ˆä½¿ç”¨ ORï¼‰
        if or_conditions:
            query = query.or_(','.join(or_conditions[:10]))  # é™åˆ¶æ¢ä»¶æ•¸é‡
        
        # åŸ·è¡ŒæŸ¥è©¢
        response = query.order('post_count', desc=True).limit(request.max_tags * 3).execute()
        
        if not response.data:
            return {
                "query": request.description,
                "recommended_tags": [],
                "category_distribution": {},
                "quality_assessment": {
                    "overall_score": 0,
                    "warnings": ["æœªæ‰¾åˆ°åŒ¹é…çš„æ¨™ç±¤ï¼Œè«‹å˜—è©¦æ›´å…·é«”çš„æè¿°"]
                },
                "metadata": {
                    "processing_time_ms": (time.time() - start_time) * 1000,
                    "total_candidates": 0
                }
            }
        
        # 3. æ™ºèƒ½æ’åºå’Œç¯©é¸
        recommendations = []
        category_counts = {}
        
        for tag_data in response.data[:request.max_tags * 2]:
            # è¨ˆç®—ç›¸é—œæ€§åˆ†æ•¸
            relevance_score = calculate_relevance(
                tag_data['name'], 
                expanded_keywords, 
                keyword_info["original"]
            )
            
            # è¨ˆç®—æµè¡Œåº¦ç­‰ç´š
            popularity_tier = get_popularity_tier(tag_data['post_count'])
            
            # ç”Ÿæˆè§£é‡‹
            match_reason = generate_match_reason(
                tag_data['name'],
                expanded_keywords,
                keyword_info["original"]
            )
            
            # ç”Ÿæˆä½¿ç”¨å»ºè­°
            usage_context = generate_usage_context(tag_data['main_category'])
            
            rec = TagRecommendation(
                tag=tag_data['name'],
                confidence=relevance_score,
                popularity_tier=popularity_tier,
                post_count=tag_data['post_count'],
                category=tag_data['main_category'] or 'UNKNOWN',
                subcategory=tag_data.get('sub_category'),
                match_reason=match_reason,
                usage_context=usage_context,
                weight=int(relevance_score * 10),
                related_tags=[]  # æœªä¾†å¯ä»¥æ·»åŠ 
            )
            
            recommendations.append(rec)
            
            # çµ±è¨ˆåˆ†é¡
            category = tag_data['main_category'] or 'UNKNOWN'
            category_counts[category] = category_counts.get(category, 0) + 1
        
        # 4. åˆ†é¡å¹³è¡¡ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        if request.balance_categories:
            recommendations = balance_by_category(recommendations, request.max_tags)
        else:
            recommendations = recommendations[:request.max_tags]
        
        # 5. å“è³ªè©•ä¼°
        quality = assess_quality(recommendations, category_counts)
        
        # 6. ç”Ÿæˆå»ºè­°çš„ prompt
        suggested_prompt = ", ".join([r.tag for r in recommendations])
        
        processing_time = (time.time() - start_time) * 1000
        
        return {
            "query": request.description,
            "recommended_tags": [r.dict() for r in recommendations],
            "category_distribution": category_counts,
            "quality_assessment": quality,
            "suggested_prompt": suggested_prompt,
            "metadata": {
                "processing_time_ms": processing_time,
                "total_candidates": len(response.data),
                "algorithm": "keyword_matching_v1",
                "cache_hit": False,
                "keywords_extracted": keyword_info["original"],
                "keywords_expanded": list(expanded_keywords)
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# è¼”åŠ©å‡½æ•¸
def calculate_relevance(tag_name: str, expanded_keywords: Set[str], original_keywords: List[str]) -> float:
    """è¨ˆç®—ç›¸é—œæ€§åˆ†æ•¸"""
    # å®Œå…¨åŒ¹é…åŸå§‹é—œéµå­—
    if tag_name in original_keywords:
        return 1.0
    
    # å‰ç¶´åŒ¹é…åŸå§‹é—œéµå­—
    for keyword in original_keywords:
        if tag_name.startswith(keyword):
            return 0.9
    
    # åŒ…å«åŸå§‹é—œéµå­—
    for keyword in original_keywords:
        if keyword in tag_name:
            return 0.8
    
    # åŒ¹é…æ“´å±•é—œéµå­—
    for keyword in expanded_keywords:
        if keyword in tag_name or tag_name in keyword:
            return 0.7
    
    return 0.5

def get_popularity_tier(post_count: int) -> str:
    """ç²å–æµè¡Œåº¦ç­‰ç´š"""
    if post_count > 100000:
        return "very_popular"
    elif post_count > 10000:
        return "popular"
    elif post_count > 1000:
        return "moderate"
    else:
        return "niche"

def generate_match_reason(tag_name: str, expanded: Set[str], original: List[str]) -> str:
    """ç”ŸæˆåŒ¹é…åŸå› """
    # æª¢æŸ¥æ˜¯å¦åŒ¹é…åŸå§‹é—œéµå­—
    for keyword in original:
        if keyword in tag_name:
            return f"ç›´æ¥åŒ¹é…é—œéµå­— '{keyword}'"
    
    # æª¢æŸ¥æ˜¯å¦ç‚ºåŒç¾©è©æ“´å±•
    for keyword in original:
        for exp in expanded:
            if exp in tag_name and exp != keyword:
                return f"é€šéåŒç¾©è©æ“´å±•: '{keyword}' â†’ '{exp}'"
    
    return "ç›¸é—œæ¨™ç±¤"

def generate_usage_context(category: str) -> str:
    """ç”Ÿæˆä½¿ç”¨å»ºè­°"""
    contexts = {
        'CHARACTER': 'è§’è‰²æ ¸å¿ƒæ¨™ç±¤ï¼Œå½±éŸ¿äººç‰©åŸºæœ¬ç‰¹å¾µå’Œæ•¸é‡',
        'CHARACTER_RELATED': 'è§’è‰²ç›¸é—œæ¨™ç±¤ï¼Œæè¿°å¤–è§€ã€æœè£ã€ç‰¹å¾µç­‰ç´°ç¯€',
        'ACTION_POSE': 'å‹•ä½œå§¿æ…‹æ¨™ç±¤ï¼Œå½±éŸ¿äººç‰©çš„å‹•ä½œå’Œè¡¨æƒ…',
        'ENVIRONMENT': 'ç’°å¢ƒæ¨™ç±¤ï¼Œè¨­å®šå ´æ™¯èƒŒæ™¯ã€æ™‚é–“ã€åœ°é»',
        'ART_STYLE': 'è—è¡“é¢¨æ ¼æ¨™ç±¤ï¼Œå½±éŸ¿æ•´é«”ç•«é¢¨å’Œè¦–è¦ºå‘ˆç¾',
        'OBJECTS': 'ç‰©ä»¶æ¨™ç±¤ï¼Œæ·»åŠ å ´æ™¯ä¸­çš„ç‰©å“å’Œé“å…·',
        'ARTIST': 'è—è¡“å®¶æ¨™ç±¤ï¼Œæ¨¡ä»¿ç‰¹å®šè—è¡“å®¶çš„é¢¨æ ¼',
        'COPYRIGHT': 'ç‰ˆæ¬Šæ¨™ç±¤ï¼ŒæŒ‡å®šç‰¹å®šä½œå“æˆ–ç³»åˆ—',
        'QUALITY': 'å“è³ªæ¨™ç±¤ï¼Œæ§åˆ¶åœ–åƒçš„è§£æåº¦å’Œå“è³ª',
        'TECHNICAL': 'æŠ€è¡“æ¨™ç±¤ï¼Œæ§åˆ¶ç”Ÿæˆåƒæ•¸',
        'THEME_CONCEPT': 'ä¸»é¡Œæ¦‚å¿µæ¨™ç±¤ï¼Œè¨­å®šæ•´é«”æ°›åœå’Œä¸»é¡Œ',
        'VISUAL_EFFECTS': 'è¦–è¦ºæ•ˆæœæ¨™ç±¤ï¼Œæ·»åŠ ç‰¹æ®Šæ•ˆæœ'
    }
    return contexts.get(category, 'é€šç”¨æ¨™ç±¤')

def balance_by_category(recommendations: List[TagRecommendation], max_tags: int) -> List[TagRecommendation]:
    """å¹³è¡¡åˆ†é¡åˆ†ä½ˆ"""
    # ç°¡å–®çš„å¹³è¡¡ç­–ç•¥ï¼šæ¯å€‹åˆ†é¡æœ€å¤šå– max_tags/3
    category_limits = {}
    max_per_category = max(3, max_tags // 3)
    
    balanced = []
    for rec in recommendations:
        category = rec.category
        current_count = category_limits.get(category, 0)
        
        if current_count < max_per_category:
            balanced.append(rec)
            category_limits[category] = current_count + 1
        
        if len(balanced) >= max_tags:
            break
    
    return balanced

def assess_quality(recommendations: List[TagRecommendation], category_counts: Dict[str, int]) -> Dict:
    """è©•ä¼°æ¨è–¦å“è³ª"""
    if not recommendations:
        return {
            "overall_score": 0,
            "balance_score": 0,
            "popularity_score": 0,
            "warnings": ["ç„¡æ¨è–¦çµæœ"]
        }
    
    # è¨ˆç®—å¹³å‡æµè¡Œåº¦
    avg_popularity = sum(r.post_count for r in recommendations) / len(recommendations)
    popularity_score = min(100, int((avg_popularity / 10000) * 50) + 50)
    
    # è¨ˆç®—åˆ†é¡å¹³è¡¡
    num_categories = len(category_counts)
    balance_score = min(100, num_categories * 25)
    
    # æ•´é«”åˆ†æ•¸
    overall_score = int((popularity_score + balance_score) / 2)
    
    warnings = []
    if num_categories < 2:
        warnings.append("å»ºè­°æ·»åŠ æ›´å¤šåˆ†é¡çš„æ¨™ç±¤ä»¥è±å¯Œç•«é¢")
    if popularity_score < 50:
        warnings.append("éƒ¨åˆ†æ¨™ç±¤æµè¡Œåº¦è¼ƒä½ï¼Œå¯èƒ½å½±éŸ¿ç”Ÿåœ–å“è³ª")
    
    return {
        "overall_score": overall_score,
        "balance_score": balance_score,
        "popularity_score": popularity_score,
        "warnings": warnings
    }
```

### Step 7: åŸ·è¡Œå’Œæ¸¬è©¦

```bash
# å•Ÿå‹• API
uvicorn main:app --reload

# æ¸¬è©¦ LLM ç«¯é»
curl -X POST http://localhost:8000/api/llm/recommend-tags \
  -H "Content-Type: application/json" \
  -d '{
    "description": "a lonely girl in cyberpunk city at night",
    "max_tags": 8,
    "exclude_adult": true
  }'
```

---

## ğŸ“Š é æœŸçµæœ

### æˆåŠŸæŒ‡æ¨™

- âœ… API éŸ¿æ‡‰æ™‚é–“ < 500ms
- âœ… é—œéµå­—æ“´å±•æº–ç¢ºç‡ > 80%
- âœ… LLM æ¨è–¦ç›¸é—œæ€§ > 85%
- âœ… æ‰€æœ‰ç«¯é»æ¸¬è©¦é€šé

### äº¤ä»˜ç‰©

**Week 1**:
- âœ… FastAPI å°ˆæ¡ˆçµæ§‹
- âœ… 3-4 å€‹åŸºç¤ç«¯é»
- âœ… Supabase æ•´åˆ
- âœ… åŸºæœ¬æ¸¬è©¦

**Week 2**:
- âœ… LLM æ¨è–¦ç«¯é»
- âœ… å“è³ªé©—è­‰ç«¯é»
- âœ… é—œéµå­—æ“´å±•ç³»çµ±
- âœ… å®Œæ•´æ–‡æª”

---

## ğŸ¯ ä¸‹ä¸€æ­¥è¡Œå‹•

1. **ç«‹å³é–‹å§‹**: å»ºç«‹ FastAPI å°ˆæ¡ˆçµæ§‹
2. **ä»Šå¤©å®Œæˆ**: å¯¦ä½œåŸºç¤ç«¯é»ä¸¦æ¸¬è©¦ Supabase é€£æ¥
3. **æ˜å¤©å®Œæˆ**: å¯¦ä½œé—œéµå­—æ“´å±•ç³»çµ±
4. **æœ¬é€±æœ«**: å®Œæˆç¬¬ä¸€å€‹ LLM æ¨è–¦ç«¯é»

**æº–å‚™å¥½é–‹å§‹äº†å—ï¼Ÿåˆ‡æ›åˆ° Agent æ¨¡å¼ï¼Œæˆ‘å€‘é–‹å§‹å¯¦ä½œï¼** ğŸš€
