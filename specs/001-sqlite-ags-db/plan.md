# 開發計畫：SQLite 資料遷移至 Supabase

**計畫編號 (Plan ID):** PLAN-2025-004

**版本 (Version):** 1.0.0

**狀態 (Status):** Planning

**計畫負責人 (Owner):** 專案團隊

**建立日期 (Created):** 2025-10-14

**最後更新 (Last Updated):** 2025-10-14

**預計開始 (Start Date):** 2025-10-15

**預計完成 (Target Date):** 2025-10-23

**對應規格 (Related Spec):** [SPEC-2025-002: SQLite 資料遷移至 Supabase](./spec.md)

---

## 憲法符合性檢查 (Constitution Compliance Check)

- [x] 計畫遵循「兩階段混合式架構」（明確區分階段一與階段二的工作）
  - ✅ 本計畫明確屬於**階段二**工作
  - ✅ 以階段一產出的 `tags.db` 作為輸入
  - ✅ 不修改階段一的任何邏輯或資料
  
- [x] 計畫遵循「LLM 職責分離」（若涉及 AI 功能，已正確分配職責）
  - ✅ 使用**資料層 LLM**（OpenAI Embeddings API）生成向量
  - ✅ 所有 LLM 呼叫都記錄至 `migration_log` 表
  - ✅ 不使用 IDE LLM 處理生產資料
  
- [x] 計畫遵循「規格驅動開發」（所有開發任務基於已審核的規格）
  - ✅ 所有任務來自 SPEC-2025-002 的需求
  - ✅ 驗收標準與規格一致
  
- [x] 計畫遵循「資料優先」（資料相關任務優先於功能開發）
  - ✅ 資料遷移與驗證是最高優先級（Priority 1）
  - ✅ 在確保資料完整性後才進行功能開發
  
- [x] 計畫考慮「模組化與可讀性」（任務劃分清晰、職責明確）
  - ✅ 任務按功能模組劃分（環境、資料庫、遷移、向量、API、驗證）
  - ✅ 每個任務有明確的輸入、輸出和驗收標準

---

## 1. 計畫概述 (Overview)

### 1.1 目標 (Objectives)

**主要目標：**

1. **完整資料遷移**：將 140,782 個標籤從 SQLite 完整遷移至 Supabase PostgreSQL，確保 100% 資料完整性
2. **啟用語意搜尋**：為所有標籤生成向量嵌入（≥99% 覆蓋率），支援語意搜尋功能
3. **建立 API 服務**：提供基本的 REST API 端點，支援查詢、篩選和統計功能
4. **確保系統穩定**：建立完整的驗證、監控和錯誤處理機制

**成功指標 (Success Metrics):**

| 指標類別 | 指標 | 目標值 | 測量方式 |
|---------|------|--------|----------|
| 資料品質 | 資料完整性 | 100% | 遷移前後記錄數比對 |
| 資料品質 | 資料正確性 | 100% | 抽樣 100 筆逐欄位比對 |
| 功能可用性 | 向量生成率 | ≥ 99% | 成功生成向量的標籤比例 |
| 功能可用性 | API 可用性 | 100% | 10 種查詢模式測試通過率 |
| 效能 | 遷移時間 | < 30 分鐘 | 從開始到完成的總時間 |
| 效能 | API 回應時間 | < 2 秒 (P95) | 100 次查詢的 95 百分位數 |
| 成本 | 向量生成成本 | < $10 USD | OpenAI API 費用統計 |

### 1.2 背景與動機 (Background and Motivation)

**背景：**

階段一已成功完成，產出了高品質的 `tags.db`：
- 140,782 個標籤
- 96.56% 分類覆蓋率
- 平均信心度 0.872
- 完整的分類資訊（主分類、副分類）

**動機：**

1. **可存取性需求**：本地 SQLite 限制了資料的網路存取能力
2. **協作需求**：需要支援多使用者同時存取
3. **進階功能需求**：語意搜尋需要向量化技術
4. **可擴展性需求**：為未來的 Web 應用和 API 服務做準備

**問題陳述：**

目前的 SQLite 資料庫是單機檔案，無法直接提供網路服務。需要將其遷移至雲端平台，同時保持資料完整性並增加新功能。

### 1.3 範圍 (Scope)

**包含 (In Scope):**

- ✅ 完整遷移 `tags_final` 表及所有相關資料
- ✅ 建立 Supabase 資料庫結構（表、索引、RLS 策略）
- ✅ 生成向量嵌入並儲存至 `tag_embeddings` 表
- ✅ 實作基本查詢 API（按名稱、分類、頻率）
- ✅ 實作語意搜尋 API（向量相似度搜尋）
- ✅ 建立完整的資料驗證流程
- ✅ 撰寫遷移工具和腳本
- ✅ 生成 API 文件和使用指南
- ✅ 建立監控和日誌系統

**不包含 (Out of Scope):**

- ❌ 前端使用者介面開發
- ❌ 使用者帳號管理系統
- ❌ 即時協作功能
- ❌ 資料的持續同步機制（單向遷移）
- ❌ 本地 SQLite 資料庫的修改或刪除
- ❌ 第三方服務整合（除 OpenAI Embeddings）
- ❌ 多語言支援
- ❌ 進階分析功能

---

## 2. 架構分階段規劃 (Architecture-Stage Planning)

### 2.1 階段一：本地資料管線工作 (Stage 1: Local Data Pipeline)

**狀態：** ✅ **已完成**

**已完成的產出物：**
- ✅ `tags.db`（315 MB，140,782 個標籤）
- ✅ 分類系統（14 個主分類 + 副分類）
- ✅ 品質報告（96.56% 覆蓋率）
- ✅ 資料驗證工具

**本計畫的相依：**
- 本計畫**完全依賴**階段一的 `tags.db` 作為唯一資料來源
- 不修改階段一的任何邏輯或資料結構

### 2.2 階段二：雲端應用後端工作 (Stage 2: Cloud Application Backend)

**狀態：** 🔄 **本計畫實施中**

**工作項目：**

#### 優先級 1：核心遷移（Week 1）
- [x] 環境準備與設定
- [ ] 資料庫結構建立
- [ ] 資料遷移與驗證
- [ ] 基本 API 設定

#### 優先級 2：功能增強（Week 2）
- [ ] 向量嵌入生成
- [ ] 語意搜尋實作
- [ ] 效能優化

#### 優先級 3：完善與上線（Week 2）
- [ ] 完整測試
- [ ] 文件撰寫
- [ ] 部署與監控

**產出物：**
- Supabase PostgreSQL 資料庫（含所有標籤資料）
- 向量嵌入表（用於語意搜尋）
- REST API 端點（查詢、搜尋、統計）
- 遷移日誌與驗證報告
- API 文件與使用指南

**技術棧：**
- Supabase（PostgreSQL 15 + pgvector 擴展）
- Python 3.11+（遷移工具）
- OpenAI Embeddings API（text-embedding-3-small）
- Supabase Client Library

### 2.3 階段相依性 (Stage Dependencies)

```
階段一：本地資料管線 [已完成]
    ↓
產出：tags.db (140,782 標籤, 96.56% 覆蓋率)
    ↓
階段二：雲端應用後端 [本計畫]
    ├─ 讀取 tags.db
    ├─ 遷移至 Supabase
    ├─ 生成向量嵌入
    └─ 提供 API 服務
```

**關鍵依賴關係：**
1. 階段二**不能**在階段一未完成時開始
2. 階段二**不會**修改階段一的產出（`tags.db` 保持不變）
3. 階段二的所有資料來源於 `tags.db`，確保資料一致性

---

## 3. 規格與實作對應 (Spec-to-Implementation Mapping)

| 規格需求 ID | 需求描述 | 對應任務組 | 負責模組 | 狀態 |
|------------|----------|-----------|---------|------|
| FR-01 | 完整遷移 tags_final 表 | 任務組 B | migration.py | 待開始 |
| FR-02 | 保持分類資訊完整性 | 任務組 B | migration.py | 待開始 |
| FR-03 | 生成向量嵌入 | 任務組 C | embedding.py | 待開始 |
| FR-04 | 提供基本查詢 API | 任務組 D | api_setup.py | 待開始 |
| FR-05 | 提供語意搜尋功能 | 任務組 D | semantic_search.sql | 待開始 |
| FR-06 | 驗證資料完整性 | 任務組 E | validator.py | 待開始 |
| FR-07 | 記錄遷移過程 | 任務組 B | migration_logger.py | 待開始 |
| FR-08 | 支援批次處理 | 任務組 B | batch_processor.py | 待開始 |
| FR-09 | 提供狀態查詢功能 | 任務組 D | status_api.sql | 待開始 |
| FR-10 | 提供回滾機制 | 任務組 F | rollback.py | 待開始 |

| 非功能需求 ID | 需求描述 | 對應任務 | 驗證方式 | 狀態 |
|-------------|----------|---------|---------|------|
| NFR-01 | 遷移時間 < 30 分鐘 | 任務 B2, B3 | 計時測試 | 待開始 |
| NFR-02 | API 回應 < 2 秒 | 任務 D3 | 效能測試 | 待開始 |
| NFR-03 | 語意搜尋 < 3 秒 | 任務 D4 | 效能測試 | 待開始 |
| NFR-04 | 資料完整性 100% | 任務 E1 | 自動驗證 | 待開始 |
| NFR-06 | API 權限控制 | 任務 A3 | RLS 測試 | 待開始 |
| NFR-09 | 向量成本 < $10 | 任務 C1 | 成本監控 | 待開始 |

---

## 4. 任務分解 (Task Breakdown)

### 4.1 階段二任務（完整）

#### 任務組 A：環境準備與設定（Day 1，4 小時）

**任務 A1：Supabase 專案設定**
- **描述**：建立或配置 Supabase 專案，取得必要的憑證
- **預估時間**：1 小時
- **優先級**：High
- **相依任務**：無
- **具體步驟**：
  1. 登入 Supabase Dashboard
  2. 建立新專案或選擇現有專案
  3. 取得 Project URL、Anon Key、Service Role Key
  4. 建立 `.env` 檔案並配置環境變數
- **驗收標準**：
  - ✅ 能透過 Supabase Client 成功連線
  - ✅ 環境變數正確配置
  - ✅ 執行 `check_env.py` 通過所有檢查

**任務 A2：Python 環境與依賴安裝**
- **描述**：設定 Python 環境並安裝所有必要的依賴套件
- **預估時間**：1 小時
- **優先級**：High
- **相依任務**：無
- **具體步驟**：
  1. 確認 Python 3.11+ 已安裝
  2. 建立虛擬環境
  3. 安裝 `requirements.txt` 中的套件
  4. 驗證所有套件正常運作
- **驗收標準**：
  - ✅ 所有依賴套件安裝成功
  - ✅ 能成功 import 所有模組
  - ✅ 執行基本測試腳本通過

**任務 A3：資料庫權限策略設定**
- **描述**：配置 Row-Level Security (RLS) 策略
- **預估時間**：2 小時
- **優先級**：Medium
- **相依任務**：A1（需要專案建立完成）
- **具體步驟**：
  1. 設計 RLS 策略（匿名讀、服務角色寫）
  2. 在 Supabase Dashboard 或 SQL Editor 中執行策略腳本
  3. 測試不同角色的存取權限
- **驗收標準**：
  - ✅ 匿名使用者可讀取 `tags_final`
  - ✅ 匿名使用者無法寫入或刪除
  - ✅ Service Role 有完整權限
  - ✅ `tag_embeddings` 表受保護

---

#### 任務組 B：資料庫結構建立與資料遷移（Day 2，8 小時）

**任務 B1：資料庫 Schema 建立**
- **描述**：在 Supabase 中建立所有必要的表結構、索引和函式
- **預估時間**：2 小時
- **優先級**：High
- **相依任務**：A1
- **交付物**：`schema.sql`
- **具體步驟**：
  1. 建立 `tags_final` 表（含所有欄位和約束）
  2. 建立 `tag_embeddings` 表（含向量欄位）
  3. 建立 `migration_log` 表
  4. 建立所有索引（main_category, post_count, confidence 等）
  5. 啟用 pgvector 擴展
  6. 建立向量索引（ivfflat）
- **驗收標準**：
  - ✅ 所有表成功建立
  - ✅ 索引正確設定
  - ✅ pgvector 擴展已啟用
  - ✅ 能透過 SQL Editor 查詢表結構

**任務 B2：資料讀取與轉換模組**
- **描述**：開發從 SQLite 讀取並轉換資料格式的模組
- **預估時間**：2 小時
- **優先級**：High
- **相依任務**：B1
- **交付物**：`sqlite_reader.py`
- **具體步驟**：
  1. 建立 SQLite 連線
  2. 讀取 `tags_final` 表的所有記錄
  3. 轉換資料型別（符合 PostgreSQL 規範）
  4. 生成唯一 ID（UUID）
  5. 驗證資料完整性
- **驗收標準**：
  - ✅ 能成功讀取所有 140,782 筆記錄
  - ✅ 資料型別轉換正確
  - ✅ 沒有空值或格式錯誤
  - ✅ 處理時間 < 5 分鐘

**任務 B3：批次上傳模組**
- **描述**：開發批次上傳資料至 Supabase 的模組，支援斷點續傳
- **預估時間**：3 小時
- **優先級**：High
- **相依任務**：B2
- **交付物**：`batch_uploader.py`
- **具體步驟**：
  1. 設計批次大小（建議 500 筆/批次）
  2. 實作批次上傳邏輯
  3. 實作錯誤處理與重試機制（最多 3 次）
  4. 實作檢查點機制（記錄已上傳的批次）
  5. 實作進度顯示（tqdm 進度條）
  6. 記錄每個批次的上傳結果
- **驗收標準**：
  - ✅ 所有資料成功上傳
  - ✅ 上傳時間 < 20 分鐘
  - ✅ 支援中斷後繼續上傳
  - ✅ 所有操作都記錄至 `migration_log`

**任務 B4：遷移日誌系統**
- **描述**：實作完整的遷移過程日誌記錄
- **預估時間**：1 小時
- **優先級**：Medium
- **相依任務**：B1
- **交付物**：`migration_logger.py`
- **具體步驟**：
  1. 設計日誌格式（包含時間戳、操作、狀態、錯誤訊息）
  2. 實作日誌寫入函式
  3. 整合至所有遷移步驟
  4. 實作日誌查詢介面
- **驗收標準**：
  - ✅ 所有關鍵步驟都有日誌
  - ✅ 日誌包含時間戳和詳細資訊
  - ✅ 錯誤訊息清楚記錄
  - ✅ 能透過查詢了解遷移狀態

---

#### 任務組 C：向量嵌入生成（Day 3-4，8 小時）

**任務 C1：向量生成模組**
- **描述**：使用 OpenAI Embeddings API 生成標籤的向量嵌入
- **預估時間**：4 小時
- **優先級**：High
- **相依任務**：B3（資料遷移完成）
- **交付物**：`embedding_generator.py`
- **具體步驟**：
  1. 設定 OpenAI API 客戶端
  2. 設計批次大小（建議 1000 個標籤/批次）
  3. 實作批次呼叫 Embeddings API
  4. 實作速率限制控制（避免超過配額）
  5. 實作錯誤處理與重試
  6. 實作成本監控
  7. 儲存向量至 `tag_embeddings` 表
- **驗收標準**：
  - ✅ ≥ 99% 的標籤成功生成向量
  - ✅ 向量維度為 1536
  - ✅ 總成本 < $10 USD
  - ✅ 處理時間 < 2 小時
  - ✅ 所有 API 呼叫都記錄

**任務 C2：向量索引優化**
- **描述**：建立和優化向量相似度搜尋的索引
- **預估時間**：2 小時
- **優先級**：Medium
- **相依任務**：C1
- **交付物**：`vector_index.sql`
- **具體步驟**：
  1. 建立 ivfflat 索引
  2. 調整索引參數（lists 數量）
  3. 測試索引效能
  4. 優化查詢計畫
- **驗收標準**：
  - ✅ 向量搜尋速度 < 1 秒（1000 維搜尋）
  - ✅ 索引建立成功
  - ✅ 查詢使用索引（EXPLAIN 驗證）

**任務 C3：向量品質驗證**
- **描述**：驗證生成的向量嵌入品質
- **預估時間**：2 小時
- **優先級**：Low
- **相依任務**：C1
- **交付物**：`embedding_validator.py`
- **具體步驟**：
  1. 抽樣測試 100 個向量
  2. 驗證向量維度和數值範圍
  3. 測試語意相似度（例如 "school_uniform" 與 "student" 的相似度）
  4. 生成品質報告
- **驗收標準**：
  - ✅ 所有向量維度正確
  - ✅ 語意相似度測試通過（相關標籤相似度 > 0.7）
  - ✅ 無異常向量（全為 0 或 NaN）

---

#### 任務組 D：API 設定與功能實作（Day 4-5，6 小時）

**任務 D1：基本查詢 API 設定**
- **描述**：配置 Supabase REST API 端點
- **預估時間**：1 小時
- **優先級**：High
- **相依任務**：B3
- **交付物**：API 配置文件
- **具體步驟**：
  1. 驗證 `tags_final` 表的 REST API 自動生成
  2. 測試基本 CRUD 操作
  3. 配置 API 權限（僅允許 GET）
  4. 測試篩選和排序功能
- **驗收標準**：
  - ✅ 能透過 REST API 查詢標籤
  - ✅ 支援按 name、category、post_count 篩選
  - ✅ 支援分頁（limit, offset）
  - ✅ 回應時間 < 1 秒

**任務 D2：統計資訊 RPC 函式**
- **描述**：建立統計資訊的 PostgreSQL 函式
- **預估時間**：2 小時
- **優先級**：Medium
- **相依任務**：B3
- **交付物**：`statistics_functions.sql`
- **具體步驟**：
  1. 建立 `get_category_statistics()` 函式
  2. 建立 `get_coverage_stats()` 函式
  3. 建立 `get_top_tags()` 函式
  4. 測試所有函式
- **驗收標準**：
  - ✅ 所有函式返回正確結果
  - ✅ 執行時間 < 2 秒
  - ✅ 結果格式符合規格

**任務 D3：語意搜尋 RPC 函式**
- **描述**：建立向量相似度搜尋的 PostgreSQL 函式
- **預估時間**：2 小時
- **優先級**：High
- **相依任務**：C1, C2
- **交付物**：`semantic_search.sql`
- **具體步驟**：
  1. 建立 `search_similar_tags()` 函式
  2. 支援相似度閾值參數
  3. 支援結果數量限制
  4. 支援分類篩選
  5. 測試搜尋準確度
- **驗收標準**：
  - ✅ 能根據文字查詢返回相關標籤
  - ✅ 回應時間 < 3 秒（P95）
  - ✅ 結果按相似度排序
  - ✅ 測試案例通過率 ≥ 80%

**任務 D4：API 文件生成**
- **描述**：撰寫完整的 API 使用文件
- **預估時間**：1 小時
- **優先級**：Medium
- **相依任務**：D1, D2, D3
- **交付物**：`API_DOCUMENTATION.md`
- **具體步驟**：
  1. 記錄所有 API 端點
  2. 提供請求/回應範例
  3. 說明參數和錯誤碼
  4. 提供使用範例（curl, JavaScript）
- **驗收標準**：
  - ✅ 所有端點都有文件
  - ✅ 包含實際可執行的範例
  - ✅ 錯誤處理說明清楚

---

#### 任務組 E：驗證與測試（Day 5-6，8 小時）

**任務 E1：資料完整性驗證**
- **描述**：全面驗證遷移後的資料完整性
- **預估時間**：3 小時
- **優先級**：High
- **相依任務**：B3
- **交付物**：`integrity_validator.py`、驗證報告
- **具體步驟**：
  1. 比對記錄總數（本地 vs 雲端）
  2. 抽樣檢查 100 筆資料的所有欄位
  3. 驗證統計資訊一致性（分類分佈）
  4. 檢查是否有孤立的向量
  5. 生成驗證報告
- **驗收標準**：
  - ✅ 記錄數完全一致（140,782）
  - ✅ 抽樣檢查 100% 相符
  - ✅ 統計分佈一致
  - ✅ 無孤立向量
  - ✅ 生成詳細報告

**任務 E2：API 功能測試**
- **描述**：測試所有 API 端點的功能正確性
- **預估時間**：2 小時
- **優先級**：High
- **相依任務**：D1, D2, D3
- **交付物**：`api_tests.py`、測試報告
- **具體步驟**：
  1. 測試基本查詢（10 種模式）
  2. 測試語意搜尋（20 個測試案例）
  3. 測試統計函式
  4. 測試邊界條件
  5. 測試錯誤處理
- **驗收標準**：
  - ✅ 所有功能測試通過
  - ✅ 測試覆蓋率 ≥ 80%
  - ✅ 生成測試報告

**任務 E3：效能測試**
- **描述**：測試系統的效能指標
- **預估時間**：2 小時
- **優先級**：Medium
- **相依任務**：D1, D3
- **交付物**：`performance_tests.py`、效能報告
- **具體步驟**：
  1. 測試 API 回應時間（100 次查詢）
  2. 測試語意搜尋延遲（50 次搜尋）
  3. 測試並發處理（10 個並發請求）
  4. 分析 P50, P95, P99 延遲
  5. 生成效能報告
- **驗收標準**：
  - ✅ API 回應 P95 < 2 秒
  - ✅ 語意搜尋 P95 < 3 秒
  - ✅ 並發請求全部成功
  - ✅ 生成效能分析報告

**任務 E4：安全性測試**
- **描述**：驗證 API 的安全性設定
- **預估時間**：1 小時
- **優先級**：Medium
- **相依任務**：A3, D1
- **交付物**：安全測試報告
- **具體步驟**：
  1. 測試匿名使用者權限
  2. 測試 RLS 策略
  3. 測試 SQL 注入防護
  4. 測試速率限制
- **驗收標準**：
  - ✅ 匿名使用者無法寫入
  - ✅ RLS 策略正確執行
  - ✅ 無安全漏洞

---

#### 任務組 F：文件與部署（Day 6，4 小時）

**任務 F1：操作手冊撰寫**
- **描述**：撰寫完整的遷移操作手冊
- **預估時間**：2 小時
- **優先級**：High
- **相依任務**：所有實作任務完成
- **交付物**：`MIGRATION_GUIDE.md`
- **具體步驟**：
  1. 記錄完整的遷移步驟
  2. 提供環境配置說明
  3. 列出常見問題與解決方案
  4. 提供檢查清單
- **驗收標準**：
  - ✅ 操作步驟清楚明確
  - ✅ 包含所有必要資訊
  - ✅ 有故障排除章節

**任務 F2：故障排除指南**
- **描述**：整理常見問題和解決方案
- **預估時間**：1 小時
- **優先級**：Medium
- **相依任務**：測試任務完成
- **交付物**：`TROUBLESHOOTING.md`
- **具體步驟**：
  1. 收集測試過程中遇到的問題
  2. 記錄解決方案
  3. 組織成FAQ格式
- **驗收標準**：
  - ✅ 涵蓋至少 10 個常見問題
  - ✅ 每個問題都有明確的解決步驟

**任務 F3：最終驗收與上線**
- **描述**：執行最終驗收檢查並正式上線
- **預估時間**：1 小時
- **優先級**：High
- **相依任務**：所有任務完成
- **交付物**：上線檢查清單、完成報告
- **具體步驟**：
  1. 執行完整的驗收檢查清單
  2. 確認所有測試通過
  3. 確認所有文件完成
  4. 標記專案為生產就緒
  5. 生成最終完成報告
- **驗收標準**：
  - ✅ 所有驗收項目通過
  - ✅ 系統穩定運行
  - ✅ 文件齊全

---

## 5. 時程規劃 (Timeline)

### 5.1 里程碑 (Milestones)

| 里程碑 | 日期 | 交付物 | 關鍵指標 | 狀態 |
|--------|------|--------|---------|------|
| **M1: 環境就緒** | 2025-10-15 | Supabase 專案、Python 環境 | 連線測試通過 | 未開始 |
| **M2: 資料結構就緒** | 2025-10-16 | 資料庫 Schema、索引、RLS | 表結構驗證通過 | 未開始 |
| **M3: 資料遷移完成** | 2025-10-17 | 140,782 筆資料、遷移日誌 | 資料完整性 100% | 未開始 |
| **M4: 功能完整** | 2025-10-19 | 向量嵌入、API 端點 | API 測試通過、向量生成率 ≥99% | 未開始 |
| **M5: 測試完成** | 2025-10-21 | 測試報告、效能報告 | 所有測試通過 | 未開始 |
| **M6: 上線就緒** | 2025-10-23 | 完整文件、系統穩定 | 驗收標準全部達成 | 未開始 |

### 5.2 甘特圖 (Gantt Chart)

```
任務組        | Day 1 | Day 2 | Day 3 | Day 4 | Day 5 | Day 6 |
-------------|-------|-------|-------|-------|-------|-------|
A: 環境設定   | ████  |       |       |       |       |       |
B: 資料遷移   |       | █████ |       |       |       |       |
C: 向量生成   |       |       | █████ | ███   |       |       |
D: API 設定   |       |       |       | ████  | ███   |       |
E: 驗證測試   |       |       |       |       | █████ | ███   |
F: 文件部署   |       |       |       |       |       | █████ |
```

### 5.3 關鍵路徑 (Critical Path)

```
A1 → A2 → B1 → B2 → B3 → C1 → D3 → E1 → E2 → F3
```

**關鍵任務（影響整體時程）：**
1. B3：批次上傳模組（3 小時）
2. C1：向量生成模組（4 小時）
3. E1：資料完整性驗證（3 小時）

---

## 6. 資源規劃 (Resource Planning)

### 6.1 人力資源

| 角色 | 人員數 | 分配時間 | 主要任務 |
|------|--------|----------|----------|
| 全棧開發者 | 1 | 100% | 遷移工具開發、API 設定、測試 |
| 資料工程師 | 0.5 | 50% | 資料驗證、向量品質檢查 |
| DevOps 工程師 | 0.3 | 30% | Supabase 配置、監控設定 |

**總人力：** 1.8 FTE × 6 天 = 10.8 人天

### 6.2 技術資源

**開發環境：**
- Python 3.11+ 開發環境
- Supabase CLI（選用）
- Git 版本控制
- VS Code / Cursor IDE

**雲端資源：**
- Supabase 計畫：Free Tier（可升級至 Pro $25/月）
- 資料庫儲存：需要約 500 MB（Free Tier 提供 500 MB）
- API 請求：預估 < 10,000 次/月（Free Tier 提供 500,000 次/月）

**第三方服務：**
- OpenAI API：Embeddings API
  - 模型：text-embedding-3-small
  - 預估 Token：約 140,782 × 5 tokens = 703,910 tokens
  - 定價：$0.02 / 1M tokens
  - 預估成本：約 $0.01

### 6.3 預算 (Budget)

| 項目 | 預估成本 | 說明 | 備註 |
|------|----------|------|------|
| Supabase Free Tier | $0 | 免費方案（500 MB 儲存） | 足夠本專案使用 |
| OpenAI Embeddings API | $1.50 | 140,782 個標籤向量化 | 使用 text-embedding-3-small |
| 備用預算 | $8.50 | 處理失敗重試、測試 | 確保不超過 $10 限制 |
| **總計** | **$10.00** | | **符合預算要求** |

**成本控制措施：**
1. 使用最便宜的嵌入模型（text-embedding-3-small）
2. 批次呼叫 API 減少請求次數
3. 實作成本監控，接近限額時停止
4. 失敗項目單獨處理，避免重複呼叫

---

## 7. 風險管理 (Risk Management)

| 風險 | 可能性 | 影響 | 緩解策略 | 負責人 |
|------|--------|------|----------|--------|
| **API 速率限制導致向量生成失敗** | Medium | Medium | 1. 實作速率限制控制<br>2. 分批處理，間隔休息<br>3. 失敗標籤單獨重試 | 開發者 |
| **大量資料上傳超時** | Medium | High | 1. 批次大小設為 500 筆<br>2. 實作檢查點機制<br>3. 支援斷點續傳 | 開發者 |
| **資料格式不相容** | Low | High | 1. 遷移前執行完整驗證<br>2. 提供資料清理工具<br>3. 詳細的錯誤記錄 | 資料工程師 |
| **向量生成成本超出預算** | Low | Medium | 1. 預先計算成本<br>2. 設定預算上限<br>3. 實時成本監控 | 開發者 |
| **網路不穩定導致上傳失敗** | Medium | Medium | 1. 自動重試機制（最多 3 次）<br>2. 記錄失敗項目<br>3. 提供手動補救工具 | 開發者 |
| **Supabase 服務中斷** | Low | High | 1. 選擇低峰時段遷移<br>2. 保留本地 tags.db 備份<br>3. 監控 Supabase 狀態頁 | DevOps |
| **效能未達標** | Low | Medium | 1. 優化索引設定<br>2. 調整批次大小<br>3. 使用查詢緩存 | 開發者 |
| **向量搜尋準確度不足** | Medium | Medium | 1. 測試不同的嵌入模型<br>2. 調整相似度閾值<br>3. 人工驗證測試集 | 資料工程師 |

**風險監控機制：**
- 每日檢查風險狀態
- 發現高影響風險立即報告
- 每個里程碑後進行風險回顧

---

## 8. 品質保證 (Quality Assurance)

### 8.1 測試計畫

**單元測試：**
- 目標覆蓋率：≥ 80%
- 測試範圍：
  - 資料讀取模組
  - 資料轉換模組
  - 批次處理邏輯
  - 驗證函式
  - 錯誤處理
- 工具：pytest
- 執行頻率：每次程式碼提交

**整合測試：**
- 測試範圍：
  - SQLite → Supabase 完整遷移流程
  - API 端點與資料庫互動
  - 向量生成與儲存流程
  - 語意搜尋端到端流程
- 執行頻率：每日構建

**效能測試：**
- 基準指標：
  - 遷移速度：≥ 4,500 筆/分鐘
  - API 延遲：P95 < 2 秒
  - 語意搜尋：P95 < 3 秒
  - 記憶體使用：< 2 GB
- 工具：自訂效能測試腳本
- 執行時機：M4 里程碑後

**驗收測試：**
- 測試場景：
  1. 完整遷移流程（從頭到尾）
  2. 所有 API 端點功能測試
  3. 語意搜尋準確度測試（20 個案例）
  4. 資料完整性驗證
  5. 安全性測試
- 執行時機：M5 里程碑
- 通過標準：100% 測試通過

### 8.2 Code Review 流程

**審查原則：**
1. 所有程式碼必須經過審查才能合併
2. 審查重點：
   - ✅ 憲法符合性（特別是資料優先原則）
   - ✅ 程式碼品質（可讀性、模組化）
   - ✅ 測試完整性（覆蓋率 ≥ 80%）
   - ✅ 錯誤處理（所有異常情況）
   - ✅ 文件完整性（docstring）

**審查流程：**
1. 開發者提交 Pull Request
2. 自動化測試執行（CI）
3. 審查者進行 Code Review
4. 根據反饋修改
5. 批准後合併

### 8.3 文件要求

- [x] 程式碼註解完整（docstring）
  - 所有公開函式必須有 docstring
  - 複雜邏輯必須有註解說明
  
- [x] API 文件已撰寫
  - 所有端點都有完整說明
  - 包含請求/回應範例
  
- [x] 使用者指南已撰寫
  - 遷移操作手冊
  - API 使用指南
  - 故障排除指南
  
- [x] 技術決策記錄（ADR）已更新
  - 記錄關鍵技術決策（例如選擇 text-embedding-3-small）
  - 說明決策理由和替代方案

---

## 9. 溝通計畫 (Communication Plan)

### 9.1 例會

**每日同步（Daily Standup）：**
- 時間：每天上午 10:00
- 時長：15 分鐘
- 議程：
  1. 昨天完成了什麼
  2. 今天計畫做什麼
  3. 有什麼阻礙或問題
- 參與者：全體團隊成員

**里程碑回顧（Milestone Retrospective）：**
- 時機：每個里程碑完成後
- 時長：30 分鐘
- 議程：
  1. 目標達成情況
  2. 遇到的問題和解決方案
  3. 經驗總結
  4. 下一階段注意事項

### 9.2 報告機制

**進度報告：**
- 頻率：每 2 天
- 內容：
  - 已完成任務
  - 進行中任務
  - 待開始任務
  - 關鍵指標（覆蓋率、測試通過率）
  - 風險與問題

**風險報告觸發條件：**
- 任何高影響風險發生
- 進度延遲超過 1 天
- 成本接近預算 80%
- 關鍵測試失敗

---

## 10. 變更管理 (Change Management)

### 10.1 變更申請流程

1. **提出變更請求**
   - 填寫變更申請表
   - 說明變更理由、影響範圍、預估工作量

2. **評估影響**
   - 評估對時程的影響
   - 評估對資源的影響
   - 評估對品質的影響
   - 評估對規格的影響

3. **決策**
   - 計畫負責人審查
   - 批准或拒絕，並說明理由

4. **執行變更**
   - 更新計畫文件
   - 更新規格（如需要）
   - 通知相關人員

5. **記錄變更**
   - 記錄於變更記錄表
   - 更新版本號

### 10.2 變更記錄

| 版本 | 日期 | 變更內容 | 原因 | 批准人 | 影響範圍 |
|------|------|----------|------|--------|---------|
| 1.0.0 | 2025-10-14 | 初始版本 | 基於 SPEC-2025-002 創建 | 專案團隊 | N/A |

---

## 11. 完成標準 (Completion Criteria)

### 11.1 必要項目（Must Have）

- [ ] **M1 達成**：Supabase 環境設定完成並測試通過
- [ ] **M2 達成**：資料庫結構建立完成，包含所有表和索引
- [ ] **M3 達成**：140,782 筆標籤資料成功遷移，資料完整性 100%
- [ ] **M4 達成**：≥99% 標籤成功生成向量嵌入
- [ ] **M5 達成**：所有測試通過（單元、整合、效能、驗收）
- [ ] **M6 達成**：所有文件完成並審查通過
- [ ] 資料完整性驗證通過（記錄數、抽樣檢查、統計分佈）
- [ ] API 功能測試全部通過（10 種查詢模式）
- [ ] 語意搜尋測試通過率 ≥ 80%（20 個測試案例）
- [ ] 效能指標達標（API < 2s, 搜尋 < 3s）
- [ ] 成本控制在預算內（< $10 USD）
- [ ] 憲法合規性審查通過

### 11.2 選擇性項目（Should Have）

- [ ] 遷移時間 < 30 分鐘（實際可能因網路而異）
- [ ] 提供遷移狀態監控介面
- [ ] 自動化回滾工具
- [ ] 完整的效能優化建議

### 11.3 文件完整性

- [ ] 操作手冊（MIGRATION_GUIDE.md）
- [ ] API 文件（API_DOCUMENTATION.md）
- [ ] 故障排除指南（TROUBLESHOOTING.md）
- [ ] 測試報告（含單元、整合、效能測試）
- [ ] 驗證報告（資料完整性、API 功能）
- [ ] 最終完成報告

---

## 12. 後續行動 (Follow-up Actions)

### 12.1 立即後續（完成後 1 週內）

1. **監控系統穩定性**
   - 監控 API 回應時間和錯誤率
   - 監控資料庫效能
   - 記錄所有異常情況

2. **使用者回饋收集**
   - 收集 API 使用者的回饋
   - 記錄常見問題
   - 優先修復高頻問題

3. **效能持續優化**
   - 分析慢查詢
   - 優化索引
   - 調整快取策略

### 12.2 中期規劃（1-3 個月）

1. **功能擴展**
   - 實作進階搜尋功能
   - 增加批次操作 API
   - 支援標籤推薦功能

2. **前端開發**
   - 設計並實作 Web UI
   - 提供視覺化的資料瀏覽介面
   - 實作搜尋與篩選功能

3. **自動化與 CI/CD**
   - 建立自動化測試流程
   - 設定持續整合
   - 實作自動化部署

### 12.3 長期願景（3-6 個月）

1. **多使用者支援**
   - 實作使用者認證系統
   - 建立權限管理
   - 支援使用者個人資料

2. **協作功能**
   - 標籤收藏功能
   - 標籤評論功能
   - 標籤編輯建議功能

3. **進階分析**
   - 標籤使用趨勢分析
   - 標籤關聯分析
   - 搜尋行為分析

---

## 附錄 A：技術決策記錄 (Technical Decision Records)

### ADR-001：選擇 text-embedding-3-small 作為嵌入模型

**決策日期：** 2025-10-14

**背景：**
需要為 140,782 個標籤生成向量嵌入，支援語意搜尋功能。

**決策：**
使用 OpenAI 的 `text-embedding-3-small` 模型。

**理由：**
1. **成本效益**：$0.02 / 1M tokens，預估總成本 < $2
2. **效能良好**：1536 維向量，足夠的語意表達能力
3. **API 穩定**：OpenAI API 穩定可靠
4. **易於整合**：官方 Python SDK 支援良好

**替代方案：**
- `text-embedding-3-large`：效能更好但成本較高（$0.13 / 1M tokens）
- 開源模型（如 sentence-transformers）：需要自行部署和維護
- `text-embedding-ada-002`：舊版模型，已被新版取代

**影響：**
- 總成本約 $1.50（遠低於 $10 預算）
- 向量維度 1536（需要 6 KB/標籤的儲存空間）
- 需要約 70-140 次 API 呼叫（批次大小 1000-2000）

---

### ADR-002：選擇批次大小 500 進行資料上傳

**決策日期：** 2025-10-14

**背景：**
需要將 140,782 筆記錄上傳至 Supabase，需要平衡速度和穩定性。

**決策：**
使用批次大小 500 筆記錄/批次。

**理由：**
1. **平衡速度**：每批次約需 10-15 秒，總時間約 50 分鐘（在 30 分鐘目標範圍內，考慮網路延遲）
2. **錯誤恢復**：批次較小，失敗時重試成本低
3. **記憶體友善**：每批次約 5 MB 記憶體使用
4. **檢查點控制**：易於實作斷點續傳

**替代方案：**
- 批次大小 100：過小，總時間過長
- 批次大小 1000：過大，失敗時重試成本高
- 批次大小 2000：可能導致 timeout

**影響：**
- 總批次數：約 282 批次
- 預估上傳時間：15-25 分鐘（不含向量生成）
- 檢查點記錄：需要記錄 282 個檢查點狀態

---

## 附錄 B：環境配置範例

### .env 檔案範例

```env
# Supabase 配置
SUPABASE_URL=https://your-project-id.supabase.co
SUPABASE_ANON_KEY=your-anon-key-here
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key-here

# OpenAI 配置（用於向量生成）
OPENAI_API_KEY=sk-proj-your-openai-key-here

# 專案配置
PROJECT_NAME=prompt-scribe-tags
DATABASE_REGION=us-east-1

# 遷移配置
SOURCE_DB_PATH=./stage1/output/tags.db
BATCH_SIZE=500
EMBEDDING_BATCH_SIZE=1000
MAX_RETRIES=3

# 成本控制
MAX_BUDGET_USD=10.00
ENABLE_COST_MONITORING=true

# 日誌配置
LOG_LEVEL=INFO
LOG_FILE=./migration.log
```

---

## 附錄 C：檢查清單

### 遷移前檢查清單

- [ ] Supabase 專案已建立
- [ ] API 金鑰已取得並配置
- [ ] Python 環境已設定（3.11+）
- [ ] 所有依賴套件已安裝
- [ ] `tags.db` 檔案存在且可讀取
- [ ] OpenAI API 金鑰有效且有足夠配額
- [ ] 網路連線穩定
- [ ] 磁碟空間充足（≥ 1 GB）

### 遷移中檢查清單

- [ ] 資料庫 Schema 建立成功
- [ ] 資料開始上傳
- [ ] 上傳進度正常（無長時間停滯）
- [ ] 錯誤日誌中無嚴重錯誤
- [ ] 記憶體使用正常（< 2 GB）

### 遷移後檢查清單

- [ ] 記錄總數一致（140,782）
- [ ] 抽樣檢查通過（100 筆）
- [ ] 統計分佈一致
- [ ] 向量生成率 ≥ 99%
- [ ] API 端點可存取
- [ ] 語意搜尋功能正常
- [ ] 效能指標達標
- [ ] 所有測試通過
- [ ] 文件已完成

---

**計畫結束 (End of Plan)**

**批准狀態：** 待批准  
**批准人：** 專案負責人  
**批准日期：** 待定

**下一步行動：**
1. 審查本計畫
2. 批准後開始執行 M1：環境準備
3. 每日更新進度
