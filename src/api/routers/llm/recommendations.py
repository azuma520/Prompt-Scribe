"""
LLM Recommendations Router
LLM æ™ºèƒ½æ¨™ç±¤æ¨è–¦ç«¯é»
"""
from fastapi import APIRouter, HTTPException, Depends
import logging
import time
from typing import List, Dict

from ...models.requests import LLMRecommendRequest
from ...models.responses import (
    TagRecommendationResponse, 
    LLMTagRecommendation,
    QualityAssessment,
    RecommendationMetadata,
    PopularityTier
)
from ...services.supabase_client import get_supabase_service, SupabaseService
from ...services.keyword_expander import get_keyword_expander, KeywordExpander
from ...services.gpt5_nano_client import get_gpt5_nano_client, GPT5NanoClient

logger = logging.getLogger(__name__)

router = APIRouter()


async def convert_gpt5_result_to_response(
    gpt5_result: Dict,
    db: SupabaseService,
    request: LLMRecommendRequest
) -> TagRecommendationResponse:
    """å°‡ GPT-5 Nano çµæœè½‰æ›ç‚ºæ¨™æº–å›æ‡‰æ ¼å¼"""
    try:
        # ç²å– GPT-5 æ¨è–¦çš„æ¨™ç±¤
        gpt5_tags = gpt5_result.get("tags", [])
        gpt5_categories = gpt5_result.get("categories", [])
        gpt5_confidence = gpt5_result.get("confidence", 0.8)
        gpt5_reasoning = gpt5_result.get("reasoning", "")
        gpt5_suggestions = gpt5_result.get("suggestions", [])
        
        # å¾è³‡æ–™åº«æŸ¥è©¢æ¨™ç±¤è©³ç´°è³‡è¨Š
        recommended_tags = []
        for tag_name in gpt5_tags:
            tag_info = await db.get_tag_by_name(tag_name)
            if tag_info:
                # æ§‹å»º LLMTagRecommendation ç‰©ä»¶
                llm_tag = LLMTagRecommendation(
                    tag=tag_info['name'],
                    category=tag_info.get('main_category', tag_info.get('sub_category', 'UNKNOWN')),
                    subcategory=tag_info.get('sub_category'),
                    post_count=tag_info.get('post_count', 0),
                    confidence=gpt5_confidence,  # ä¿æŒ 0-1 ç¯„åœ
                    weight=int(gpt5_confidence * 10),  # è½‰æ›ç‚º 1-10 åˆ†æ•¸
                    popularity_tier=calculate_popularity_tier(tag_info.get('post_count', 0)),
                    match_reason=gpt5_reasoning,
                    usage_context=get_usage_context(tag_info.get('main_category', 'UNKNOWN')),
                    related_tags=[]  # æš«æ™‚ç‚ºç©ºï¼Œå¯ä»¥å¾ŒçºŒæ“´å±•
                )
                recommended_tags.append(llm_tag)
        
        # è¨ˆç®—åˆ†é¡åˆ†ä½ˆ
        category_distribution = {}
        for tag in recommended_tags:
            category = tag.category
            category_distribution[category] = category_distribution.get(category, 0) + 1
        
        # æ§‹å»ºå“è³ªè©•ä¼°
        quality_assessment = QualityAssessment(
            overall_score=gpt5_confidence,
            warnings=[],
            suggestions=gpt5_suggestions
        )
        
        # æ§‹å»ºå»ºè­°çš„ prompt
        suggested_prompt = ", ".join([tag.tag for tag in recommended_tags])
        
        # æ§‹å»ºå›æ‡‰
        response = TagRecommendationResponse(
            query=request.description,
            recommended_tags=recommended_tags,
            category_distribution=category_distribution,
            quality_assessment=quality_assessment,
            suggested_prompt=suggested_prompt,
            metadata=RecommendationMetadata(
                processing_time_ms=0,  # æœƒåœ¨å¤–éƒ¨è¨­ç½®
                total_candidates=len(gpt5_tags),
                algorithm="gpt-5-nano",
                cache_hit=False,
                keywords_extracted=gpt5_tags,
                keywords_expanded=gpt5_tags
            )
        )
        
        logger.info(f"GPT-5 Nano generated {len(recommended_tags)} tags")
        return response
        
    except Exception as e:
        logger.error(f"Failed to convert GPT-5 result: {e}")
        raise HTTPException(status_code=500, detail="Failed to process GPT-5 result")


def calculate_popularity_tier(post_count: int) -> PopularityTier:
    """è¨ˆç®—æµè¡Œåº¦ç­‰ç´š"""
    if post_count > 100000:
        return PopularityTier.VERY_POPULAR
    elif post_count > 10000:
        return PopularityTier.POPULAR
    elif post_count > 1000:
        return PopularityTier.MODERATE
    else:
        return PopularityTier.NICHE


def get_usage_context(category: str) -> str:
    """æ ¹æ“šåˆ†é¡è¿”å›ä½¿ç”¨æƒ…å¢ƒèªªæ˜"""
    context_map = {
        "CHARACTER": "è§’è‰²æ ¸å¿ƒæ¨™ç±¤ï¼Œå½±éŸ¿äººç‰©åŸºæœ¬ç‰¹å¾µå’Œæ•¸é‡",
        "CHARACTER_RELATED": "è§’è‰²ç›¸é—œæ¨™ç±¤ï¼Œæè¿°å¤–è§€ã€æœè£å’Œç´°ç¯€ç‰¹å¾µ",
        "ACTION_POSE": "å‹•ä½œå§¿æ…‹æ¨™ç±¤ï¼Œå½±éŸ¿äººç‰©å‹•ä½œã€è¡¨æƒ…å’Œå§¿å‹¢",
        "ENVIRONMENT": "ç’°å¢ƒæ¨™ç±¤ï¼Œè¨­å®šå ´æ™¯èƒŒæ™¯ã€åœ°é»å’Œæ°›åœ",
        "ART_STYLE": "è—è¡“é¢¨æ ¼æ¨™ç±¤ï¼Œå½±éŸ¿æ•´é«”ç•«é¢¨å’Œè¦–è¦ºå‘ˆç¾",
        "OBJECTS": "ç‰©ä»¶æ¨™ç±¤ï¼Œæ·»åŠ å ´æ™¯ä¸­çš„é“å…·å’Œç‰©å“",
        "COMPOSITION": "æ§‹åœ–æ¨™ç±¤ï¼Œå½±éŸ¿è¦–è§’ã€æ™¯æ·±å’Œç•«é¢æ§‹æˆ",
        "VISUAL_EFFECTS": "è¦–è¦ºæ•ˆæœæ¨™ç±¤ï¼Œæ·»åŠ å…‰å½±ã€ç‰¹æ•ˆå’Œæ°›åœ",
        "QUALITY": "å“è³ªæ¨™ç±¤ï¼Œæå‡æ•´é«”ç•«è³ªå’Œç²¾ç´°åº¦",
        "TECHNICAL": "æŠ€è¡“æ¨™ç±¤ï¼Œæ§åˆ¶ç”Ÿæˆåƒæ•¸å’Œé¢¨æ ¼ç´°ç¯€",
    }
    return context_map.get(category, "é€šç”¨æ¨™ç±¤ï¼Œå¯ç”¨æ–¼å„ç¨®å ´æ™¯")


def calculate_confidence(tag_name: str, keywords: List[str], expanded_keywords: List[str]) -> float:
    """
    è¨ˆç®—æ¨è–¦ä¿¡å¿ƒåº¦
    
    Args:
        tag_name: æ¨™ç±¤åç¨±
        keywords: åŸå§‹é—œéµå­—
        expanded_keywords: æ“´å±•å¾Œçš„é—œéµå­—
    """
    # å®Œå…¨åŒ¹é…
    if tag_name in keywords:
        return 0.98
    
    # æ“´å±•åŒ¹é…
    if tag_name in expanded_keywords:
        return 0.92
    
    # éƒ¨åˆ†åŒ¹é…
    for keyword in keywords:
        if keyword in tag_name or tag_name in keyword:
            return 0.85
    
    # åˆ†é¡åŒ¹é…
    return 0.70


@router.post(
    "/recommend-tags",
    response_model=TagRecommendationResponse,
    summary="ğŸ¤– æ™ºèƒ½æ¨™ç±¤æ¨è–¦",
    description="""
    **LLM å°ˆç”¨çš„ä¸€ç«™å¼æ¨™ç±¤æ¨è–¦ç«¯é»**
    
    è¼¸å…¥è‡ªç„¶èªè¨€æè¿°ï¼Œè¿”å›æœ€é©åˆçš„æ¨™ç±¤çµ„åˆï¼ŒåŒ…å«:
    - æ™ºèƒ½é—œéµå­—æå–å’Œæ“´å±•
    - åˆ†é¡å¹³è¡¡å„ªåŒ–
    - æµè¡Œåº¦åŠ æ¬Šæ’åº
    - è©³ç´°çš„ä½¿ç”¨å»ºè­°å’Œè§£é‡‹
    
    é€™æ˜¯ LLM æœ€å¸¸ç”¨çš„ç«¯é»ï¼Œä¸€æ¬¡èª¿ç”¨å®Œæˆæ‰€æœ‰å·¥ä½œã€‚
    """
)
async def recommend_tags(
    request: LLMRecommendRequest,
    db: SupabaseService = Depends(get_supabase_service),
    expander: KeywordExpander = Depends(get_keyword_expander)
):
    """æ™ºèƒ½æ¨™ç±¤æ¨è–¦"""
    start_time = time.time()
    
    try:
        # 0. å˜—è©¦ä½¿ç”¨ GPT-5 Nanoï¼ˆå¦‚æœå¯ç”¨ï¼‰
        gpt5_client = get_gpt5_nano_client()
        if gpt5_client.is_available():
            logger.info("Using GPT-5 Nano for tag recommendation")
            gpt5_result = await gpt5_client.generate_tags(request.description)
            
            if gpt5_result:
                # è½‰æ› GPT-5 çµæœç‚ºæ¨™æº–æ ¼å¼
                return await convert_gpt5_result_to_response(gpt5_result, db, request)
            else:
                logger.warning("GPT-5 Nano failed, falling back to keyword matching")
        
        # å›é€€åˆ°åŸæœ‰çš„é—œéµå­—åŒ¹é…é‚è¼¯
        logger.info("Using keyword-based tag recommendation")
        # 1. æå–å’Œæ“´å±•é—œéµå­—
        original_keywords, expanded_keywords = expander.expand_query(request.description)
        logger.info(f"Keywords: {original_keywords} -> {expanded_keywords}")
        
        # 2. æœå°‹å€™é¸æ¨™ç±¤
        candidates = await db.search_tags_by_keywords(
            keywords=expanded_keywords,
            limit=request.max_tags * 3,  # ç²å–æ›´å¤šå€™é¸
            min_popularity=request.min_popularity
        )
        
        # 3. æ’åºå’Œè©•åˆ†
        scored_tags = []
        for tag in candidates:
            # è¨ˆç®—ä¿¡å¿ƒåº¦
            confidence = calculate_confidence(
                tag['name'], 
                original_keywords, 
                expanded_keywords
            )
            
            # è¨ˆç®—ç¶œåˆæ¬Šé‡ (ç›¸é—œæ€§ 70% + æµè¡Œåº¦ 30%)
            relevance_weight = confidence * 0.7
            popularity_weight = min(tag['post_count'] / 100000, 1.0) * 0.3
            combined_weight = relevance_weight + popularity_weight
            
            scored_tags.append({
                'tag': tag,
                'confidence': confidence,
                'weight': int(combined_weight * 10)
            })
        
        # æŒ‰ç¶œåˆæ¬Šé‡æ’åº
        scored_tags.sort(key=lambda x: x['weight'], reverse=True)
        
        # 4. åˆ†é¡å¹³è¡¡ (å¦‚æœå•Ÿç”¨)
        if request.balance_categories:
            # ç°¡åŒ–å¯¦ç¾ï¼šç¢ºä¿è‡³å°‘åŒ…å« 2-3 å€‹ä¸åŒåˆ†é¡
            selected_tags = []
            categories_used = set()
            
            # ç¬¬ä¸€è¼ªï¼šé¸æ“‡é«˜åˆ†æ¨™ç±¤
            for item in scored_tags:
                if len(selected_tags) >= request.max_tags:
                    break
                selected_tags.append(item)
                categories_used.add(item['tag']['main_category'])
            
            scored_tags = selected_tags
        else:
            scored_tags = scored_tags[:request.max_tags]
        
        # 5. æ§‹å»ºæ¨è–¦åˆ—è¡¨
        recommendations = []
        for item in scored_tags:
            tag = item['tag']
            recommendations.append(
                LLMTagRecommendation(
                    tag=tag['name'],
                    confidence=item['confidence'],
                    popularity_tier=calculate_popularity_tier(tag['post_count']),
                    post_count=tag['post_count'],
                    category=tag['main_category'] or 'UNKNOWN',
                    subcategory=tag.get('sub_category'),
                    match_reason=f"åŒ¹é…é—œéµå­—: {', '.join(original_keywords[:3])}",
                    usage_context=get_usage_context(tag['main_category']),
                    weight=item['weight'],
                    related_tags=[]  # TODO: å¯¦ä½œç›¸é—œæ¨™ç±¤æ¨è–¦
                )
            )
        
        # 6. è¨ˆç®—åˆ†é¡åˆ†ä½ˆ
        category_distribution = {}
        for rec in recommendations:
            category_distribution[rec.category] = category_distribution.get(rec.category, 0) + 1
        
        # 7. å“è³ªè©•ä¼°
        overall_score = int(sum(r.confidence for r in recommendations) / len(recommendations) * 100) if recommendations else 0
        balance_score = min(len(category_distribution) * 25, 100)  # è¶Šå¤šåˆ†é¡è¶Šå¥½
        popularity_score = int(sum(r.post_count for r in recommendations) / len(recommendations) / 10000) if recommendations else 0
        popularity_score = min(popularity_score, 100)
        
        quality_assessment = QualityAssessment(
            overall_score=overall_score,
            balance_score=balance_score,
            popularity_score=popularity_score,
            warnings=[]
        )
        
        # æ·»åŠ è­¦å‘Š
        if len(recommendations) < request.max_tags:
            quality_assessment.warnings.append(
                f"åƒ…æ‰¾åˆ° {len(recommendations)} å€‹æ¨™ç±¤ï¼Œå°‘æ–¼è«‹æ±‚çš„ {request.max_tags} å€‹"
            )
        if balance_score < 50:
            quality_assessment.warnings.append("æ¨™ç±¤åˆ†é¡è¼ƒç‚ºå–®ä¸€ï¼Œå»ºè­°å¢åŠ ä¸åŒé¡å‹çš„é—œéµå­—")
        
        # 8. ç”Ÿæˆå»ºè­°çš„ prompt
        suggested_prompt = ", ".join([r.tag for r in recommendations])
        
        # 9. å…ƒè³‡æ–™
        processing_time = (time.time() - start_time) * 1000
        metadata = RecommendationMetadata(
            processing_time_ms=round(processing_time, 2),
            total_candidates=len(candidates),
            algorithm="keyword_matching_v1",
            cache_hit=False,
            keywords_extracted=original_keywords,
            keywords_expanded=expanded_keywords
        )
        
        return TagRecommendationResponse(
            query=request.description,
            recommended_tags=recommendations,
            category_distribution=category_distribution,
            quality_assessment=quality_assessment,
            suggested_prompt=suggested_prompt,
            metadata=metadata
        )
        
    except Exception as e:
        logger.error(f"Error in recommend_tags: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get(
    "/test-openai-config",
    summary="ğŸ”§ æ¸¬è©¦ OpenAI é…ç½®",
    description="""
    **æ¸¬è©¦ GPT-5 Nano é…ç½®å’Œé€£æ¥**
    
    æª¢æŸ¥ï¼š
    - API é‡‘é‘°æ˜¯å¦è¨­ç½®
    - ç’°å¢ƒè®Šæ•¸æ˜¯å¦æ­£ç¢º
    - æ¨¡å‹æ˜¯å¦å¯ç”¨
    - é€£æ¥æ¸¬è©¦
    """
)
async def test_openai_config():
    """æ¸¬è©¦ OpenAI é…ç½®"""
    gpt5_client = get_gpt5_nano_client()
    test_result = await gpt5_client.test_connection()
    
    return {
        "status": "success",
        "message": "OpenAI é…ç½®æ¸¬è©¦å®Œæˆ",
        "result": test_result
    }

