"""
LLM Recommendations Router
LLM æ™ºèƒ½æ¨™ç±¤æ¨è–¦ç«¯é»
"""
from fastapi import APIRouter, HTTPException, Depends
import logging
import time
from typing import List, Dict

from models.requests import LLMRecommendRequest
from models.responses import (
    TagRecommendationResponse, 
    LLMTagRecommendation,
    QualityAssessment,
    RecommendationMetadata,
    PopularityTier
)
from services.supabase_client import get_supabase_service, SupabaseService
from services.keyword_expander import get_keyword_expander, KeywordExpander

logger = logging.getLogger(__name__)

router = APIRouter()


def calculate_popularity_tier(post_count: int) -> PopularityTier:
    """è¨ˆç®—æµè¡Œåº¦ç­‰ç´š"""
    if post_count > 100000:
        return PopularityTier.VERY_POPULAR
    elif post_count > 10000:
        return PopularityTier.POPULAR
    elif post_count > 1000:
        return PopularityTier.MODERATE
    else:
        return PopularityTier.NICHE


def get_usage_context(category: str) -> str:
    """æ ¹æ“šåˆ†é¡è¿”å›ä½¿ç”¨æƒ…å¢ƒèªªæ˜"""
    context_map = {
        "CHARACTER": "è§’è‰²æ ¸å¿ƒæ¨™ç±¤ï¼Œå½±éŸ¿äººç‰©åŸºæœ¬ç‰¹å¾µå’Œæ•¸é‡",
        "CHARACTER_RELATED": "è§’è‰²ç›¸é—œæ¨™ç±¤ï¼Œæè¿°å¤–è§€ã€æœè£å’Œç´°ç¯€ç‰¹å¾µ",
        "ACTION_POSE": "å‹•ä½œå§¿æ…‹æ¨™ç±¤ï¼Œå½±éŸ¿äººç‰©å‹•ä½œã€è¡¨æƒ…å’Œå§¿å‹¢",
        "ENVIRONMENT": "ç’°å¢ƒæ¨™ç±¤ï¼Œè¨­å®šå ´æ™¯èƒŒæ™¯ã€åœ°é»å’Œæ°›åœ",
        "ART_STYLE": "è—è¡“é¢¨æ ¼æ¨™ç±¤ï¼Œå½±éŸ¿æ•´é«”ç•«é¢¨å’Œè¦–è¦ºå‘ˆç¾",
        "OBJECTS": "ç‰©ä»¶æ¨™ç±¤ï¼Œæ·»åŠ å ´æ™¯ä¸­çš„é“å…·å’Œç‰©å“",
        "COMPOSITION": "æ§‹åœ–æ¨™ç±¤ï¼Œå½±éŸ¿è¦–è§’ã€æ™¯æ·±å’Œç•«é¢æ§‹æˆ",
        "VISUAL_EFFECTS": "è¦–è¦ºæ•ˆæœæ¨™ç±¤ï¼Œæ·»åŠ å…‰å½±ã€ç‰¹æ•ˆå’Œæ°›åœ",
        "QUALITY": "å“è³ªæ¨™ç±¤ï¼Œæå‡æ•´é«”ç•«è³ªå’Œç²¾ç´°åº¦",
        "TECHNICAL": "æŠ€è¡“æ¨™ç±¤ï¼Œæ§åˆ¶ç”Ÿæˆåƒæ•¸å’Œé¢¨æ ¼ç´°ç¯€",
    }
    return context_map.get(category, "é€šç”¨æ¨™ç±¤ï¼Œå¯ç”¨æ–¼å„ç¨®å ´æ™¯")


def calculate_confidence(tag_name: str, keywords: List[str], expanded_keywords: List[str]) -> float:
    """
    è¨ˆç®—æ¨è–¦ä¿¡å¿ƒåº¦
    
    Args:
        tag_name: æ¨™ç±¤åç¨±
        keywords: åŸå§‹é—œéµå­—
        expanded_keywords: æ“´å±•å¾Œçš„é—œéµå­—
    """
    # å®Œå…¨åŒ¹é…
    if tag_name in keywords:
        return 0.98
    
    # æ“´å±•åŒ¹é…
    if tag_name in expanded_keywords:
        return 0.92
    
    # éƒ¨åˆ†åŒ¹é…
    for keyword in keywords:
        if keyword in tag_name or tag_name in keyword:
            return 0.85
    
    # åˆ†é¡åŒ¹é…
    return 0.70


@router.post(
    "/recommend-tags",
    response_model=TagRecommendationResponse,
    summary="ğŸ¤– æ™ºèƒ½æ¨™ç±¤æ¨è–¦",
    description="""
    **LLM å°ˆç”¨çš„ä¸€ç«™å¼æ¨™ç±¤æ¨è–¦ç«¯é»**
    
    è¼¸å…¥è‡ªç„¶èªè¨€æè¿°ï¼Œè¿”å›æœ€é©åˆçš„æ¨™ç±¤çµ„åˆï¼ŒåŒ…å«:
    - æ™ºèƒ½é—œéµå­—æå–å’Œæ“´å±•
    - åˆ†é¡å¹³è¡¡å„ªåŒ–
    - æµè¡Œåº¦åŠ æ¬Šæ’åº
    - è©³ç´°çš„ä½¿ç”¨å»ºè­°å’Œè§£é‡‹
    
    é€™æ˜¯ LLM æœ€å¸¸ç”¨çš„ç«¯é»ï¼Œä¸€æ¬¡èª¿ç”¨å®Œæˆæ‰€æœ‰å·¥ä½œã€‚
    """
)
async def recommend_tags(
    request: LLMRecommendRequest,
    db: SupabaseService = Depends(get_supabase_service),
    expander: KeywordExpander = Depends(get_keyword_expander)
):
    """æ™ºèƒ½æ¨™ç±¤æ¨è–¦"""
    start_time = time.time()
    
    try:
        # 1. æå–å’Œæ“´å±•é—œéµå­—
        original_keywords, expanded_keywords = expander.expand_query(request.description)
        logger.info(f"Keywords: {original_keywords} -> {expanded_keywords}")
        
        # 2. æœå°‹å€™é¸æ¨™ç±¤
        candidates = await db.search_tags_by_keywords(
            keywords=expanded_keywords,
            limit=request.max_tags * 3,  # ç²å–æ›´å¤šå€™é¸
            min_popularity=request.min_popularity
        )
        
        # 3. æ’åºå’Œè©•åˆ†
        scored_tags = []
        for tag in candidates:
            # è¨ˆç®—ä¿¡å¿ƒåº¦
            confidence = calculate_confidence(
                tag['name'], 
                original_keywords, 
                expanded_keywords
            )
            
            # è¨ˆç®—ç¶œåˆæ¬Šé‡ (ç›¸é—œæ€§ 70% + æµè¡Œåº¦ 30%)
            relevance_weight = confidence * 0.7
            popularity_weight = min(tag['post_count'] / 100000, 1.0) * 0.3
            combined_weight = relevance_weight + popularity_weight
            
            scored_tags.append({
                'tag': tag,
                'confidence': confidence,
                'weight': int(combined_weight * 10)
            })
        
        # æŒ‰ç¶œåˆæ¬Šé‡æ’åº
        scored_tags.sort(key=lambda x: x['weight'], reverse=True)
        
        # 4. åˆ†é¡å¹³è¡¡ (å¦‚æœå•Ÿç”¨)
        if request.balance_categories:
            # ç°¡åŒ–å¯¦ç¾ï¼šç¢ºä¿è‡³å°‘åŒ…å« 2-3 å€‹ä¸åŒåˆ†é¡
            selected_tags = []
            categories_used = set()
            
            # ç¬¬ä¸€è¼ªï¼šé¸æ“‡é«˜åˆ†æ¨™ç±¤
            for item in scored_tags:
                if len(selected_tags) >= request.max_tags:
                    break
                selected_tags.append(item)
                categories_used.add(item['tag']['main_category'])
            
            scored_tags = selected_tags
        else:
            scored_tags = scored_tags[:request.max_tags]
        
        # 5. æ§‹å»ºæ¨è–¦åˆ—è¡¨
        recommendations = []
        for item in scored_tags:
            tag = item['tag']
            recommendations.append(
                LLMTagRecommendation(
                    tag=tag['name'],
                    confidence=item['confidence'],
                    popularity_tier=calculate_popularity_tier(tag['post_count']),
                    post_count=tag['post_count'],
                    category=tag['main_category'] or 'UNKNOWN',
                    subcategory=tag.get('sub_category'),
                    match_reason=f"åŒ¹é…é—œéµå­—: {', '.join(original_keywords[:3])}",
                    usage_context=get_usage_context(tag['main_category']),
                    weight=item['weight'],
                    related_tags=[]  # TODO: å¯¦ä½œç›¸é—œæ¨™ç±¤æ¨è–¦
                )
            )
        
        # 6. è¨ˆç®—åˆ†é¡åˆ†ä½ˆ
        category_distribution = {}
        for rec in recommendations:
            category_distribution[rec.category] = category_distribution.get(rec.category, 0) + 1
        
        # 7. å“è³ªè©•ä¼°
        overall_score = int(sum(r.confidence for r in recommendations) / len(recommendations) * 100) if recommendations else 0
        balance_score = min(len(category_distribution) * 25, 100)  # è¶Šå¤šåˆ†é¡è¶Šå¥½
        popularity_score = int(sum(r.post_count for r in recommendations) / len(recommendations) / 10000) if recommendations else 0
        popularity_score = min(popularity_score, 100)
        
        quality_assessment = QualityAssessment(
            overall_score=overall_score,
            balance_score=balance_score,
            popularity_score=popularity_score,
            warnings=[]
        )
        
        # æ·»åŠ è­¦å‘Š
        if len(recommendations) < request.max_tags:
            quality_assessment.warnings.append(
                f"åƒ…æ‰¾åˆ° {len(recommendations)} å€‹æ¨™ç±¤ï¼Œå°‘æ–¼è«‹æ±‚çš„ {request.max_tags} å€‹"
            )
        if balance_score < 50:
            quality_assessment.warnings.append("æ¨™ç±¤åˆ†é¡è¼ƒç‚ºå–®ä¸€ï¼Œå»ºè­°å¢åŠ ä¸åŒé¡å‹çš„é—œéµå­—")
        
        # 8. ç”Ÿæˆå»ºè­°çš„ prompt
        suggested_prompt = ", ".join([r.tag for r in recommendations])
        
        # 9. å…ƒè³‡æ–™
        processing_time = (time.time() - start_time) * 1000
        metadata = RecommendationMetadata(
            processing_time_ms=round(processing_time, 2),
            total_candidates=len(candidates),
            algorithm="keyword_matching_v1",
            cache_hit=False,
            keywords_extracted=original_keywords,
            keywords_expanded=expanded_keywords
        )
        
        return TagRecommendationResponse(
            query=request.description,
            recommended_tags=recommendations,
            category_distribution=category_distribution,
            quality_assessment=quality_assessment,
            suggested_prompt=suggested_prompt,
            metadata=metadata
        )
        
    except Exception as e:
        logger.error(f"Error in recommend_tags: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

