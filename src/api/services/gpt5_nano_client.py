"""
GPT-5 Nano å®¢æˆ¶ç«¯æœå‹™
ç”¨æ–¼èˆ‡ OpenAI GPT-5 Nano æ¨¡å‹é€²è¡Œäº¤äº’
"""

import os
import json
import logging
import asyncio
from typing import Dict, List, Optional, Any
from datetime import datetime

try:
    import openai
except ImportError:
    openai = None

from config import settings
from .gpt5_output_schema import get_gpt5_validator, GPT5TagOutputSchema
from .model_selector import get_optimal_model

logger = logging.getLogger(__name__)


class GPT5NanoClient:
    """OpenAI LLM å®¢æˆ¶ç«¯é¡åˆ¥
    
    æ”¯æ´çš„ GPT-5 ç³»åˆ—æ¨¡å‹ï¼ˆ2025 æœ€æ–°ï¼‰ï¼š
    - gpt-5: è¤‡é›œæ¨ç†ã€å»£é—Šçš„ä¸–ç•ŒçŸ¥è­˜ã€ä»£ç¢¼ç¹é‡æˆ–å¤šæ­¥é©Ÿä»£ç†ä»»å‹™ï¼ˆæœ€å¼·å¤§ï¼‰
    - gpt-5-mini: æˆæœ¬å„ªåŒ–çš„æ¨ç†å’ŒèŠå¤©ï¼›å¹³è¡¡é€Ÿåº¦ã€æˆæœ¬å’Œèƒ½åŠ›ï¼ˆæ¨è–¦ï¼‰
    - gpt-5-nano: é«˜é€šé‡ä»»å‹™ï¼Œç‰¹åˆ¥æ˜¯ç°¡å–®çš„æŒ‡ä»¤éµå¾ªæˆ–åˆ†é¡ï¼ˆæœ€ç¶“æ¿Ÿï¼‰
    
    æ”¯æ´çš„ GPT-4 ç³»åˆ—æ¨¡å‹ï¼š
    - gpt-4o: å¤šæ¨¡æ…‹æ——è‰¦æ¨¡å‹
    - gpt-4o-mini: å¿«é€Ÿç¶“æ¿Ÿçš„æ¨¡å‹ï¼ˆé»˜èªï¼‰
    
    æ³¨æ„ï¼šGPT-5 ç³»åˆ—ä¸æ”¯æŒ temperatureã€top_pã€logprobs åƒæ•¸
    """
    
    def __init__(self):
        """åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯"""
        # å¾é…ç½®å°è±¡è®€å–
        self.api_key = settings.openai_api_key
        self.enabled = settings.enable_openai_integration
        
        # ä½¿ç”¨é…ç½®çš„æ¨¡å‹ï¼ˆä¸é€²è¡Œå‹•æ…‹é¸æ“‡ä»¥é¿å…å»¶é²ï¼‰
        self.model = settings.openai_model
        self.max_tokens = settings.openai_max_tokens
        self.temperature = settings.openai_temperature
        self.timeout = settings.openai_timeout
        
        # æª¢æŸ¥æ˜¯å¦ç‚º GPT-5 ç³»åˆ—
        self.is_gpt5 = self.model.startswith("gpt-5")
        
        # è¨˜éŒ„é…ç½®ç‹€æ…‹
        logger.info("=" * 60)
        logger.info("ğŸ¤– GPT-5 Nano å®¢æˆ¶ç«¯åˆå§‹åŒ–")
        logger.info(f"  - API Key å·²è¨­ç½®: {'âœ… æ˜¯' if self.api_key else 'âŒ å¦'}")
        logger.info(f"  - æ¨¡å‹: {self.model}")
        logger.info(f"  - æœ€å¤§ Tokens: {self.max_tokens}")
        logger.info(f"  - è¶…æ™‚æ™‚é–“: {self.timeout}ç§’")
        logger.info(f"  - åŠŸèƒ½å•Ÿç”¨: {'âœ… æ˜¯' if self.enabled else 'âŒ å¦'}")
        logger.info(f"  - OpenAI åº«: {'âœ… å·²å®‰è£' if openai else 'âŒ æœªå®‰è£'}")
        
        # è¨˜éŒ„ä½¿ç”¨çš„æ¨¡å‹é¡å‹
        if self.enabled:
            model_type = "GPT-5 ç³»åˆ—" if self.is_gpt5 else "GPT-4 ç³»åˆ—"
            logger.info(f"  - æ¨¡å‹é¡å‹: {model_type}")
            if self.is_gpt5:
                logger.info(f"  - æ³¨æ„: GPT-5 ä¸æ”¯æŒ temperature åƒæ•¸")
        logger.info("=" * 60)
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯
        if self.api_key and openai:
            try:
                self.client = openai.OpenAI(api_key=self.api_key)
                logger.info("âœ… OpenAI å®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸ")
                
                # æª¢æ¸¬ Responses API å¯ç”¨æ€§
                self.has_responses_api = hasattr(self.client, 'responses')
                self.prefer_responses_api = True  # å„ªå…ˆä½¿ç”¨ Responses API
                
                logger.info(f"  - Responses API: {'âœ… å¯ç”¨' if self.has_responses_api else 'âŒ ä¸å¯ç”¨'}")
                
                if self.has_responses_api and self.is_gpt5:
                    logger.info(f"  - å°‡ä½¿ç”¨: Responses API (æ¨è–¦)")
                elif self.is_gpt5:
                    logger.warning(f"  - å°‡ä½¿ç”¨: Chat Completions API (Responses API ä¸å¯ç”¨)")
                else:
                    logger.info(f"  - å°‡ä½¿ç”¨: Chat Completions API (GPT-4 ç³»åˆ—)")
                    
            except Exception as e:
                self.client = None
                self.has_responses_api = False
                logger.error(f"âŒ OpenAI å®¢æˆ¶ç«¯åˆå§‹åŒ–å¤±æ•—: {e}")
        else:
            self.client = None
            self.has_responses_api = False
            if not self.api_key:
                logger.warning("âš ï¸ OpenAI API key æœªè¨­ç½® (è«‹åœ¨ç’°å¢ƒè®Šæ•¸ä¸­è¨­ç½® OPENAI_API_KEY)")
            if not openai:
                logger.warning("âš ï¸ OpenAI library æœªå®‰è£ (åŸ·è¡Œ: pip install openai)")
    
    def is_available(self) -> bool:
        """æª¢æŸ¥ GPT-5 Nano æ˜¯å¦å¯ç”¨"""
        return (
            self.enabled and 
            self.client is not None and 
            self.api_key is not None
        )
    
    async def generate_tags(
        self, 
        description: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Optional[Dict[str, Any]]:
        """
        ç”Ÿæˆæ¨™ç±¤æ¨è–¦
        
        Args:
            description: ç”¨æˆ¶æè¿°
            context: é¡å¤–ä¸Šä¸‹æ–‡è³‡è¨Š
            
        Returns:
            æ¨™ç±¤æ¨è–¦çµæœæˆ– None
        """
        logger.info("=" * 60)
        logger.info("ğŸ¯ é–‹å§‹ GPT-5 Nano æ¨™ç±¤ç”Ÿæˆ")
        logger.info(f"  - æè¿°: {description[:100]}{'...' if len(description) > 100 else ''}")
        
        # æª¢æŸ¥å¯ç”¨æ€§
        if not self.is_available():
            logger.warning("âŒ GPT-5 Nano ä¸å¯ç”¨ï¼Œä½¿ç”¨é™ç´šæ–¹æ¡ˆ")
            logger.warning(f"  - Enabled: {self.enabled}")
            logger.warning(f"  - Client: {self.client is not None}")
            logger.warning(f"  - API Key: {self.api_key is not None}")
            
            # è¿”å›é™ç´šæ–¹æ¡ˆ
            fallback_result = GPT5TagOutputSchema.create_fallback_response(description)
            logger.info("ğŸ”„ ä½¿ç”¨é™ç´šæ–¹æ¡ˆå›æ‡‰")
            return fallback_result
        
        # é¸æ“‡æœ€ä½³ API
        if self.has_responses_api and self.is_gpt5 and self.prefer_responses_api:
            logger.info("ğŸ“¡ ä½¿ç”¨ Responses API (æ¨è–¦)")
            return await self._generate_with_responses_api(description, context)
        else:
            logger.info("ğŸ“¡ ä½¿ç”¨ Chat Completions API")
            return await self._generate_with_chat_completions(description, context)
    
    async def _generate_with_chat_completions(
        self,
        description: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨ Chat Completions API ç”Ÿæˆæ¨™ç±¤ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            # æ§‹å»ºç³»çµ±æç¤ºè©
            system_prompt = self._build_system_prompt(context)
            logger.info(f"  - System prompt é•·åº¦: {len(system_prompt)} å­—ç¬¦")
            
            # æ§‹å»ºç”¨æˆ¶æç¤ºè©
            user_prompt = self._build_user_prompt(description, context)
            logger.info(f"  - User prompt é•·åº¦: {len(user_prompt)} å­—ç¬¦")
            
            # èª¿ç”¨ OpenAI API
            logger.info(f"ğŸ“¡ èª¿ç”¨ OpenAI API")
            logger.info(f"  - æ¨¡å‹: {self.model}")
            logger.info(f"  - Max tokens: {self.max_tokens}")
            logger.info(f"  - Timeout: {self.timeout}ç§’")
            
            # æº–å‚™ API åƒæ•¸
            api_params = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "timeout": self.timeout
            }
            
            # GPT-5 ç³»åˆ—ä½¿ç”¨ç‰¹æ®Šåƒæ•¸
            if self.is_gpt5:
                api_params["max_completion_tokens"] = self.max_tokens  # GPT-5 ä½¿ç”¨ max_completion_tokens
                api_params["reasoning_effort"] = "low"  # æ¨™ç±¤æ¨è–¦ä¸éœ€è¦è¤‡é›œæ¨ç†
                api_params["verbosity"] = "medium"  # æ”¹ç‚º medium ä»¥æé«˜ç©©å®šæ€§
                logger.info(f"  - Max completion tokens: {self.max_tokens} (GPT-5)")
                logger.info(f"  - Reasoning effort: low (GPT-5)")
                logger.info(f"  - Verbosity: medium (GPT-5ï¼Œæé«˜ç©©å®šæ€§)")
                logger.info(f"  - Temperature: N/A (GPT-5 ä¸æ”¯æŒ)")
            else:
                api_params["max_tokens"] = self.max_tokens  # GPT-4 ä½¿ç”¨ max_tokens
                api_params["temperature"] = self.temperature
                logger.info(f"  - Max tokens: {self.max_tokens}")
                logger.info(f"  - Temperature: {self.temperature}")
            
            # èª¿ç”¨ API
            logger.info("â³ ç­‰å¾… API å›æ‡‰...")
            response = self.client.chat.completions.create(**api_params)
            logger.info("âœ… API å›æ‡‰æˆåŠŸ")
            
            # è§£æå›æ‡‰
            content = response.choices[0].message.content
            logger.info(f"ğŸ“¦ å›æ‡‰å…§å®¹:")
            logger.info(f"  - é•·åº¦: {len(content)} å­—ç¬¦")
            logger.info(f"  - å‰ 500 å­—ç¬¦: {content[:500]}")
            
            # è§£æ JSON å›æ‡‰
            result = self._parse_response(content)
            
            if result:
                logger.info("âœ… JSON è§£ææˆåŠŸ")
                logger.info(f"  - Tags: {result.get('tags', [])[:5]}")
                logger.info(f"  - Confidence: {result.get('confidence', 0)}")
            else:
                logger.error("âŒ JSON è§£æå¤±æ•—")
            
            # è¨˜éŒ„ä½¿ç”¨é‡
            self._log_usage(response)
            
            logger.info("=" * 60)
            return result
            
        except openai.APIError as e:
            logger.error("=" * 60)
            logger.error(f"âŒ OpenAI API éŒ¯èª¤: {e}")
            logger.error(f"  - ç‹€æ…‹ç¢¼: {e.status_code if hasattr(e, 'status_code') else 'N/A'}")
            logger.error(f"  - éŒ¯èª¤è¨Šæ¯: {str(e)}")
            logger.error("=" * 60)
            return None
        except openai.APIConnectionError as e:
            logger.error("=" * 60)
            logger.error(f"âŒ OpenAI é€£æ¥éŒ¯èª¤: {e}")
            logger.error("  - å¯èƒ½åŸå› :")
            logger.error("    1. ç¶²è·¯é€£æ¥å•é¡Œ")
            logger.error("    2. API é‡‘é‘°ç„¡æ•ˆ")
            logger.error("    3. OpenAI æœå‹™æš«æ™‚ä¸å¯ç”¨")
            logger.error("=" * 60)
            return None
        except openai.RateLimitError as e:
            logger.error("=" * 60)
            logger.error(f"âŒ OpenAI é€Ÿç‡é™åˆ¶: {e}")
            logger.error("  - å»ºè­°: ç¨å¾Œå†è©¦æˆ–å‡ç´š API æ–¹æ¡ˆ")
            logger.error("=" * 60)
            return None
        except Exception as e:
            logger.error("=" * 60)
            logger.error(f"âŒ GPT-5 Nano æœªé æœŸçš„éŒ¯èª¤: {e}", exc_info=True)
            logger.error("=" * 60)
            return None
    
    def _build_system_prompt(self, context: Optional[Dict[str, Any]] = None) -> str:
        """æ§‹å»ºç³»çµ±æç¤ºè©ï¼ˆçµæ§‹åŒ–è¼¸å‡ºç‰ˆæœ¬ï¼‰"""
        base_prompt = """You are an expert AI image generation tag recommendation assistant for Danbooru-style tagging system.

Your task:
1. Analyze the user's description carefully
2. Recommend 5-10 relevant English tags that best match the description
3. Tags should follow Danbooru conventions (e.g., "1girl", "long_hair", "blue_eyes", "school_uniform")
4. Prioritize commonly used and effective tags
5. Include character, appearance, clothing, and scene tags as appropriate

Tag Categories:
- Character count: 1girl, 2girls, solo, multiple_girls
- Physical features: long_hair, short_hair, blue_eyes, blonde_hair
- Clothing: school_uniform, dress, shirt, skirt
- Actions: sitting, standing, smiling, looking_at_viewer
- Scene: outdoors, indoors, city, forest, night, sunset
- Art style: anime_style, realistic, masterpiece, high_quality

CRITICAL: You MUST return a valid JSON object in this EXACT format:
{
    "tags": ["tag1", "tag2", "tag3", "tag4", "tag5"],
    "confidence": 0.85,
    "reasoning": "Brief explanation of why these tags were chosen",
    "categories": ["CHARACTER", "APPEARANCE", "SCENE"]
}

VALIDATION RULES (strictly enforced):
- "tags": Array of 1-15 strings, English only, use underscores for multi-word tags
- "confidence": Number between 0.6 and 0.95
- "reasoning": Non-empty string explaining your choices (max 500 chars)
- "categories": Optional array from: CHARACTER, APPEARANCE, CLOTHING, ACTION, SCENE, STYLE, OBJECT, COMPOSITION, EFFECT
- Return ONLY the JSON object, no other text
- All field names must be exactly as shown above

Examples of valid tags:
- "1girl", "solo", "long_hair", "blue_eyes", "school_uniform"
- "smiling", "looking_at_viewer", "outdoors", "sunset"
- "anime_style", "masterpiece", "high_quality" """
        
        if context:
            context_info = f"\n\nAdditional context: {json.dumps(context, ensure_ascii=False)}"
            base_prompt += context_info
        
        return base_prompt
    
    def _build_user_prompt(self, description: str, context: Optional[Dict[str, Any]] = None) -> str:
        """æ§‹å»ºç”¨æˆ¶æç¤ºè©"""
        prompt = f"User Description: \"{description}\"\n\nPlease analyze this description and recommend the most appropriate Danbooru-style tags for AI image generation."
        
        if context and context.get("existing_tags"):
            prompt += f"\n\nExisting tags to consider: {', '.join(context['existing_tags'])}"
        
        if context and context.get("user_preferences"):
            prompt += f"\n\nUser preferences: {context['user_preferences']}"
        
        if context and context.get("style_hint"):
            prompt += f"\n\nStyle hint: {context['style_hint']}"
        
        return prompt
    
    def _parse_response(self, content: str) -> Optional[Dict[str, Any]]:
        """è§£æ GPT-5 Nano å›æ‡‰ï¼ˆä½¿ç”¨çµæ§‹åŒ–é©—è­‰ï¼Œå¼·åŒ–éŒ¯èª¤è™•ç†ï¼‰"""
        try:
            # æª¢æŸ¥ç©ºå›æ‡‰
            if not content or len(content.strip()) == 0:
                logger.error(f"âŒ æ”¶åˆ°ç©ºå›æ‡‰")
                return None
            
            # æ¸…ç†å›æ‡‰å…§å®¹ï¼ˆç§»é™¤å¯èƒ½çš„ markdown ä»£ç¢¼å¡Šï¼‰
            cleaned_content = content.strip()
            if cleaned_content.startswith("```"):
                lines = cleaned_content.split('\n')
                # ç§»é™¤é–‹é ­çš„ ```json æˆ– ```
                if lines[0].startswith("```"):
                    lines = lines[1:]
                # ç§»é™¤çµå°¾çš„ ```
                if lines and lines[-1].strip() == "```":
                    lines = lines[:-1]
                cleaned_content = '\n'.join(lines).strip()
            
            # æå– JSON éƒ¨åˆ†ï¼ˆå¦‚æœæœ‰é¡å¤–æ–‡å­—ï¼‰
            if '{' in cleaned_content and '}' in cleaned_content:
                start = cleaned_content.find('{')
                end = cleaned_content.rfind('}') + 1
                json_part = cleaned_content[start:end]
            else:
                json_part = cleaned_content
            
            # ä½¿ç”¨çµæ§‹åŒ–é©—è­‰ç³»çµ±
            validator = get_gpt5_validator()
            result = validator.validate(json_part)
            
            # æª¢æŸ¥é©—è­‰çµæœ
            if result is None:
                logger.error("âŒ Validator returned None")
                return None
            
            # æ·»åŠ é¡å¤–çš„å…ƒè³‡æ–™
            result["generated_at"] = datetime.now().isoformat()
            result["source"] = self.model
            result["validation_method"] = "json_schema_v1"
            
            # è¨˜éŒ„é©—è­‰çµ±è¨ˆ
            stats = validator.get_stats()
            logger.info(f"ğŸ“Š é©—è­‰çµ±è¨ˆ: æˆåŠŸç‡ {stats['success_rate']}% ({stats['successful']}/{stats['total_validations']})")
            
            logger.info(f"âœ… è¿”å›å®Œæ•´çµæœï¼ŒåŒ…å« keys: {list(result.keys())}")
            return result
            
        except ValueError as e:
            logger.error(f"âŒ GPT-5 å›æ‡‰é©—è­‰å¤±æ•—: {e}")
            logger.error(f"Raw response: {content[:200] if content else '(empty)'}...")
            return None
        except Exception as e:
            logger.error(f"âŒ æœªé æœŸçš„è§£æéŒ¯èª¤: {e}", exc_info=True)
            logger.error(f"Raw response: {content[:200] if content else '(empty)'}...")
            return None
    
    def _log_usage(self, response) -> Dict[str, Any]:
        """
        è¨˜éŒ„ API ä½¿ç”¨é‡ä¸¦è¨ˆç®—æˆæœ¬
        
        GPT-5 Nano å®šåƒ¹ (2025 æœ€æ–°):
        - Input: $0.00002 / 1K tokens
        - Output: $0.00008 / 1K tokens
        
        Returns:
            ä½¿ç”¨é‡çµ±è¨ˆå­—å…¸
        """
        usage_stats = {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
            "estimated_cost_usd": 0.0,
            "model": self.model
        }
        
        try:
            if hasattr(response, 'usage') and response.usage:
                usage = response.usage
                usage_stats["prompt_tokens"] = usage.prompt_tokens
                usage_stats["completion_tokens"] = usage.completion_tokens
                usage_stats["total_tokens"] = usage.total_tokens
                
                # æ ¹æ“šæ¨¡å‹è¨ˆç®—å¯¦éš›æˆæœ¬
                if self.model == "gpt-5-nano":
                    # GPT-5 Nano å®šåƒ¹
                    input_cost = (usage.prompt_tokens / 1000) * 0.00002
                    output_cost = (usage.completion_tokens / 1000) * 0.00008
                elif self.model == "gpt-5-mini":
                    # GPT-5 Mini å®šåƒ¹ï¼ˆé ä¼°ï¼‰
                    input_cost = (usage.prompt_tokens / 1000) * 0.00005
                    output_cost = (usage.completion_tokens / 1000) * 0.0002
                elif self.model.startswith("gpt-4"):
                    # GPT-4 ç³»åˆ—å®šåƒ¹ï¼ˆé ä¼°ï¼‰
                    input_cost = (usage.prompt_tokens / 1000) * 0.00015
                    output_cost = (usage.completion_tokens / 1000) * 0.0006
                else:
                    # é»˜èªä½¿ç”¨ GPT-5 Nano åƒ¹æ ¼
                    input_cost = (usage.prompt_tokens / 1000) * 0.00002
                    output_cost = (usage.completion_tokens / 1000) * 0.00008
                
                total_cost = input_cost + output_cost
                usage_stats["estimated_cost_usd"] = total_cost
                usage_stats["input_cost_usd"] = input_cost
                usage_stats["output_cost_usd"] = output_cost
                
                logger.info("ğŸ’° API ä½¿ç”¨é‡çµ±è¨ˆ:")
                logger.info(f"  - Prompt tokens: {usage.prompt_tokens}")
                logger.info(f"  - Completion tokens: {usage.completion_tokens}")
                logger.info(f"  - Total tokens: {usage.total_tokens}")
                logger.info(f"  - Input cost: ${input_cost:.6f}")
                logger.info(f"  - Output cost: ${output_cost:.6f}")
                logger.info(f"  - Total cost: ${total_cost:.6f} USD")
                
                # è¨ˆç®—æ¯æœˆæˆæœ¬é ä¼°
                monthly_estimate_1k = total_cost * 1000
                monthly_estimate_10k = total_cost * 10000
                logger.info(f"  - æœˆåº¦æˆæœ¬é ä¼°:")
                logger.info(f"    â€¢ 1,000 æ¬¡èª¿ç”¨: ${monthly_estimate_1k:.2f}")
                logger.info(f"    â€¢ 10,000 æ¬¡èª¿ç”¨: ${monthly_estimate_10k:.2f}")
                
        except Exception as e:
            logger.error(f"Failed to log usage: {e}")
        
        return usage_stats
    
    async def _generate_with_responses_api(
        self,
        description: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨ Responses API ç”Ÿæˆæ¨™ç±¤ï¼ˆå„ªå…ˆæ–¹æ¡ˆï¼‰"""
        try:
            # æ§‹å»º instructions (ç³»çµ±æç¤ºè©)
            instructions = self._build_system_prompt(context)
            logger.info(f"  - Instructions é•·åº¦: {len(instructions)} å­—ç¬¦")
            
            # æ§‹å»º input (ç”¨æˆ¶è¼¸å…¥)
            user_input = self._build_user_prompt(description, context)
            logger.info(f"  - Input é•·åº¦: {len(user_input)} å­—ç¬¦")
            
            # èª¿ç”¨ Responses API
            logger.info(f"ğŸ“¡ èª¿ç”¨ Responses API")
            logger.info(f"  - æ¨¡å‹: {self.model}")
            logger.info(f"  - Reasoning effort: low")
            logger.info(f"  - Text verbosity: medium")
            logger.info(f"  - Max output tokens: {self.max_tokens}")
            
            logger.info("â³ ç­‰å¾… API å›æ‡‰...")
            
            response = self.client.responses.create(
                model=self.model,
                instructions=instructions,
                input=user_input,
                reasoning={"effort": "low"},
                text={
                    "verbosity": "medium",
                    "format": {
                        "type": "json_schema",
                        "name": "tag_recommendation",
                        "strict": True,
                        "schema": {
                            "type": "object",
                            "properties": {
                                "tags": {
                                    "type": "array",
                                    "items": {"type": "string"},
                                    "minItems": 1,
                                    "maxItems": 15
                                },
                                "confidence": {
                                    "type": "number",
                                    "minimum": 0.0,
                                    "maximum": 1.0
                                },
                                "reasoning": {
                                    "type": "string",
                                    "maxLength": 500
                                },
                                "categories": {
                                    "type": "array",
                                    "items": {
                                        "type": "string",
                                        "enum": [
                                            "CHARACTER", "APPEARANCE", "CLOTHING", "ACTION", 
                                            "SCENE", "STYLE", "OBJECT", "COMPOSITION", "EFFECT"
                                        ]
                                    }
                                }
                            },
                            "required": ["tags", "confidence", "reasoning", "categories"],
                            "additionalProperties": False
                        }
                    }
                },
                max_output_tokens=self.max_tokens
            )
            
            logger.info("âœ… API å›æ‡‰æˆåŠŸ")
            
            # ç²å–å›æ‡‰æ–‡å­—
            output_text = response.output_text
            logger.info(f"ğŸ“¦ å›æ‡‰å…§å®¹:")
            logger.info(f"  - é•·åº¦: {len(output_text)} å­—ç¬¦")
            logger.info(f"  - å‰ 200 å­—ç¬¦: {output_text[:200]}")
            
            # è§£æå›æ‡‰ï¼ˆResponses API å·²ç¶“ä¿è­‰ JSON æ ¼å¼ï¼‰
            result = self._parse_response(output_text)
            
            if result:
                logger.info("âœ… JSON è§£ææˆåŠŸ")
                logger.info(f"  - Tags: {result.get('tags', [])[:5]}")
                logger.info(f"  - Confidence: {result.get('confidence', 0)}")
            else:
                logger.error("âŒ JSON è§£æå¤±æ•—")
            
            # è¨˜éŒ„ä½¿ç”¨é‡
            self._log_responses_api_usage(response)
            
            logger.info("=" * 60)
            return result
            
        except openai.APIError as e:
            logger.error("=" * 60)
            logger.error(f"âŒ Responses API éŒ¯èª¤: {e}")
            logger.error(f"  - ç‹€æ…‹ç¢¼: {e.status_code if hasattr(e, 'status_code') else 'N/A'}")
            logger.error("=" * 60)
            return None
        except Exception as e:
            logger.error("=" * 60)
            logger.error(f"âŒ Responses API æœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
            logger.error("=" * 60)
            return None
    
    def _log_responses_api_usage(self, response) -> Dict[str, Any]:
        """è¨˜éŒ„ Responses API ä½¿ç”¨é‡"""
        usage_stats = {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
            "estimated_cost_usd": 0.0,
            "model": self.model,
            "api_type": "responses"
        }
        
        try:
            # Responses API çš„ usage å¯èƒ½åœ¨ä¸åŒä½ç½®
            if hasattr(response, 'usage') and response.usage:
                usage = response.usage
                
                # å˜—è©¦ç²å– token æ•¸æ“š
                prompt_tokens = getattr(usage, 'input_tokens', 0) or getattr(usage, 'prompt_tokens', 0)
                completion_tokens = getattr(usage, 'output_tokens', 0) or getattr(usage, 'completion_tokens', 0)
                total_tokens = getattr(usage, 'total_tokens', 0) or (prompt_tokens + completion_tokens)
                
                usage_stats["prompt_tokens"] = prompt_tokens
                usage_stats["completion_tokens"] = completion_tokens
                usage_stats["total_tokens"] = total_tokens
                
                # è¨ˆç®—æˆæœ¬
                if self.model == "gpt-5-mini":
                    input_cost = (prompt_tokens / 1000) * 0.00005
                    output_cost = (completion_tokens / 1000) * 0.0002
                else:
                    input_cost = (prompt_tokens / 1000) * 0.00002
                    output_cost = (completion_tokens / 1000) * 0.00008
                
                total_cost = input_cost + output_cost
                usage_stats["estimated_cost_usd"] = total_cost
                
                logger.info("ğŸ’° Responses API ä½¿ç”¨é‡:")
                logger.info(f"  - Input tokens: {prompt_tokens}")
                logger.info(f"  - Output tokens: {completion_tokens}")
                logger.info(f"  - Total tokens: {total_tokens}")
                logger.info(f"  - æˆæœ¬: ${total_cost:.6f}")
                
        except Exception as e:
            logger.error(f"è¨˜éŒ„ Responses API ä½¿ç”¨é‡å¤±æ•—: {e}")
        
        return usage_stats
    
    async def test_connection(self) -> Dict[str, Any]:
        """æ¸¬è©¦ GPT-5 Nano é€£æ¥"""
        test_result = {
            "available": False,
            "error": None,
            "config": {},
            "test_response": None,
            "validation_stats": None
        }
        
        try:
            # æª¢æŸ¥é…ç½®
            test_result["config"] = {
                "api_key_set": bool(self.api_key),
                "model": self.model,
                "max_tokens": self.max_tokens,
                "temperature": self.temperature,
                "timeout": self.timeout,
                "enabled": self.enabled
            }
            
            # ç²å–é©—è­‰çµ±è¨ˆ
            validator = get_gpt5_validator()
            test_result["validation_stats"] = validator.get_stats()
            
            if not self.is_available():
                test_result["error"] = "GPT-5 Nano not available"
                return test_result
            
            # æ¸¬è©¦ API èª¿ç”¨
            test_params = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹æ¸¬è©¦åŠ©æ‰‹ã€‚è«‹å›æ‡‰ 'Hello, OpenAI!'"},
                    {"role": "user", "content": "è«‹å›æ‡‰æ¸¬è©¦è¨Šæ¯"}
                ],
                "max_completion_tokens": 50,
                "timeout": 10
            }
            
            # åªæœ‰é GPT-5 æ¨¡å‹æ‰æ·»åŠ  temperature
            if not self.is_gpt5:
                test_params["temperature"] = 0.1
            
            test_response = self.client.chat.completions.create(**test_params)
            
            test_result["available"] = True
            test_result["test_response"] = test_response.choices[0].message.content
            
        except Exception as e:
            test_result["error"] = str(e)
            logger.error(f"GPT-5 Nano connection test failed: {e}")
        
        return test_result
    
    def get_validation_stats(self) -> Dict[str, Any]:
        """ç²å–é©—è­‰çµ±è¨ˆä¿¡æ¯"""
        validator = get_gpt5_validator()
        return validator.get_stats()
    
    def reset_validation_stats(self) -> None:
        """é‡ç½®é©—è­‰çµ±è¨ˆ"""
        validator = get_gpt5_validator()
        validator.reset_stats()


# å…¨åŸŸå¯¦ä¾‹
_gpt5_nano_client = None


def get_gpt5_nano_client() -> GPT5NanoClient:
    """ç²å– GPT-5 Nano å®¢æˆ¶ç«¯å¯¦ä¾‹"""
    global _gpt5_nano_client
    if _gpt5_nano_client is None:
        _gpt5_nano_client = GPT5NanoClient()
    return _gpt5_nano_client
