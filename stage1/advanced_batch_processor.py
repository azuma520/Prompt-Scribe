#!/usr/bin/env python3
"""
é€²éšæ‰¹é‡è™•ç†å™¨ - æ”¯æŒå‹•æ…‹èª¿æ•´å’Œæª¢æŸ¥é»
è™•ç†å‰©é¤˜çš„æ‰€æœ‰ä¸­é »æ¨™ç±¤ï¼Œç›®æ¨™é”æˆ 92% è¦†è“‹ç‡
"""

import sqlite3
import time
from optimized_llm_classifier import OptimizedLLMClassifier
from datetime import datetime

class AdvancedBatchProcessor:
    """é€²éšæ‰¹é‡è™•ç†å™¨"""
    
    def __init__(self, budget_limit=5.0):
        self.classifier = OptimizedLLMClassifier()
        self.budget_limit = budget_limit
        self.estimated_cost_per_batch = 0.0001  # Gemini 2.5 Flash Lite
        self.total_processed = 0
        self.total_updated = 0
        self.total_cost = 0.0
        self.checkpoint_interval = 300
        
    def estimate_total_cost(self, total_tags):
        """é ä¼°ç¸½æˆæœ¬"""
        batches = (total_tags + 19) // 20
        return batches * self.estimated_cost_per_batch
    
    def get_current_stats(self):
        """ç²å–ç•¶å‰çµ±è¨ˆ"""
        conn = sqlite3.connect('output/tags.db')
        
        total_tags = conn.execute('SELECT COUNT(*) FROM tags_final').fetchone()[0]
        classified_tags = conn.execute('SELECT COUNT(*) FROM tags_final WHERE main_category IS NOT NULL').fetchone()[0]
        coverage = classified_tags / total_tags * 100
        
        # LLM åˆ†é¡å“è³ª
        llm_stats = conn.execute('''
            SELECT 
                COUNT(*) as count,
                AVG(classification_confidence) as avg_conf
            FROM tags_final 
            WHERE classification_source LIKE '%llm%'
            AND classification_timestamp >= datetime('now', '-1 hour')
        ''').fetchone()
        
        recent_count, recent_avg_conf = llm_stats if llm_stats[0] else (0, 0)
        
        conn.close()
        
        return {
            'coverage': coverage,
            'total_tags': total_tags,
            'classified_tags': classified_tags,
            'recent_count': recent_count,
            'recent_avg_conf': recent_avg_conf or 0
        }
    
    def checkpoint_evaluation(self):
        """æª¢æŸ¥é»è©•ä¼°"""
        print("\n" + "="*80)
        print(f"æª¢æŸ¥é»è©•ä¼° - å·²è™•ç† {self.total_processed} å€‹æ¨™ç±¤")
        print("="*80)
        
        stats = self.get_current_stats()
        
        print(f"\nç•¶å‰ç‹€æ…‹:")
        print(f"  è¦†è“‹ç‡: {stats['coverage']:.2f}%")
        print(f"  æœ¬è¼ªè™•ç†: {self.total_processed} å€‹æ¨™ç±¤")
        print(f"  æˆåŠŸæ›´æ–°: {self.total_updated} å€‹")
        print(f"  æˆåŠŸç‡: {self.total_updated/self.total_processed*100:.2f}%")
        print(f"  é ä¼°æˆæœ¬: ${self.total_cost:.3f}")
        
        if stats['recent_count'] > 0:
            print(f"  æœ€è¿‘å¹³å‡ä¿¡å¿ƒåº¦: {stats['recent_avg_conf']:.3f}")
        
        # è©•ä¼°æ˜¯å¦éœ€è¦èª¿æ•´
        success_rate = self.total_updated / self.total_processed if self.total_processed > 0 else 1.0
        
        print(f"\nå“è³ªè©•ä¼°:")
        if stats['recent_avg_conf'] >= 0.85:
            print(f"  ä¿¡å¿ƒåº¦: å„ªç§€ ({stats['recent_avg_conf']:.3f})")
        elif stats['recent_avg_conf'] >= 0.75:
            print(f"  ä¿¡å¿ƒåº¦: è‰¯å¥½ ({stats['recent_avg_conf']:.3f})")
        else:
            print(f"  [WARN] ä¿¡å¿ƒåº¦åä½ ({stats['recent_avg_conf']:.3f})")
        
        if success_rate >= 0.95:
            print(f"  æˆåŠŸç‡: å„ªç§€ ({success_rate*100:.2f}%)")
        elif success_rate >= 0.90:
            print(f"  æˆåŠŸç‡: è‰¯å¥½ ({success_rate*100:.2f}%)")
        else:
            print(f"  [WARN] æˆåŠŸç‡åä½ ({success_rate*100:.2f}%)")
        
        # æ±ºç­–å»ºè­°
        print(f"\nå»ºè­°:")
        if success_rate < 0.90 or (stats['recent_avg_conf'] > 0 and stats['recent_avg_conf'] < 0.75):
            print("  â†’ å»ºè­°æš«åœï¼Œæª¢æŸ¥ä¸¦å„ªåŒ–æç¤ºè©")
            return False
        else:
            print("  â†’ å¯ä»¥ç¹¼çºŒè™•ç†")
            return True
    
    def process_frequency_range(self, min_freq, max_freq, phase_name, batch_size=20):
        """è™•ç†ç‰¹å®šé »ç‡ç¯„åœçš„æ¨™ç±¤"""
        conn = sqlite3.connect('output/tags.db')
        
        # ç²å–æ¨™ç±¤
        tags_to_process = conn.execute(f'''
            SELECT name, post_count
            FROM tags_final 
            WHERE danbooru_cat = 0 
            AND main_category IS NULL
            AND post_count >= {min_freq} AND post_count < {max_freq}
            ORDER BY post_count DESC
        ''').fetchall()
        
        conn.close()
        
        total_tags = len(tags_to_process)
        
        if total_tags == 0:
            print(f"\n[{phase_name}] æ²’æœ‰éœ€è¦è™•ç†çš„æ¨™ç±¤")
            return 0, 0
        
        print("\n" + "="*80)
        print(f"[{phase_name}] è™•ç† {min_freq:,}-{max_freq:,} é »ç‡ç¯„åœ")
        print("="*80)
        print(f"æ¨™ç±¤æ•¸é‡: {total_tags} å€‹")
        print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"é ä¼°æ‰¹æ¬¡: {(total_tags + batch_size - 1) // batch_size}")
        print(f"é ä¼°æˆæœ¬: ${self.estimate_total_cost(total_tags):.3f}")
        
        # æ‰¹æ¬¡è™•ç†
        phase_processed = 0
        phase_updated = 0
        total_batches = (total_tags + batch_size - 1) // batch_size
        
        for batch_idx in range(0, total_tags, batch_size):
            batch_tags = [tag for tag, _ in tags_to_process[batch_idx:batch_idx + batch_size]]
            batch_num = batch_idx // batch_size + 1
            
            print(f"\næ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch_tags)} å€‹æ¨™ç±¤)")
            print(f"  æ¨™ç±¤: {', '.join(batch_tags[:5])}{'...' if len(batch_tags) > 5 else ''}")
            
            # åˆ†é¡
            results = self.classifier.classify_batch(batch_tags)
            
            # ä¿å­˜
            updated = self.classifier.save_to_database(results, f"{phase_name.lower().replace(' ', '_')}_batch")
            
            phase_processed += len(batch_tags)
            phase_updated += updated
            self.total_processed += len(batch_tags)
            self.total_updated += updated
            self.total_cost += self.estimated_cost_per_batch
            
            print(f"  å®Œæˆ: {updated}/{len(batch_tags)} å€‹æ¨™ç±¤")
            
            # æª¢æŸ¥é»è©•ä¼°
            if self.total_processed % self.checkpoint_interval == 0:
                if not self.checkpoint_evaluation():
                    print("\n[INFO] å»ºè­°æš«åœï¼Œè«‹æª¢æŸ¥å“è³ª")
                    return phase_processed, phase_updated
            
            # API é™æµå»¶é²
            if batch_idx + batch_size < total_tags:
                time.sleep(1.5)
        
        # Phase ç¸½çµ
        print(f"\n[{phase_name}] éšæ®µå®Œæˆ:")
        print(f"  è™•ç†: {phase_processed} å€‹")
        print(f"  æ›´æ–°: {phase_updated} å€‹")
        print(f"  æˆåŠŸç‡: {phase_updated/phase_processed*100:.2f}%")
        
        return phase_processed, phase_updated
    
    def run_full_optimization(self):
        """åŸ·è¡Œå®Œæ•´å„ªåŒ–æµç¨‹"""
        print("="*80)
        print("é€²éšæ‰¹é‡è™•ç† - ç›®æ¨™ 92% è¦†è“‹ç‡")
        print("="*80)
        print(f"é ç®—ä¸Šé™: ${self.budget_limit}")
        print(f"æª¢æŸ¥é»é–“éš”: æ¯ {self.checkpoint_interval} å€‹æ¨™ç±¤")
        print(f"é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # åˆå§‹çµ±è¨ˆ
        initial_stats = self.get_current_stats()
        print(f"\nåˆå§‹è¦†è“‹ç‡: {initial_stats['coverage']:.2f}%")
        
        # Phase 1: 30K-50K
        print("\n" + "ğŸ¯ Phase 1: é«˜é »æ®µ (30K-50K)")
        p1_processed, p1_updated = self.process_frequency_range(
            30000, 50000, "Phase 1", batch_size=20
        )
        
        # Phase 2: 20K-30K
        print("\n" + "ğŸ¯ Phase 2: ä¸­é«˜é »æ®µ (20K-30K)")
        p2_processed, p2_updated = self.process_frequency_range(
            20000, 30000, "Phase 2", batch_size=15
        )
        
        # Phase 3: 10K-20K
        print("\n" + "ğŸ¯ Phase 3: ä¸­é »æ®µ (10K-20K)")
        p3_processed, p3_updated = self.process_frequency_range(
            10000, 20000, "Phase 3", batch_size=15
        )
        
        # æœ€çµ‚ç¸½çµ
        final_stats = self.get_current_stats()
        
        print("\n" + "="*80)
        print("å®Œæ•´å„ªåŒ–æµç¨‹ç¸½çµ")
        print("="*80)
        print(f"åˆå§‹è¦†è“‹ç‡: {initial_stats['coverage']:.2f}%")
        print(f"æœ€çµ‚è¦†è“‹ç‡: {final_stats['coverage']:.2f}%")
        print(f"è¦†è“‹ç‡æå‡: +{final_stats['coverage'] - initial_stats['coverage']:.2f}%")
        print(f"\nè™•ç†æ¨™ç±¤ç¸½æ•¸: {self.total_processed}")
        print(f"æˆåŠŸæ›´æ–°: {self.total_updated}")
        print(f"ç¸½æˆåŠŸç‡: {self.total_updated/self.total_processed*100:.2f}%")
        print(f"é ä¼°ç¸½æˆæœ¬: ${self.total_cost:.3f}")
        print(f"çµæŸæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        if final_stats['coverage'] >= 92.0:
            print("\nğŸ‰ğŸ‰ğŸ‰ æ­å–œï¼å·²é”æˆ 92% ç›®æ¨™ï¼ ğŸ‰ğŸ‰ğŸ‰")
        elif final_stats['coverage'] >= 91.5:
            print("\nğŸŠ å„ªç§€ï¼å·²æ¥è¿‘ 92% ç›®æ¨™ï¼")
        else:
            print(f"\nè·é›¢ 92% é‚„éœ€: {92.0 - final_stats['coverage']:.2f}%")
        
        print("="*80)

if __name__ == "__main__":
    processor = AdvancedBatchProcessor(budget_limit=5.0)
    processor.run_full_optimization()


