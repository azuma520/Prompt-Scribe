#!/usr/bin/env python3
"""
Plan C Phase 2 åŸ·è¡Œè…³æœ¬
è™•ç†ä½é »æ¨™ç±¤ (1K-10K post_count)
"""

import sqlite3
import time
import logging
from typing import List, Dict, Optional
from datetime import datetime
from pathlib import Path

from optimized_llm_classifier import OptimizedLLMClassifier, ClassificationResult
from checkpoint_evaluator import CheckpointEvaluator
from batch_size_adjuster import BatchSizeAdjuster
from quality_monitor import QualityMonitor
from progress_reporter import ProgressReporter
from auto_rule_extractor import AutoRuleExtractor
from config import DB_PATH, OUTPUT_DIR

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(OUTPUT_DIR / 'plan_c_phase2.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class Phase2Executor:
    """Phase 2 åŸ·è¡Œå™¨ - è™•ç†ä½é »æ¨™ç±¤"""
    
    # Phase é…ç½®
    PHASES = [
        {
            'name': 'Phase 2-1: 5K-10K',
            'min_count': 5000,
            'max_count': 10000,
            'batch_size': 12,
            'confidence_threshold': 0.70,
            'source_tag': 'phase2_1_5k_10k_batch',
            'retry_count': 2,
            'delay': 2.0
        },
        {
            'name': 'Phase 2-2: 3K-5K',
            'min_count': 3000,
            'max_count': 5000,
            'batch_size': 12,
            'confidence_threshold': 0.65,
            'source_tag': 'phase2_2_3k_5k_batch',
            'retry_count': 2,
            'delay': 2.0
        },
        {
            'name': 'Phase 2-3: 1K-3K',
            'min_count': 1000,
            'max_count': 3000,
            'batch_size': 10,
            'confidence_threshold': 0.60,
            'source_tag': 'phase2_3_1k_3k_batch',
            'retry_count': 2,
            'delay': 2.5
        }
    ]
    
    def __init__(self):
        """åˆå§‹åŒ–åŸ·è¡Œå™¨"""
        self.classifier = OptimizedLLMClassifier(use_low_freq_prompt=True)  # ä½¿ç”¨ä½é »æç¤ºè©
        self.checkpoint_evaluator = CheckpointEvaluator()
        self.batch_adjuster = BatchSizeAdjuster()
        self.quality_monitor = QualityMonitor()
        self.progress_reporter = ProgressReporter()
        self.rule_extractor = AutoRuleExtractor()
        
        self.db_path = DB_PATH
        self.total_processed = 0
        self.total_success = 0
        self.phase_stats = []
        
    def get_unclassified_tags(self, min_count: int, max_count: int) -> List[Dict]:
        """ç²å–æœªåˆ†é¡çš„æ¨™ç±¤"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT name, post_count, danbooru_cat
            FROM tags_final
            WHERE main_category IS NULL
            AND post_count >= ?
            AND post_count < ?
            ORDER BY post_count DESC
        """, (min_count, max_count))
        
        tags = [
            {
                'name': row[0],
                'post_count': row[1],
                'danbooru_cat': row[2]
            }
            for row in cursor.fetchall()
        ]
        
        conn.close()
        logger.info(f"æ‰¾åˆ° {len(tags)} å€‹æœªåˆ†é¡æ¨™ç±¤ ({min_count}-{max_count})")
        return tags
    
    def update_tag_classification(self, result: ClassificationResult, 
                                 source_tag: str, needs_review: bool = False) -> bool:
        """æ›´æ–°æ¨™ç±¤åˆ†é¡"""
        if not result.success:
            return False
            
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # å°æ–¼ä½ä¿¡å¿ƒåº¦æ¨™ç±¤ï¼Œæ·»åŠ éœ€å¯©æŸ¥æ¨™è¨˜
            reasoning = result.reasoning
            if needs_review:
                reasoning = f"[éœ€å¯©æŸ¥] {reasoning}"
            
            cursor.execute("""
                UPDATE tags_final
                SET main_category = ?,
                    sub_category = ?,
                    classification_confidence = ?,
                    classification_reasoning = ?,
                    classification_source = ?,
                    classification_timestamp = ?
                WHERE name = ?
            """, (
                result.main_category,
                result.sub_category,
                result.confidence,
                reasoning,
                source_tag,
                datetime.now().isoformat(),
                result.tag_name
            ))
            
            conn.commit()
            conn.close()
            return True
            
        except Exception as e:
            logger.error(f"æ›´æ–°æ¨™ç±¤å¤±æ•— {result.tag_name}: {e}")
            return False
    
    def process_phase(self, phase_config: Dict) -> Dict:
        """è™•ç†å–®å€‹ phase"""
        logger.info("="*80)
        logger.info(f"é–‹å§‹ {phase_config['name']}")
        logger.info("="*80)
        
        # ç²å–å¾…è™•ç†æ¨™ç±¤
        tags = self.get_unclassified_tags(
            phase_config['min_count'],
            phase_config['max_count']
        )
        
        if not tags:
            logger.info(f"{phase_config['name']}: æ²’æœ‰å¾…è™•ç†æ¨™ç±¤")
            return {
                'phase': phase_config['name'],
                'processed': 0,
                'success': 0,
                'failed': 0,
                'success_rate': 0.0,
                'avg_confidence': 0.0
            }
        
        # åˆå§‹åŒ–çµ±è¨ˆ
        phase_start_time = time.time()
        processed = 0
        success = 0
        failed = 0
        low_confidence_count = 0
        confidences = []
        
        # å‹•æ…‹æ‰¹æ¬¡å¤§å°
        current_batch_size = phase_config['batch_size']
        
        # åˆ†æ‰¹è™•ç†
        for i in range(0, len(tags), current_batch_size):
            batch = tags[i:i + current_batch_size]
            batch_names = [tag['name'] for tag in batch]
            
            logger.info(f"\nè™•ç†æ‰¹æ¬¡ {i//current_batch_size + 1}: {len(batch)} å€‹æ¨™ç±¤")
            
            # ä½¿ç”¨åˆ†é¡å™¨è™•ç†
            results = self.classifier.classify_batch(
                batch_names,
                max_retries=phase_config['retry_count']
            )
            
            # æ›´æ–°æ•¸æ“šåº«
            batch_success = 0
            batch_confidences = []
            
            for result in results:
                processed += 1
                self.total_processed += 1
                
                # æª¢æŸ¥ä¿¡å¿ƒåº¦é–¾å€¼
                if result.success and result.confidence >= phase_config['confidence_threshold']:
                    # æ¨™è¨˜ä½ä¿¡å¿ƒåº¦æ¨™ç±¤
                    needs_review = result.confidence < 0.70
                    if needs_review:
                        low_confidence_count += 1
                    
                    if self.update_tag_classification(result, phase_config['source_tag'], needs_review):
                        success += 1
                        batch_success += 1
                        self.total_success += 1
                        confidences.append(result.confidence)
                        batch_confidences.append(result.confidence)
                        
                        if needs_review:
                            logger.warning(f"æ¨™ç±¤ {result.tag_name} ä¿¡å¿ƒåº¦è¼ƒä½: {result.confidence:.2f} [å·²æ¨™è¨˜éœ€å¯©æŸ¥]")
                    else:
                        failed += 1
                else:
                    failed += 1
                    if result.success:
                        logger.warning(f"æ¨™ç±¤ {result.tag_name} ä¿¡å¿ƒåº¦ä¸è¶³: {result.confidence:.2f}")
            
            # æ‰¹æ¬¡çµ±è¨ˆ
            logger.info(f"æ‰¹æ¬¡æˆåŠŸ: {batch_success}/{len(batch)} ({batch_success/len(batch)*100:.1f}%)")
            if batch_confidences:
                logger.info(f"æ‰¹æ¬¡å¹³å‡ä¿¡å¿ƒåº¦: {sum(batch_confidences)/len(batch_confidences):.3f}")
            
            # å“è³ªç›£æ§
            self.quality_monitor.record_batch(results, phase_config['name'])
            
            # æª¢æŸ¥é»è©•ä¼°ï¼ˆæ¯ 300 å€‹æ¨™ç±¤ï¼‰
            if processed % 300 == 0:
                checkpoint_result = self.checkpoint_evaluator.evaluate(
                    processed=processed,
                    success=success,
                    confidences=confidences,
                    phase_name=phase_config['name']
                )
                
                logger.info("\n" + "="*60)
                logger.info("æª¢æŸ¥é»è©•ä¼°")
                logger.info("="*60)
                logger.info(f"æˆåŠŸç‡: {checkpoint_result['success_rate']:.1%} - {checkpoint_result['success_rating']}")
                logger.info(f"å¹³å‡ä¿¡å¿ƒåº¦: {checkpoint_result['avg_confidence']:.3f} - {checkpoint_result['confidence_rating']}")
                logger.info(f"è¦†è“‹ç‡é€²åº¦: {checkpoint_result['coverage_progress']}")
                logger.info(f"ä½ä¿¡å¿ƒåº¦æ¨™ç±¤: {low_confidence_count} ({low_confidence_count/processed*100:.1f}%)")
                logger.info("="*60 + "\n")
                
                # æ ¹æ“šè©•ä¼°çµæœèª¿æ•´æ‰¹æ¬¡å¤§å°
                if checkpoint_result['success_rating'] == 'ğŸ›‘ è­¦å‘Š':
                    logger.warning("æˆåŠŸç‡éä½ï¼Œé™ä½æ‰¹æ¬¡å¤§å°")
                    current_batch_size = max(6, current_batch_size - 2)
            
            # æ¯ 500 å€‹æ¨™ç±¤æå–è¦å‰‡
            if processed % 500 == 0:
                logger.info("æå–è¦å‰‡æ¨¡å¼...")
                try:
                    rules = self.rule_extractor.extract_all_rules()
                    total_rules = sum(len(r) for r in rules.values())
                    logger.info(f"æå–åˆ° {total_rules} å€‹è¦å‰‡æ¨¡å¼")
                except Exception as e:
                    logger.error(f"è¦å‰‡æå–å¤±æ•—: {e}")
            
            # å»¶é²
            time.sleep(phase_config['delay'])
        
        # Phase çµ±è¨ˆ
        phase_duration = time.time() - phase_start_time
        success_rate = success / processed if processed > 0 else 0.0
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
        
        phase_stats = {
            'phase': phase_config['name'],
            'processed': processed,
            'success': success,
            'failed': failed,
            'low_confidence_count': low_confidence_count,
            'success_rate': success_rate,
            'avg_confidence': avg_confidence,
            'duration': phase_duration
        }
        
        self.phase_stats.append(phase_stats)
        
        logger.info("\n" + "="*80)
        logger.info(f"{phase_config['name']} å®Œæˆ")
        logger.info("="*80)
        logger.info(f"è™•ç†: {processed} å€‹")
        logger.info(f"æˆåŠŸ: {success} å€‹ ({success_rate*100:.1f}%)")
        logger.info(f"å¤±æ•—: {failed} å€‹")
        logger.info(f"ä½ä¿¡å¿ƒåº¦: {low_confidence_count} å€‹ ({low_confidence_count/processed*100:.1f}%)")
        logger.info(f"å¹³å‡ä¿¡å¿ƒåº¦: {avg_confidence:.3f}")
        logger.info(f"è€—æ™‚: {phase_duration/60:.1f} åˆ†é˜")
        logger.info("="*80 + "\n")
        
        return phase_stats
    
    def run(self, phase_range: Optional[List[int]] = None):
        """åŸ·è¡Œ Phase 2 çš„æ‰€æœ‰éšæ®µ"""
        logger.info("\n" + "ğŸš€"*40)
        logger.info("é–‹å§‹åŸ·è¡Œ Plan C Phase 2: ä½é »æ¨™ç±¤è™•ç†")
        logger.info("ğŸš€"*40 + "\n")
        
        start_time = time.time()
        
        # ç¢ºå®šè¦åŸ·è¡Œçš„ phase
        phases_to_run = self.PHASES
        if phase_range:
            phases_to_run = [self.PHASES[i] for i in phase_range if i < len(self.PHASES)]
        
        # åŸ·è¡Œå„å€‹ phase
        for phase_config in phases_to_run:
            self.process_phase(phase_config)
            
            # ç”Ÿæˆé€²åº¦å ±å‘Š
            self.progress_reporter.generate_phase2_report(
                self.phase_stats,
                self.total_processed,
                self.total_success
            )
            
            # æª¢æŸ¥æ˜¯å¦é”åˆ°ç›®æ¨™
            overall_stats = self.progress_reporter.get_overall_stats()
            if overall_stats['coverage'] >= 96.0:
                logger.info("\n" + "ğŸ‰"*40)
                logger.info("å·²é”æˆ 96% è¦†è“‹ç‡ç›®æ¨™ï¼")
                logger.info("ğŸ‰"*40 + "\n")
                break
        
        # ç¸½çµ
        total_duration = time.time() - start_time
        overall_success_rate = self.total_success / self.total_processed if self.total_processed > 0 else 0.0
        
        # ç²å–æœ€çµ‚çµ±è¨ˆ
        final_stats = self.progress_reporter.get_overall_stats()
        
        logger.info("\n" + "ğŸ‰"*40)
        logger.info("Phase 2 å…¨éƒ¨å®Œæˆï¼")
        logger.info("ğŸ‰"*40)
        logger.info(f"\nç¸½è™•ç†: {self.total_processed} å€‹æ¨™ç±¤")
        logger.info(f"ç¸½æˆåŠŸ: {self.total_success} å€‹")
        logger.info(f"ç¸½æˆåŠŸç‡: {overall_success_rate*100:.1f}%")
        logger.info(f"ç¸½è€—æ™‚: {total_duration/3600:.2f} å°æ™‚")
        logger.info(f"\næœ€çµ‚è¦†è“‹ç‡: {final_stats['coverage']:.2f}%")
        logger.info(f"å·²åˆ†é¡æ¨™ç±¤: {final_stats['classified_tags']:,}")
        logger.info(f"æœªåˆ†é¡æ¨™ç±¤: {final_stats['unclassified_tags']:,}")
        logger.info("\n" + "="*80 + "\n")
        
        # ç”Ÿæˆæœ€çµ‚å ±å‘Š
        logger.info("ç”Ÿæˆæœ€çµ‚å ±å‘Š...")
        self.quality_monitor.generate_quality_report()
        self.rule_extractor.generate_report()
        self.rule_extractor.generate_python_code()
        
        # å¦‚æœé”åˆ° 96%ï¼Œç”Ÿæˆé”æˆå ±å‘Š
        if final_stats['coverage'] >= 96.0:
            self.progress_reporter.generate_milestone_report(96)
        
        return {
            'total_processed': self.total_processed,
            'total_success': self.total_success,
            'success_rate': overall_success_rate,
            'duration': total_duration,
            'phases': self.phase_stats,
            'final_coverage': final_stats['coverage']
        }


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Plan C Phase 2 åŸ·è¡Œå™¨')
    parser.add_argument('--phases', type=int, nargs='+',
                      help='æŒ‡å®šè¦åŸ·è¡Œçš„ phase (0-2)ï¼Œä¾‹å¦‚: --phases 0 1')
    parser.add_argument('--dry-run', action='store_true',
                      help='æ¸¬è©¦é‹è¡Œï¼Œä¸å¯¦éš›æ›´æ–°æ•¸æ“šåº«')
    
    args = parser.parse_args()
    
    executor = Phase2Executor()
    
    try:
        result = executor.run(phase_range=args.phases)
        
        if result['final_coverage'] >= 96.0:
            logger.info("âœ… Plan C ç›®æ¨™é”æˆï¼è¦†è“‹ç‡ >= 96%")
        else:
            logger.info(f"âš ï¸ ç›®æ¨™æœªå®Œå…¨é”æˆï¼Œç•¶å‰è¦†è“‹ç‡: {result['final_coverage']:.2f}%")
        
        return 0
    except Exception as e:
        logger.error(f"âŒ Phase 2 åŸ·è¡Œå¤±æ•—: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    exit(main())

