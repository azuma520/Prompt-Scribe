#!/usr/bin/env python3
"""
SQLite åˆ° Supabase PostgreSQL é·ç§»å·¥å…·
å°‡ tags.db æ•¸æ“šé·ç§»åˆ° Supabase
"""

import os
import sys
import sqlite3
import json
from datetime import datetime
from dotenv import load_dotenv
import psycopg2
from psycopg2.extras import execute_values
import requests

def load_env():
    """è¼‰å…¥ç’°å¢ƒè®Šæ•¸"""
    load_dotenv()
    
    return {
        'supabase_url': os.getenv('SUPABASE_URL'),
        'supabase_key': os.getenv('SUPABASE_SERVICE_ROLE_KEY'),
        'db_path': 'stage1/output/tags.db'
    }

def get_supabase_connection():
    """ç²å– Supabase PostgreSQL é€£æŽ¥"""
    url = os.getenv('SUPABASE_URL')
    service_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')
    
    # å¾ž Supabase URL æå–é€£æŽ¥ä¿¡æ¯
    # https://xxx.supabase.co -> xxx.supabase.co
    host = url.replace('https://', '').replace('http://', '')
    
    # æ§‹å»º PostgreSQL é€£æŽ¥å­—ä¸²
    conn_string = f"host={host} port=5432 dbname=postgres user=postgres password={service_key} sslmode=require"
    
    try:
        conn = psycopg2.connect(conn_string)
        return conn
    except Exception as e:
        print(f"X ç„¡æ³•é€£æŽ¥åˆ° Supabase: {e}")
        return None

def create_tables(cursor):
    """å‰µå»º PostgreSQL è¡¨çµæ§‹"""
    print("ðŸ“‹ å‰µå»º PostgreSQL è¡¨çµæ§‹...")
    
    # å‰µå»º tags_final è¡¨
    create_tags_table = """
    CREATE TABLE IF NOT EXISTS tags_final (
        id SERIAL PRIMARY KEY,
        name VARCHAR(255) UNIQUE NOT NULL,
        main_category VARCHAR(100),
        sub_category VARCHAR(100),
        classification_source VARCHAR(100),
        classification_confidence DECIMAL(5,3),
        post_count INTEGER DEFAULT 0,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    """
    
    cursor.execute(create_tags_table)
    
    # å‰µå»ºç´¢å¼•
    indexes = [
        "CREATE INDEX IF NOT EXISTS idx_tags_name ON tags_final(name);",
        "CREATE INDEX IF NOT EXISTS idx_tags_main_category ON tags_final(main_category);",
        "CREATE INDEX IF NOT EXISTS idx_tags_sub_category ON tags_final(sub_category);",
        "CREATE INDEX IF NOT EXISTS idx_tags_confidence ON tags_final(classification_confidence);",
        "CREATE INDEX IF NOT EXISTS idx_tags_post_count ON tags_final(post_count);"
    ]
    
    for index_sql in indexes:
        cursor.execute(index_sql)
    
    print("âœ… è¡¨çµæ§‹å‰µå»ºå®Œæˆ")

def migrate_data(sqlite_path, cursor):
    """é·ç§»æ•¸æ“š"""
    print(f"ðŸ“¦ é–‹å§‹é·ç§»æ•¸æ“šå¾ž {sqlite_path}...")
    
    # é€£æŽ¥åˆ° SQLite æ•¸æ“šåº«
    sqlite_conn = sqlite3.connect(sqlite_path)
    sqlite_cursor = sqlite_conn.cursor()
    
    try:
        # ç²å–æ‰€æœ‰æ•¸æ“š
        sqlite_cursor.execute("""
            SELECT name, main_category, sub_category, classification_source, 
                   classification_confidence, post_count
            FROM tags_final
            ORDER BY name
        """)
        
        rows = sqlite_cursor.fetchall()
        total_rows = len(rows)
        
        print(f"ðŸ“Š æ‰¾åˆ° {total_rows:,} ç­†è¨˜éŒ„éœ€è¦é·ç§»")
        
        if total_rows == 0:
            print("âš ï¸ æ²’æœ‰æ•¸æ“šéœ€è¦é·ç§»")
            return
        
        # åˆ†æ‰¹æ’å…¥æ•¸æ“š
        batch_size = 1000
        inserted_count = 0
        error_count = 0
        
        for i in range(0, total_rows, batch_size):
            batch = rows[i:i + batch_size]
            
            try:
                # ä½¿ç”¨ execute_values é€²è¡Œæ‰¹é‡æ’å…¥
                execute_values(
                    cursor,
                    """
                    INSERT INTO tags_final (name, main_category, sub_category, 
                                          classification_source, classification_confidence, post_count)
                    VALUES %s
                    ON CONFLICT (name) DO UPDATE SET
                        main_category = EXCLUDED.main_category,
                        sub_category = EXCLUDED.sub_category,
                        classification_source = EXCLUDED.classification_source,
                        classification_confidence = EXCLUDED.classification_confidence,
                        post_count = EXCLUDED.post_count,
                        updated_at = CURRENT_TIMESTAMP
                    """,
                    batch,
                    template=None,
                    page_size=1000
                )
                
                inserted_count += len(batch)
                print(f"âœ… å·²é·ç§» {inserted_count:,}/{total_rows:,} ç­†è¨˜éŒ„ ({inserted_count/total_rows*100:.1f}%)")
                
            except Exception as e:
                print(f"âŒ æ‰¹æ¬¡æ’å…¥éŒ¯èª¤: {e}")
                error_count += len(batch)
        
        print(f"\nðŸ“Š é·ç§»å®Œæˆ:")
        print(f"  âœ… æˆåŠŸ: {inserted_count:,} ç­†")
        print(f"  âŒ å¤±æ•—: {error_count:,} ç­†")
        
    finally:
        sqlite_conn.close()

def verify_migration(cursor):
    """é©—è­‰é·ç§»çµæžœ"""
    print("\nðŸ” é©—è­‰é·ç§»çµæžœ...")
    
    # æª¢æŸ¥ç¸½è¨˜éŒ„æ•¸
    cursor.execute("SELECT COUNT(*) FROM tags_final")
    total_count = cursor.fetchone()[0]
    print(f"ðŸ“Š ç¸½è¨˜éŒ„æ•¸: {total_count:,}")
    
    # æª¢æŸ¥åˆ†é¡žçµ±è¨ˆ
    cursor.execute("""
        SELECT main_category, COUNT(*) as count, 
               ROUND(AVG(classification_confidence), 3) as avg_confidence
        FROM tags_final 
        WHERE main_category IS NOT NULL
        GROUP BY main_category 
        ORDER BY count DESC
    """)
    
    categories = cursor.fetchall()
    print(f"\nðŸ“ˆ ä¸»åˆ†é¡žçµ±è¨ˆ:")
    for category, count, avg_conf in categories:
        print(f"  {category:25} {count:6,} ç­† (å¹³å‡ä¿¡å¿ƒåº¦: {avg_conf})")
    
    # æª¢æŸ¥ä¿¡å¿ƒåº¦åˆ†ä½ˆ
    cursor.execute("""
        SELECT 
            CASE 
                WHEN classification_confidence >= 0.9 THEN 'é«˜ä¿¡å¿ƒåº¦ (â‰¥0.9)'
                WHEN classification_confidence >= 0.8 THEN 'ä¸­é«˜ä¿¡å¿ƒåº¦ (0.8-0.9)'
                WHEN classification_confidence >= 0.7 THEN 'ä¸­ç­‰ä¿¡å¿ƒåº¦ (0.7-0.8)'
                ELSE 'ä½Žä¿¡å¿ƒåº¦ (<0.7)'
            END as confidence_range,
            COUNT(*) as count
        FROM tags_final 
        WHERE classification_confidence IS NOT NULL
        GROUP BY 
            CASE 
                WHEN classification_confidence >= 0.9 THEN 'é«˜ä¿¡å¿ƒåº¦ (â‰¥0.9)'
                WHEN classification_confidence >= 0.8 THEN 'ä¸­é«˜ä¿¡å¿ƒåº¦ (0.8-0.9)'
                WHEN classification_confidence >= 0.7 THEN 'ä¸­ç­‰ä¿¡å¿ƒåº¦ (0.7-0.8)'
                ELSE 'ä½Žä¿¡å¿ƒåº¦ (<0.7)'
            END
        ORDER BY count DESC
    """)
    
    confidence_stats = cursor.fetchall()
    print(f"\nðŸ“Š ä¿¡å¿ƒåº¦åˆ†ä½ˆ:")
    for range_name, count in confidence_stats:
        print(f"  {range_name:20} {count:6,} ç­†")

def main():
    """ä¸»å‡½æ•¸"""
    print("SQLite åˆ° Supabase é·ç§»å·¥å…·")
    print("=" * 50)
    
    # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
    env = load_env()
    
    # æª¢æŸ¥ SQLite æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(env['db_path']):
        print(f"X æ‰¾ä¸åˆ° SQLite æ–‡ä»¶: {env['db_path']}")
        sys.exit(1)
    
    print(f"V æ‰¾åˆ° SQLite æ–‡ä»¶: {env['db_path']}")
    
    # é€£æŽ¥åˆ° Supabase
    print("é€£æŽ¥åˆ° Supabase...")
    conn = get_supabase_connection()
    if not conn:
        sys.exit(1)
    
    try:
        cursor = conn.cursor()
        
        # å‰µå»ºè¡¨çµæ§‹
        create_tables(cursor)
        
        # é·ç§»æ•¸æ“š
        migrate_data(env['db_path'], cursor)
        
        # æäº¤äº‹å‹™
        conn.commit()
        
        # é©—è­‰é·ç§»çµæžœ
        verify_migration(cursor)
        
        print("\né·ç§»å®Œæˆï¼")
        print("æ•¸æ“šå·²æˆåŠŸé·ç§»åˆ° Supabase PostgreSQL")
        
    except Exception as e:
        print(f"X é·ç§»éŽç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        conn.rollback()
        sys.exit(1)
        
    finally:
        conn.close()

if __name__ == "__main__":
    main()
