#!/usr/bin/env python3
"""
è¦å‰‡è‡ªå‹•æå–å™¨
å¾å·²è™•ç†çš„æ¨™ç±¤ä¸­æå–åˆ†é¡è¦å‰‡æ¨¡å¼
"""

import sqlite3
from typing import List, Dict, Tuple
from collections import defaultdict, Counter
from datetime import datetime
from pathlib import Path

from config import DB_PATH, OUTPUT_DIR


class AutoRuleExtractor:
    """è¦å‰‡è‡ªå‹•æå–å™¨ - å¾å·²åˆ†é¡æ¨™ç±¤ä¸­æå–è¦å‰‡"""
    
    def __init__(self, min_pattern_count: int = 5, min_confidence: float = 0.95):
        """åˆå§‹åŒ–æå–å™¨
        
        Args:
            min_pattern_count: æœ€å°‘æ¨¡å¼å‡ºç¾æ¬¡æ•¸
            min_confidence: æœ€ä½ä¿¡å¿ƒåº¦è¦æ±‚
        """
        self.db_path = DB_PATH
        self.min_pattern_count = min_pattern_count
        self.min_confidence = min_confidence
        self.extracted_rules = []
    
    def extract_suffix_rules(self) -> List[Dict]:
        """æå–å¾Œç¶´è¦å‰‡ï¼ˆå¦‚ _day, _hair, _eyesï¼‰"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ç²å–é«˜ä¿¡å¿ƒåº¦çš„å·²åˆ†é¡æ¨™ç±¤
        cursor.execute("""
            SELECT name, main_category, sub_category, classification_confidence
            FROM tags_final
            WHERE main_category IS NOT NULL
            AND classification_confidence >= ?
            AND name LIKE '%\_%'
        """, (self.min_confidence,))
        
        tags = cursor.fetchall()
        conn.close()
        
        # æŒ‰å¾Œç¶´åˆ†çµ„
        suffix_patterns = defaultdict(list)
        for name, main_cat, sub_cat, confidence in tags:
            if '_' in name:
                suffix = '_' + name.rsplit('_', 1)[-1]
                suffix_patterns[suffix].append({
                    'name': name,
                    'main_category': main_cat,
                    'sub_category': sub_cat,
                    'confidence': confidence
                })
        
        # ç”Ÿæˆè¦å‰‡
        rules = []
        for suffix, tags_list in suffix_patterns.items():
            if len(tags_list) >= self.min_pattern_count:
                # æª¢æŸ¥åˆ†é¡ä¸€è‡´æ€§
                categories = [f"{t['main_category']}/{t['sub_category']}" for t in tags_list]
                category_counter = Counter(categories)
                most_common_cat, count = category_counter.most_common(1)[0]
                
                consistency = count / len(tags_list)
                if consistency >= 0.90:  # 90% ä¸€è‡´æ€§
                    main_cat, sub_cat = most_common_cat.split('/')
                    rules.append({
                        'type': 'suffix',
                        'pattern': suffix,
                        'main_category': main_cat,
                        'sub_category': sub_cat if sub_cat != 'None' else None,
                        'support_count': len(tags_list),
                        'consistency': consistency,
                        'avg_confidence': sum(t['confidence'] for t in tags_list) / len(tags_list),
                        'examples': [t['name'] for t in tags_list[:5]]
                    })
        
        return sorted(rules, key=lambda x: x['support_count'], reverse=True)
    
    def extract_prefix_rules(self) -> List[Dict]:
        """æå–å‰ç¶´è¦å‰‡ï¼ˆå¦‚ white_, blue_, red_ï¼‰"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT name, main_category, sub_category, classification_confidence
            FROM tags_final
            WHERE main_category IS NOT NULL
            AND classification_confidence >= ?
            AND name LIKE '%\_%'
        """, (self.min_confidence,))
        
        tags = cursor.fetchall()
        conn.close()
        
        # æŒ‰å‰ç¶´åˆ†çµ„
        prefix_patterns = defaultdict(list)
        for name, main_cat, sub_cat, confidence in tags:
            if '_' in name:
                prefix = name.split('_', 1)[0] + '_'
                prefix_patterns[prefix].append({
                    'name': name,
                    'main_category': main_cat,
                    'sub_category': sub_cat,
                    'confidence': confidence
                })
        
        # ç”Ÿæˆè¦å‰‡
        rules = []
        for prefix, tags_list in prefix_patterns.items():
            if len(tags_list) >= self.min_pattern_count:
                categories = [f"{t['main_category']}/{t['sub_category']}" for t in tags_list]
                category_counter = Counter(categories)
                most_common_cat, count = category_counter.most_common(1)[0]
                
                consistency = count / len(tags_list)
                if consistency >= 0.90:
                    main_cat, sub_cat = most_common_cat.split('/')
                    rules.append({
                        'type': 'prefix',
                        'pattern': prefix,
                        'main_category': main_cat,
                        'sub_category': sub_cat if sub_cat != 'None' else None,
                        'support_count': len(tags_list),
                        'consistency': consistency,
                        'avg_confidence': sum(t['confidence'] for t in tags_list) / len(tags_list),
                        'examples': [t['name'] for t in tags_list[:5]]
                    })
        
        return sorted(rules, key=lambda x: x['support_count'], reverse=True)
    
    def extract_contains_rules(self) -> List[Dict]:
        """æå–åŒ…å«è¦å‰‡ï¼ˆå¦‚åŒ…å« 'girl', 'boy', 'animal'ï¼‰"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT name, main_category, sub_category, classification_confidence
            FROM tags_final
            WHERE main_category IS NOT NULL
            AND classification_confidence >= ?
        """, (self.min_confidence,))
        
        tags = cursor.fetchall()
        conn.close()
        
        # å¸¸è¦‹è©å½™
        common_words = [
            'girl', 'boy', 'hair', 'eye', 'dress', 'skirt', 'shirt', 
            'weapon', 'sword', 'gun', 'animal', 'cat', 'dog', 'bird',
            'background', 'sky', 'cloud', 'water', 'fire'
        ]
        
        # æŒ‰åŒ…å«è©å½™åˆ†çµ„
        contains_patterns = defaultdict(list)
        for name, main_cat, sub_cat, confidence in tags:
            for word in common_words:
                if word in name:
                    contains_patterns[word].append({
                        'name': name,
                        'main_category': main_cat,
                        'sub_category': sub_cat,
                        'confidence': confidence
                    })
        
        # ç”Ÿæˆè¦å‰‡
        rules = []
        for word, tags_list in contains_patterns.items():
            if len(tags_list) >= self.min_pattern_count:
                categories = [f"{t['main_category']}/{t['sub_category']}" for t in tags_list]
                category_counter = Counter(categories)
                most_common_cat, count = category_counter.most_common(1)[0]
                
                consistency = count / len(tags_list)
                if consistency >= 0.85:  # 85% ä¸€è‡´æ€§ï¼ˆç¨å¾®å¯¬é¬†ï¼‰
                    main_cat, sub_cat = most_common_cat.split('/')
                    rules.append({
                        'type': 'contains',
                        'pattern': word,
                        'main_category': main_cat,
                        'sub_category': sub_cat if sub_cat != 'None' else None,
                        'support_count': len(tags_list),
                        'consistency': consistency,
                        'avg_confidence': sum(t['confidence'] for t in tags_list) / len(tags_list),
                        'examples': [t['name'] for t in tags_list[:5]]
                    })
        
        return sorted(rules, key=lambda x: x['support_count'], reverse=True)
    
    def extract_all_rules(self) -> Dict[str, List[Dict]]:
        """æå–æ‰€æœ‰é¡å‹çš„è¦å‰‡"""
        print("æå–å¾Œç¶´è¦å‰‡...")
        suffix_rules = self.extract_suffix_rules()
        print(f"æ‰¾åˆ° {len(suffix_rules)} å€‹å¾Œç¶´è¦å‰‡")
        
        print("æå–å‰ç¶´è¦å‰‡...")
        prefix_rules = self.extract_prefix_rules()
        print(f"æ‰¾åˆ° {len(prefix_rules)} å€‹å‰ç¶´è¦å‰‡")
        
        print("æå–åŒ…å«è¦å‰‡...")
        contains_rules = self.extract_contains_rules()
        print(f"æ‰¾åˆ° {len(contains_rules)} å€‹åŒ…å«è¦å‰‡")
        
        self.extracted_rules = {
            'suffix': suffix_rules,
            'prefix': prefix_rules,
            'contains': contains_rules
        }
        
        return self.extracted_rules
    
    def generate_python_code(self, output_file: str = 'output/extracted_rules.py'):
        """ç”Ÿæˆ Python è¦å‰‡ä»£ç¢¼"""
        if not self.extracted_rules:
            self.extract_all_rules()
        
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('#!/usr/bin/env python3\n')
            f.write('"""\n')
            f.write('è‡ªå‹•æå–çš„åˆ†é¡è¦å‰‡\n')
            f.write(f'ç”Ÿæˆæ™‚é–“: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n')
            f.write('"""\n\n')
            
            # å¾Œç¶´è¦å‰‡
            f.write('# å¾Œç¶´è¦å‰‡\n')
            f.write('SUFFIX_RULES = {\n')
            for rule in self.extracted_rules['suffix'][:20]:  # å‰ 20 å€‹
                sub_cat = f'"{rule["sub_category"]}"' if rule['sub_category'] else 'None'
                f.write(f'    "{rule["pattern"]}": ("{rule["main_category"]}", {sub_cat}),  ')
                f.write(f'# æ”¯æŒåº¦: {rule["support_count"]}, ä¸€è‡´æ€§: {rule["consistency"]:.1%}\n')
            f.write('}\n\n')
            
            # å‰ç¶´è¦å‰‡
            f.write('# å‰ç¶´è¦å‰‡\n')
            f.write('PREFIX_RULES = {\n')
            for rule in self.extracted_rules['prefix'][:20]:
                sub_cat = f'"{rule["sub_category"]}"' if rule['sub_category'] else 'None'
                f.write(f'    "{rule["pattern"]}": ("{rule["main_category"]}", {sub_cat}),  ')
                f.write(f'# æ”¯æŒåº¦: {rule["support_count"]}, ä¸€è‡´æ€§: {rule["consistency"]:.1%}\n')
            f.write('}\n\n')
            
            # åŒ…å«è¦å‰‡
            f.write('# åŒ…å«è¦å‰‡\n')
            f.write('CONTAINS_RULES = {\n')
            for rule in self.extracted_rules['contains'][:20]:
                sub_cat = f'"{rule["sub_category"]}"' if rule['sub_category'] else 'None'
                f.write(f'    "{rule["pattern"]}": ("{rule["main_category"]}", {sub_cat}),  ')
                f.write(f'# æ”¯æŒåº¦: {rule["support_count"]}, ä¸€è‡´æ€§: {rule["consistency"]:.1%}\n')
            f.write('}\n\n')
            
            # åˆ†é¡å‡½æ•¸
            f.write('def apply_rules(tag_name: str) -> tuple:\n')
            f.write('    """æ‡‰ç”¨æå–çš„è¦å‰‡\n')
            f.write('    \n')
            f.write('    Returns:\n')
            f.write('        (main_category, sub_category) or (None, None)\n')
            f.write('    """\n')
            f.write('    # å¾Œç¶´åŒ¹é…\n')
            f.write('    for suffix, (main_cat, sub_cat) in SUFFIX_RULES.items():\n')
            f.write('        if tag_name.endswith(suffix):\n')
            f.write('            return (main_cat, sub_cat)\n')
            f.write('    \n')
            f.write('    # å‰ç¶´åŒ¹é…\n')
            f.write('    for prefix, (main_cat, sub_cat) in PREFIX_RULES.items():\n')
            f.write('        if tag_name.startswith(prefix):\n')
            f.write('            return (main_cat, sub_cat)\n')
            f.write('    \n')
            f.write('    # åŒ…å«åŒ¹é…\n')
            f.write('    for word, (main_cat, sub_cat) in CONTAINS_RULES.items():\n')
            f.write('        if word in tag_name:\n')
            f.write('            return (main_cat, sub_cat)\n')
            f.write('    \n')
            f.write('    return (None, None)\n')
        
        print(f"Python è¦å‰‡ä»£ç¢¼å·²ç”Ÿæˆ: {output_path}")
    
    def generate_report(self, output_file: str = 'output/RULE_EXTRACTION_LOG.md'):
        """ç”Ÿæˆè¦å‰‡æå–å ±å‘Š"""
        if not self.extracted_rules:
            self.extract_all_rules()
        
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('# è¦å‰‡è‡ªå‹•æå–è¨˜éŒ„\n\n')
            f.write(f'**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n\n')
            f.write('---\n\n')
            
            # ç¸½çµ
            total_rules = sum(len(rules) for rules in self.extracted_rules.values())
            f.write('## ğŸ“Š æå–ç¸½çµ\n\n')
            f.write(f'- **ç¸½è¦å‰‡æ•¸**: {total_rules}\n')
            f.write(f'- **å¾Œç¶´è¦å‰‡**: {len(self.extracted_rules["suffix"])}\n')
            f.write(f'- **å‰ç¶´è¦å‰‡**: {len(self.extracted_rules["prefix"])}\n')
            f.write(f'- **åŒ…å«è¦å‰‡**: {len(self.extracted_rules["contains"])}\n\n')
            
            # å¾Œç¶´è¦å‰‡
            f.write('## å¾Œç¶´è¦å‰‡ (Top 20)\n\n')
            f.write('| æ¨¡å¼ | ä¸»åˆ†é¡ | å‰¯åˆ†é¡ | æ”¯æŒåº¦ | ä¸€è‡´æ€§ | å¹³å‡ä¿¡å¿ƒåº¦ |\n')
            f.write('|------|--------|--------|--------|--------|----------|\n')
            for rule in self.extracted_rules['suffix'][:20]:
                f.write(f'| `{rule["pattern"]}` | {rule["main_category"]} | {rule["sub_category"] or "N/A"} | ')
                f.write(f'{rule["support_count"]} | {rule["consistency"]:.1%} | {rule["avg_confidence"]:.3f} |\n')
            f.write('\n')
            
            # å‰ç¶´è¦å‰‡
            f.write('## å‰ç¶´è¦å‰‡ (Top 20)\n\n')
            f.write('| æ¨¡å¼ | ä¸»åˆ†é¡ | å‰¯åˆ†é¡ | æ”¯æŒåº¦ | ä¸€è‡´æ€§ | å¹³å‡ä¿¡å¿ƒåº¦ |\n')
            f.write('|------|--------|--------|--------|--------|----------|\n')
            for rule in self.extracted_rules['prefix'][:20]:
                f.write(f'| `{rule["pattern"]}` | {rule["main_category"]} | {rule["sub_category"] or "N/A"} | ')
                f.write(f'{rule["support_count"]} | {rule["consistency"]:.1%} | {rule["avg_confidence"]:.3f} |\n')
            f.write('\n')
            
            # åŒ…å«è¦å‰‡
            f.write('## åŒ…å«è¦å‰‡ (Top 20)\n\n')
            f.write('| æ¨¡å¼ | ä¸»åˆ†é¡ | å‰¯åˆ†é¡ | æ”¯æŒåº¦ | ä¸€è‡´æ€§ | å¹³å‡ä¿¡å¿ƒåº¦ |\n')
            f.write('|------|--------|--------|--------|--------|----------|\n')
            for rule in self.extracted_rules['contains'][:20]:
                f.write(f'| `{rule["pattern"]}` | {rule["main_category"]} | {rule["sub_category"] or "N/A"} | ')
                f.write(f'{rule["support_count"]} | {rule["consistency"]:.1%} | {rule["avg_confidence"]:.3f} |\n')
            f.write('\n')
            
            # ç¯„ä¾‹
            f.write('## è¦å‰‡ç¯„ä¾‹\n\n')
            for rule_type, rules in self.extracted_rules.items():
                if rules:
                    f.write(f'### {rule_type.capitalize()} ç¯„ä¾‹\n\n')
                    for rule in rules[:3]:
                        f.write(f'**æ¨¡å¼**: `{rule["pattern"]}`\n')
                        f.write(f'- åˆ†é¡: {rule["main_category"]}/{rule["sub_category"] or "N/A"}\n')
                        f.write(f'- ç¯„ä¾‹: {", ".join(rule["examples"])}\n\n')
        
        print(f"è¦å‰‡æå–å ±å‘Šå·²ç”Ÿæˆ: {output_path}")


if __name__ == "__main__":
    # æ¸¬è©¦
    print("é–‹å§‹æå–è¦å‰‡...")
    extractor = AutoRuleExtractor(min_pattern_count=5, min_confidence=0.90)
    
    rules = extractor.extract_all_rules()
    
    print("\nç”Ÿæˆå ±å‘Šå’Œä»£ç¢¼...")
    extractor.generate_report()
    extractor.generate_python_code()
    
    print("\nå®Œæˆï¼")

